<!DOCTYPE html>
<html lang="en" dir="ltr" class="client-nojs">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" >
<title>Technological singularity - Wikipedia, the free encyclopedia</title>
<meta charset="UTF-8" />
<meta name="generator" content="MediaWiki 1.21wmf9" />
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="../../w/index-title=Technological_singularity&action=edit.php.html" />
<link rel="edit" title="Edit this page" href="../../w/index-title=Technological_singularity&action=edit.php.html" />
<link rel="apple-touch-icon" href="http://en.wikipedia.org/apple-touch-icon.png" />
<link rel="shortcut icon" href="http://en.wikipedia.org/favicon.ico" />
<link rel="search" type="application/opensearchdescription+xml" href="../../w/opensearch_desc.php.html" title="Wikipedia (en)" />
<link rel="EditURI" type="application/rsd+xml" href="../../w/api-action=rsd.php.html" />
<link rel="copyright" href="http://creativecommons.org/licenses/by-sa/3.0/" />
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="../../w/index-title=Special_RecentChanges&feed=atom.php.html" />
<link rel="stylesheet" href="http://bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&lang=en&modules=ext.gadget.DRN-wizard,ReferenceTooltips,charinsert,teahouse%7Cext.wikihiero%7Cmediawiki.legacy.commonPrint,shared%7Cmw.PopUpMediaTransform%7Cskins.vector&only=styles&skin=vector&*" />
<meta name="ResourceLoaderDynamicStyles" content="" />
<link rel="stylesheet" href="http://bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&lang=en&modules=site&only=styles&skin=vector&*" />
<style>a:lang(ar),a:lang(ckb),a:lang(fa),a:lang(kk-arab),a:lang(mzn),a:lang(ps),a:lang(ur){text-decoration:none}
/* cache key: enwiki:resourceloader:filter:minify-css:7:d11e4771671c2d6cdedf7c90d8131cd5 */</style>

<script src="http://bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&lang=en&modules=startup&only=scripts&skin=vector&*"></script>
<script>if(window.mw){
mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Technological_singularity","wgTitle":"Technological singularity","wgCurRevisionId":538009358,"wgArticleId":54245,"wgIsArticle":true,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Missing redirects","All articles with unsourced statements","Articles with unsourced statements from July 2012","Articles with unsourced statements from November 2010","All articles with dead external links","Articles with dead external links from July 2009","Wikipedia external links cleanup from March 2011","Wikipedia spam cleanup from March 2011","Spoken articles","Articles with hAudio microformats","Eschatology","Evolution","Futurology","Philosophy of artificial intelligence","Singularitarianism","Sociocultural evolution","Theories of history"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Technological_singularity","wgRestrictionEdit":[],"wgRestrictionMove":[],"wgVectorEnabledModules":{"collapsiblenav":true,"collapsibletabs":true,"editwarning":true,"expandablesearch":false,"footercleanup":true,"sectioneditlinks":false,"experiments":true},"wgWikiEditorEnabledModules":{"toolbar":true,"dialogs":true,"hidesig":true,"templateEditor":false,"templates":false,"preview":false,"previewDialog":false,"publish":false,"toc":false},"wgTrackingToken":"b02f40c2b7e8838c0538e503f200aebb","wgArticleFeedbackv5Permissions":{"aft-reader":true,"aft-member":false,"aft-editor":false,"aft-monitor":false,"aft-administrator":false,"aft-oversighter":false},"wgVisualEditor":{"isPageWatched":false,"enableSectionEditLinks":false},"wikilove-recipient":"","wikilove-anon":0,"wgGuidedTourHelpUrl":"Help:Guided tours","wgGuidedTourTestWikitextDescription":"A guider in your on-wiki tour can contain wikitext using onShow and parseDescription. Use it to create a wikilink to the \x3ca href=\"/wiki/Help:Guided_tours\" title=\"Help:Guided tours\"\x3eGuided tours documentation\x3c/a\x3e. Or an external link \x3ca rel=\"nofollow\" class=\"external text\" href=\"https://github.com/tychay/mwgadget.GuidedTour\"\x3eto GitHub\x3c/a\x3e, for instance.","wgFlaggedRevsParams":{"tags":{"status":{"levels":1,"quality":2,"pristine":3}}},"wgStableRevisionId":null,"wgCategoryTreePageCategoryOptions":"{\"mode\":0,\"hideprefix\":20,\"showcount\":true,\"namespaces\":false}","Geo":{"city":"","country":""},"wgNoticeProject":"wikipedia","aftv5Article":{"id":54245,"title":"Technological singularity","namespace":0,"categories":["All articles with dead external links","All articles with unsourced statements","Articles with dead external links from July 2009","Articles with hAudio microformats","Articles with unsourced statements from July 2012","Articles with unsourced statements from November 2010","Eschatology","Evolution","Futurology","Missing redirects","Philosophy of artificial intelligence","Singularitarianism","Sociocultural evolution","Spoken articles","Theories of history","Wikipedia external links cleanup from March 2011","Wikipedia spam cleanup from March 2011"],"permissionLevel":"aft-reader"}});
}</script><script>if(window.mw){
mw.loader.implement("user.options",function(){mw.user.options.set({"ccmeonemails":0,"cols":80,"date":"default","diffonly":0,"disablemail":0,"disablesuggest":0,"editfont":"default","editondblclick":0,"editsection":1,"editsectiononrightclick":0,"enotifminoredits":0,"enotifrevealaddr":0,"enotifusertalkpages":1,"enotifwatchlistpages":0,"extendwatchlist":0,"externaldiff":0,"externaleditor":0,"fancysig":0,"forceeditsummary":0,"gender":"unknown","hideminor":0,"hidepatrolled":0,"imagesize":2,"justify":0,"math":0,"minordefault":0,"newpageshidepatrolled":0,"nocache":0,"noconvertlink":0,"norollbackdiff":0,"numberheadings":0,"previewonfirst":0,"previewontop":1,"quickbar":5,"rcdays":7,"rclimit":50,"rememberpassword":0,"rows":25,"searchlimit":20,"showhiddencats":false,"showjumplinks":1,"shownumberswatching":1,"showtoc":1,"showtoolbar":1,"skin":"vector","stubthreshold":0,"thumbsize":4,"underline":2,"uselivepreview":0,"usenewrc":0,"watchcreations":1,"watchdefault":0,"watchdeletion":0,"watchlistdays":3
,"watchlisthideanons":0,"watchlisthidebots":0,"watchlisthideliu":0,"watchlisthideminor":0,"watchlisthideown":0,"watchlisthidepatrolled":0,"watchmoves":0,"wllimit":250,"flaggedrevssimpleui":1,"flaggedrevsstable":0,"flaggedrevseditdiffs":true,"flaggedrevsviewdiffs":false,"vector-simplesearch":1,"useeditwarning":1,"vector-collapsiblenav":1,"usebetatoolbar":1,"usebetatoolbar-cgd":1,"aftv5-last-filter":null,"wikilove-enabled":1,"echo-email-notificationspagetriage-mark-as-reviewed":true,"echo-email-notificationspagetriage-add-maintenance-tag":true,"echo-email-notificationspagetriage-add-deletion-tag":true,"ep_showtoplink":false,"ep_bulkdelorgs":false,"ep_bulkdelcourses":true,"ep_showdyk":true,"variant":"en","language":"en","searchNs0":true,"searchNs1":false,"searchNs2":false,"searchNs3":false,"searchNs4":false,"searchNs5":false,"searchNs6":false,"searchNs7":false,"searchNs8":false,"searchNs9":false,"searchNs10":false,"searchNs11":false,"searchNs12":false,"searchNs13":false,"searchNs14":false
,"searchNs15":false,"searchNs100":false,"searchNs101":false,"searchNs108":false,"searchNs109":false,"searchNs446":false,"searchNs447":false,"searchNs710":false,"searchNs711":false,"gadget-teahouse":1,"gadget-ReferenceTooltips":1,"gadget-HotCat":1,"gadget-DRN-wizard":1,"gadget-charinsert":1,"gadget-mySandbox":1});;},{},{});mw.loader.implement("user.tokens",function(){mw.user.tokens.set({"editToken":"+\\","patrolToken":false,"watchToken":false});;},{},{});
/* cache key: enwiki:resourceloader:filter:minify-js:7:19e64e7d3e84450cdd6aaeece6e56fab */
}</script>
<script>if(window.mw){
mw.loader.load(["mediawiki.page.startup","mediawiki.legacy.wikibits","mediawiki.legacy.ajax","ext.vector.footerCleanup","ext.wikimediaShopLink.core","ext.centralNotice.bannerController"]);
}</script>
<script src="http://bits.wikimedia.org/geoiplookup"></script><link rel="dns-prefetch" href="http://meta.wikimedia.org" /><!--[if lt IE 7]><style type="text/css">body{behavior:url("../../w/skins-1.21wmf9/vector/csshover.min.htc")}</style><![endif]--></head>
<body class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-Technological_singularity skin-vector action-view vector-animateLayout">
		<div id="mw-page-base" class="noprint"></div>
		<div id="mw-head-base" class="noprint"></div>
		<!-- content -->
		<div id="content" class="mw-body" role="main">
			<a id="top"></a>
			<div id="mw-js-message" style="display:none;"></div>
						<!-- sitenotice -->
			<div id="siteNotice"><!-- CentralNotice --><script>
	mw.loader.using( 'ext.centralNotice.bannerController', function() { mw.centralNotice.initialize(); } );
</script>
</div>
			<!-- /sitenotice -->
						<!-- firstHeading -->
			<h1 id="firstHeading" class="firstHeading" lang="en"><span dir="auto">Technological singularity</span></h1>
			<!-- /firstHeading -->
			<!-- bodyContent -->
			<div id="bodyContent">
								<!-- tagline -->
				<div id="siteSub">From Wikipedia, the free encyclopedia</div>
				<!-- /tagline -->
								<!-- subtitle -->
				<div id="contentSub"></div>
				<!-- /subtitle -->
																<!-- jumpto -->
				<div id="jump-to-nav" class="mw-jump">
					Jump to:					<a href="#mw-head">navigation</a>, 					<a href="#p-search">search</a>
				</div>
				<!-- /jumpto -->
								<!-- bodycontent -->
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="dablink">"Rapture of the nerds" redirects here. For the novel by Cory Doctorow and Charles Stross, see <a href="The_Rapture_of_the_Nerds" title="The Rapture of the Nerds">The Rapture of the Nerds</a>.</div>
<p>The <b>technological singularity</b> is the theoretical emergence of <a href="Superintelligence" title="Superintelligence">superintelligence</a> through technological means.<sup id="cite_ref-1" class="reference"><a href="#cite_note-1"><span>[</span>1<span>]</span></a></sup> Since the capabilities of such intelligence would be difficult for an unaided human mind to comprehend, the technological singularity is seen as an occurrence beyond which events cannot be predicted.</p>
<p>Proponents of the singularity typically state that an "intelligence explosion",<sup id="cite_ref-Singularity.2C_Intelligence_Explosion_2010_2-0" class="reference"><a href="#cite_note-Singularity.2C_Intelligence_Explosion_2010-2"><span>[</span>2<span>]</span></a></sup><sup id="cite_ref-3" class="reference"><a href="#cite_note-3"><span>[</span>3<span>]</span></a></sup> where superintelligences design successive generations of increasingly powerful minds, might occur very quickly and might not stop until the agent's cognitive abilities greatly surpass that of any human.</p>
<p>The term was popularized by science fiction writer <a href="Vernor_Vinge" title="Vernor Vinge">Vernor Vinge</a>, who argues that <a href="Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a>, <a href="Human_enhancement" title="Human enhancement">human biological enhancement</a>, or <a href="Brain%E2%80%93computer_interface" title="Brain–computer interface">brain-computer interfaces</a> could be possible causes of the singularity. The specific term "singularity" as a description for a phenomenon of technological acceleration causing an eventual unpredictable outcome in society was coined by mathematician <a href="John_von_Neumann" title="John von Neumann">John von Neumann</a>, who in the mid 1950s spoke of "ever accelerating progress of technology and changes in the mode of human life, which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs, as we know them, could not continue." The concept has also been popularized by futurists such as <a href="Ray_Kurzweil" title="Ray Kurzweil">Ray Kurzweil</a>, who cited von Neumann's use of the term in a foreword to von Neumann's classic <i><a href="The_Computer_and_the_Brain" title="The Computer and the Brain">The Computer and the Brain</a></i>.</p>
<p>Kurzweil predicts the singularity to occur around 2045 while Vinge predicts some time before 2030.</p>
<table id="toc" class="toc">
<tr>
<td>
<div id="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Basic_concepts"><span class="tocnumber">1</span> <span class="toctext">Basic concepts</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#History_of_the_idea"><span class="tocnumber">2</span> <span class="toctext">History of the idea</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Intelligence_explosion"><span class="tocnumber">3</span> <span class="toctext">Intelligence explosion</span></a>
<ul>
<li class="toclevel-2 tocsection-4"><a href="#Speed_improvements"><span class="tocnumber">3.1</span> <span class="toctext">Speed improvements</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#Intelligence_improvements"><span class="tocnumber">3.2</span> <span class="toctext">Intelligence improvements</span></a></li>
<li class="toclevel-2 tocsection-6"><a href="#Impact"><span class="tocnumber">3.3</span> <span class="toctext">Impact</span></a>
<ul>
<li class="toclevel-3 tocsection-7"><a href="#Existential_risk"><span class="tocnumber">3.3.1</span> <span class="toctext">Existential risk</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-8"><a href="#Implications_for_human_society"><span class="tocnumber">3.4</span> <span class="toctext">Implications for human society</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-9"><a href="#Accelerating_change"><span class="tocnumber">4</span> <span class="toctext">Accelerating change</span></a></li>
<li class="toclevel-1 tocsection-10"><a href="#Criticisms"><span class="tocnumber">5</span> <span class="toctext">Criticisms</span></a></li>
<li class="toclevel-1 tocsection-11"><a href="#In_popular_culture"><span class="tocnumber">6</span> <span class="toctext">In popular culture</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="#See_also"><span class="tocnumber">7</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-13"><a href="#Notes"><span class="tocnumber">8</span> <span class="toctext">Notes</span></a></li>
<li class="toclevel-1 tocsection-14"><a href="#References"><span class="tocnumber">9</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-15"><a href="#External_links"><span class="tocnumber">10</span> <span class="toctext">External links</span></a>
<ul>
<li class="toclevel-2 tocsection-16"><a href="#Essays_and_articles"><span class="tocnumber">10.1</span> <span class="toctext">Essays and articles</span></a></li>
<li class="toclevel-2 tocsection-17"><a href="#Singularity_AI_projects"><span class="tocnumber">10.2</span> <span class="toctext">Singularity AI projects</span></a></li>
<li class="toclevel-2 tocsection-18"><a href="#Fiction"><span class="tocnumber">10.3</span> <span class="toctext">Fiction</span></a></li>
<li class="toclevel-2 tocsection-19"><a href="#Other_links"><span class="tocnumber">10.4</span> <span class="toctext">Other links</span></a></li>
</ul>
</li>
</ul>
</td>
</tr>
</table>
<h2><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=1.php.html" title="Edit section: Basic concepts">edit</a>]</span> <span class="mw-headline" id="Basic_concepts">Basic concepts</span></h2>
<div class="thumb tright">
<div class="thumbinner" style="width:227px;"><a href="http://en.wikipedia.org/wiki/File:PPTMooresLawai.jpg" class="image"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/PPTMooresLawai.jpg/225px-PPTMooresLawai.jpg" width="225" height="226" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/c/c5/PPTMooresLawai.jpg/338px-PPTMooresLawai.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/c5/PPTMooresLawai.jpg/450px-PPTMooresLawai.jpg 2x" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="http://en.wikipedia.org/wiki/File:PPTMooresLawai.jpg" class="internal" title="Enlarge"><img src="http://bits.wikimedia.org/static-1.21wmf9/skins/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
<a href="Ray_Kurzweil" title="Ray Kurzweil">Kurzweil</a> writes that, due to <a href="Paradigm_shift" title="Paradigm shift">paradigm shifts</a>, a trend of exponential growth extends <a href="Moore's_law" title="Moore's law">Moore's law</a> to <a href="Integrated_circuits" title="Integrated circuits" class="mw-redirect">integrated circuits</a> from earlier <a href="Transistor" title="Transistor">transistors</a>, <a href="Vacuum_tube" title="Vacuum tube">vacuum tubes</a>, <a href="Relay" title="Relay">relays</a>, and <a href="Electromechanics" title="Electromechanics">electromechanical</a> computers. He predicts that the exponential growth will continue, and that in a few decades the computing power of all computers will exceed that of human brains, with superhuman <a href="Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> appearing around the same time.</div>
</div>
</div>
<p>Many of the most recognized writers on the singularity, such as Vernor Vinge and Ray Kurzweil, define the concept in terms of the technological creation of superintelligence, and argue that it is difficult or impossible for present-day humans to predict what a post-singularity would be like, due to the difficulty of imagining the intentions and capabilities of superintelligent entities.<sup id="cite_ref-vinge1993_4-0" class="reference"><a href="#cite_note-vinge1993-4"><span>[</span>4<span>]</span></a></sup><sup id="cite_ref-singularity_5-0" class="reference"><a href="#cite_note-singularity-5"><span>[</span>5<span>]</span></a></sup><sup id="cite_ref-singinst.org_6-0" class="reference"><a href="#cite_note-singinst.org-6"><span>[</span>6<span>]</span></a></sup> The term "technological singularity" was originally coined by Vinge, who made an analogy between the breakdown in our ability to predict what would happen after the development of superintelligence and the breakdown of the predictive ability of modern <a href="Physics" title="Physics">physics</a> at the <a href="Gravitational_singularity" title="Gravitational singularity">space-time singularity</a> beyond the <a href="Event_horizon" title="Event horizon">event horizon</a> of a <a href="Black_hole" title="Black hole">black hole</a>.<sup id="cite_ref-singinst.org_6-1" class="reference"><a href="#cite_note-singinst.org-6"><span>[</span>6<span>]</span></a></sup></p>
<p>Some writers use "the singularity" in a broader way to refer to any radical changes in our society brought about by new technologies such as <a href="Molecular_nanotechnology" title="Molecular nanotechnology">molecular nanotechnology</a>,<sup id="cite_ref-hplusmagazine_7-0" class="reference"><a href="#cite_note-hplusmagazine-7"><span>[</span>7<span>]</span></a></sup><sup id="cite_ref-yudkowsky.net_8-0" class="reference"><a href="#cite_note-yudkowsky.net-8"><span>[</span>8<span>]</span></a></sup><sup id="cite_ref-agi-conf_9-0" class="reference"><a href="#cite_note-agi-conf-9"><span>[</span>9<span>]</span></a></sup> although Vinge and other prominent writers specifically state that without superintelligence, such changes would not qualify as a true singularity.<sup id="cite_ref-vinge1993_4-1" class="reference"><a href="#cite_note-vinge1993-4"><span>[</span>4<span>]</span></a></sup> Many writers also tie the singularity to observations of exponential growth in various technologies (with <a href="Moore's_Law" title="Moore's Law" class="mw-redirect">Moore's Law</a> being the most prominent example), using such observations as a basis for predicting that the singularity is likely to happen sometime within the 21st century.<sup id="cite_ref-yudkowsky.net_8-1" class="reference"><a href="#cite_note-yudkowsky.net-8"><span>[</span>8<span>]</span></a></sup><sup id="cite_ref-kurzweilai.net_10-0" class="reference"><a href="#cite_note-kurzweilai.net-10"><span>[</span>10<span>]</span></a></sup></p>
<p>A technological singularity includes the concept of an intelligence explosion, a term coined in 1965 by <a href="../I._J._Good" title="I. J. Good">I. J. Good</a>.<sup id="cite_ref-stat_11-0" class="reference"><a href="#cite_note-stat-11"><span>[</span>11<span>]</span></a></sup> Although technological progress has been accelerating, it has been limited by the basic intelligence of the human brain, which has not, according to <a href="../Paul_R._Ehrlich" title="Paul R. Ehrlich">Paul R. Ehrlich</a>, changed significantly for millennia.<sup id="cite_ref-Paul_Ehrlich_June_2008_12-0" class="reference"><a href="#cite_note-Paul_Ehrlich_June_2008-12"><span>[</span>12<span>]</span></a></sup> However, with the increasing power of computers and other technologies, it might eventually be possible to build a machine that is more intelligent than humanity.<sup id="cite_ref-businessweek_13-0" class="reference"><a href="#cite_note-businessweek-13"><span>[</span>13<span>]</span></a></sup> If superhuman intelligences were invented, either through the <a href="Intelligence_amplification" title="Intelligence amplification">amplification of human intelligence</a> or artificial intelligence, it would bring to bear greater problem-solving and inventive skills than humans, then it could design a yet more capable machine, or re-write its source code to become more intelligent. This more capable machine could then go on to design a machine of even greater capability. These iterations of <a href="Seed_AI" title="Seed AI">recursive self-improvement</a> could accelerate, potentially allowing enormous qualitative change before any upper limits imposed by the laws of physics or theoretical computation set in.<sup id="cite_ref-ultraintelligent_14-0" class="reference"><a href="#cite_note-ultraintelligent-14"><span>[</span>14<span>]</span></a></sup><sup id="cite_ref-acceleratingfuture_15-0" class="reference"><a href="#cite_note-acceleratingfuture-15"><span>[</span>15<span>]</span></a></sup><sup id="cite_ref-ultraintelligent1_16-0" class="reference"><a href="#cite_note-ultraintelligent1-16"><span>[</span>16<span>]</span></a></sup></p>
<p>The exponential growth in computing technology suggested by Moore's Law is commonly cited as a reason to expect a singularity in the relatively near future, and a number of authors have proposed generalizations of Moore's Law. Computer scientist and futurist <a href="Hans_Moravec" title="Hans Moravec">Hans Moravec</a> proposed in a 1998 book that the exponential growth curve could be extended back through earlier computing technologies prior to the <a href="Integrated_circuit" title="Integrated circuit">integrated circuit</a>. Futurist Ray Kurzweil postulates a <a href="Law_of_accelerating_returns" title="Law of accelerating returns" class="mw-redirect">law of accelerating returns</a> in which the speed of technological change (and more generally, all evolutionary processes<sup id="cite_ref-google_17-0" class="reference"><a href="#cite_note-google-17"><span>[</span>17<span>]</span></a></sup>) increases exponentially, generalizing Moore's Law in the same manner as Moravec's proposal, and also including material technology (especially as applied to <a href="Nanotechnology" title="Nanotechnology">nanotechnology</a>), medical technology and others.<sup id="cite_ref-singularity2_18-0" class="reference"><a href="#cite_note-singularity2-18"><span>[</span>18<span>]</span></a></sup> Between 1986 and 2007, machines’ application-specific capacity to compute information per capita has roughly doubled every 14 months; the per capita capacity of the world’s general-purpose computers has doubled every 18 months; the global telecommunication capacity per capita doubled every 34 months; and the world’s storage capacity per capita required roughly 40 months to double (every 3 years). <sup id="cite_ref-HilbertLopez2011_19-0" class="reference"><a href="#cite_note-HilbertLopez2011-19"><span>[</span>19<span>]</span></a></sup> Like other authors, though, Kurzweil reserves the term "singularity" for a rapid increase in intelligence (as opposed to other technologies), writing for example that "The Singularity will allow us to transcend these limitations of our biological bodies and brains ... There will be no distinction, post-Singularity, between human and machine".<sup id="cite_ref-singularity3_20-0" class="reference"><a href="#cite_note-singularity3-20"><span>[</span>20<span>]</span></a></sup> He also defines his predicted date of the singularity (2045) in terms of when he expects computer-based intelligences to significantly exceed the sum total of human brainpower, writing that advances in computing before that date "will not represent the Singularity" because they do "not yet correspond to a profound expansion of our intelligence."<sup id="cite_ref-transformation_21-0" class="reference"><a href="#cite_note-transformation-21"><span>[</span>21<span>]</span></a></sup></p>
<p>The term "technological singularity" reflects the idea that such change may happen suddenly, and that it is difficult to predict how such a new world would operate.<sup id="cite_ref-positive-and-negative_22-0" class="reference"><a href="#cite_note-positive-and-negative-22"><span>[</span>22<span>]</span></a></sup><sup id="cite_ref-theuncertainfuture_23-0" class="reference"><a href="#cite_note-theuncertainfuture-23"><span>[</span>23<span>]</span></a></sup> It is unclear whether an intelligence explosion of this kind would be beneficial or harmful, or even an <a href="Existential_risk" title="Existential risk" class="mw-redirect">existential threat</a>,<sup id="cite_ref-catastrophic_24-0" class="reference"><a href="#cite_note-catastrophic-24"><span>[</span>24<span>]</span></a></sup><sup id="cite_ref-nickbostrom_25-0" class="reference"><a href="#cite_note-nickbostrom-25"><span>[</span>25<span>]</span></a></sup> as the issue has not been dealt with by most <a href="Artificial_general_intelligence" title="Artificial general intelligence" class="mw-redirect">artificial general intelligence</a> researchers, although the topic of <a href="Friendly_AI" title="Friendly AI" class="mw-redirect">friendly artificial intelligence</a> is investigated by the <a href="Singularity_Institute_for_Artificial_Intelligence" title="Singularity Institute for Artificial Intelligence" class="mw-redirect">Singularity Institute for Artificial Intelligence</a> and the <a href="Future_of_Humanity_Institute" title="Future of Humanity Institute">Future of Humanity Institute</a>.<sup id="cite_ref-positive-and-negative_22-1" class="reference"><a href="#cite_note-positive-and-negative-22"><span>[</span>22<span>]</span></a></sup></p>
<p>Many prominent technologists and academics dispute the plausibility of a technological singularity, including <a href="Jeff_Hawkins" title="Jeff Hawkins">Jeff Hawkins</a>, <a href="John_Henry_Holland" title="John Henry Holland">John Holland</a>, <a href="Jaron_Lanier" title="Jaron Lanier">Jaron Lanier</a>, and <a href="Gordon_Moore" title="Gordon Moore">Gordon Moore</a>, whose <a href="Moore's_Law" title="Moore's Law" class="mw-redirect">Moore's Law</a> is often cited in support of the concept.<sup id="cite_ref-spectrum.ieee.org_26-0" class="reference"><a href="#cite_note-spectrum.ieee.org-26"><span>[</span>26<span>]</span></a></sup><sup id="cite_ref-ieee_27-0" class="reference"><a href="#cite_note-ieee-27"><span>[</span>27<span>]</span></a></sup></p>
<h2><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=2.php.html" title="Edit section: History of the idea">edit</a>]</span> <span class="mw-headline" id="History_of_the_idea">History of the idea</span></h2>
<p>In 1847, R. Thornton, the editor of <i>The Expounder of Primitive Christianity</i>,<sup id="cite_ref-The_Expounder_of_Primitive_Christianity_28-0" class="reference"><a href="#cite_note-The_Expounder_of_Primitive_Christianity-28"><span>[</span>28<span>]</span></a></sup> wrote about the recent invention of a four function <a href="Mechanical_calculator" title="Mechanical calculator">mechanical calculator</a>:</p>
<blockquote class="templatequote">
<div class="Bug6200">...such machines, by which the scholar may, by turning a crank, grind out the solution of a problem without the fatigue of mental application, would by its introduction into schools, do incalculable injury. But who knows that such machines when brought to greater perfection, may not think of a plan to remedy all their own defects and then grind out ideas beyond the ken of mortal mind!</div>
</blockquote>
<p>In 1951, <a href="Alan_Turing" title="Alan Turing">Alan Turing</a> spoke of machines outstripping humans intellectually:<sup id="cite_ref-oxfordjournals_29-0" class="reference"><a href="#cite_note-oxfordjournals-29"><span>[</span>29<span>]</span></a></sup></p>
<blockquote class="templatequote">
<div class="Bug6200">once the machine thinking method has started, it would not take long to outstrip our feeble powers. ... At some stage therefore we should have to expect the machines to take control, in the way that is mentioned in <a href="Samuel_Butler_(novelist)" title="Samuel Butler (novelist)">Samuel Butler</a>'s <i><a href="Erewhon" title="Erewhon">Erewhon</a></i>.</div>
</blockquote>
<p>In the mid fifties <a href="Stanislaw_Ulam" title="Stanislaw Ulam">Stanislaw Ulam</a> had a conversation with <a href="John_von_Neumann" title="John von Neumann">John von Neumann</a> in which von Neumann spoke of "ever accelerating progress of technology and changes in the mode of human life, which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs, as we know them, could not continue."</p>
<p>In 1965, I. J. Good first wrote of an "intelligence explosion", suggesting that if machines could even slightly surpass human intellect, they could improve their own designs in ways unforeseen by their designers, and thus <a href="Recursion" title="Recursion">recursively</a> augment themselves into far greater intelligences. The first such improvements might be small, but as the machine became more intelligent it would become better at becoming more intelligent, which could lead to a cascade of self-improvements and a sudden surge to superintelligence (or a singularity).</p>
<p>In 1983, mathematician and author Vernor Vinge greatly popularized Good’s notion of an intelligence explosion in a number of writings, first addressing the topic in print in the January 1983 issue of <i><a href="Omni_(magazine)" title="Omni (magazine)">Omni</a></i> magazine. In this op-ed piece, Vinge seems to have been the first to use the term "singularity" in a way that was specifically tied to the creation of intelligent machines,<sup id="cite_ref-google4_30-0" class="reference"><a href="#cite_note-google4-30"><span>[</span>30<span>]</span></a></sup><sup id="cite_ref-technological_31-0" class="reference"><a href="#cite_note-technological-31"><span>[</span>31<span>]</span></a></sup> writing:</p>
<blockquote class="templatequote">
<div class="Bug6200">We will soon create intelligences greater than our own. When this happens, human history will have reached a kind of singularity, an intellectual transition as impenetrable as the knotted space-time at the center of a black hole, and the world will pass far beyond our understanding. This singularity, I believe, already haunts a number of science-fiction writers. It makes realistic extrapolation to an interstellar future impossible. To write a story set more than a century hence, one needs a nuclear war in between ... so that the world remains intelligible.</div>
</blockquote>
<p>In 1984, <a href="../Samuel_R._Delany" title="Samuel R. Delany">Samuel R. Delany</a> used "cultural fugue" as a plot device in his science fiction novel <i><a href="Stars_in_My_Pocket_Like_Grains_of_Sand" title="Stars in My Pocket Like Grains of Sand">Stars in My Pocket Like Grains of Sand</a></i>; the terminal runaway of technological and cultural complexity in effect destroys all life on any world on which it transpires, a process which is poorly understood by the novel's characters, and against which they seek a stable defense. In 1985 <a href="Ray_Solomonoff" title="Ray Solomonoff">Ray Solomonoff</a> introduced the notion of "infinity point"<sup id="cite_ref-std_32-0" class="reference"><a href="#cite_note-std-32"><span>[</span>32<span>]</span></a></sup> in the time scale of artificial intelligence, analyzed the magnitude of the "<a href="Future_shock" title="Future shock" class="mw-redirect">future shock</a>" that "we can expect from our AI expanded scientific community" and on social effects. Estimates were made "for when these milestones would occur, followed by some suggestions for the more effective utilization of the extremely rapid technological growth that is expected."</p>
<p>Vinge also popularized the concept in SF novels such as <i><a href="Marooned_in_Realtime" title="Marooned in Realtime">Marooned in Realtime</a></i> (1986) and <i><a href="A_Fire_Upon_the_Deep" title="A Fire Upon the Deep">A Fire Upon the Deep</a></i> (1992). The former is set in a world of rapidly <a href="Accelerating_change" title="Accelerating change">accelerating change</a> leading to the emergence of more and more sophisticated technologies separated by shorter and shorter time intervals, until a point beyond human comprehension is reached. The latter starts with an imaginative description of the evolution of a superintelligence passing through exponentially accelerating developmental stages ending in a <a href="Transcendence_(philosophy)" title="Transcendence (philosophy)">transcendent</a>, almost <a href="Omnipotent" title="Omnipotent" class="mw-redirect">omnipotent</a> power unfathomable by mere humans. It is also implied that the development does not stop at this level.</p>
<p>In his 1988 book <i>Mind Children</i>, computer scientist and futurist Hans Moravec generalizes Moore's law to make predictions about the future of artificial life. Moravec outlines a timeline and a scenario in this regard,<sup id="cite_ref-When_will_computer_hardware_match_the_human_brain.3F_33-0" class="reference"><a href="#cite_note-When_will_computer_hardware_match_the_human_brain.3F-33"><span>[</span>33<span>]</span></a></sup><sup id="cite_ref-The_Age_of_Robots_34-0" class="reference"><a href="#cite_note-The_Age_of_Robots-34"><span>[</span>34<span>]</span></a></sup> in that the robots will evolve into a new series of artificial species, starting around 2030–2040.<sup id="cite_ref-Robot_Predictions_Evolution_35-0" class="reference"><a href="#cite_note-Robot_Predictions_Evolution-35"><span>[</span>35<span>]</span></a></sup> In <i>Robot: Mere Machine to Transcendent Mind</i>, published in 1998, Moravec further considers the implications of evolving <a href="Robot_intelligence" title="Robot intelligence" class="mw-redirect">robot intelligence</a>, generalizing Moore's law to technologies predating the <a href="Integrated_circuit" title="Integrated circuit">integrated circuit</a>, and speculating about a coming "mind fire" of rapidly expanding superintelligence, similar to Vinge's ideas.</p>
<p>A 1993 article by Vinge, "The Coming Technological Singularity: How to Survive in the Post-Human Era",<sup id="cite_ref-vinge1993_4-2" class="reference"><a href="#cite_note-vinge1993-4"><span>[</span>4<span>]</span></a></sup> was widely disseminated on the internet and helped to popularize the idea.<sup id="cite_ref-google5_36-0" class="reference"><a href="#cite_note-google5-36"><span>[</span>36<span>]</span></a></sup> This article contains the oft-quoted statement, "Within thirty years, we will have the technological means to create superhuman intelligence. Shortly after, the human era will be ended." Vinge refines his estimate of the time scales involved, adding, "I'll be surprised if this event occurs before 2005 or after 2030."</p>
<p>Vinge predicted four ways the singularity could occur:<sup id="cite_ref-37" class="reference"><a href="#cite_note-37"><span>[</span>37<span>]</span></a></sup></p>
<ol>
<li>The development of computers that are "awake" and superhumanly intelligent.</li>
<li>Large computer networks (and their associated users) may "wake up" as a superhumanly intelligent entity.</li>
<li>Computer/human interfaces may become so intimate that users may reasonably be considered superhumanly intelligent.</li>
<li>Biological science may find ways to improve upon the natural human intellect.</li>
</ol>
<p>Vinge continues by predicting that superhuman intelligences will be able to enhance their own minds faster than their human creators. "When greater-than-human intelligence drives progress," Vinge writes, "that progress will be much more rapid." This <a href="Feedback_loop" title="Feedback loop" class="mw-redirect">feedback loop</a> of self-improving intelligence, he predicts, will cause large amounts of technological progress within a short period, and that the creation of superhuman intelligence represented a breakdown in humans' ability to model their future. His argument was that authors cannot write realistic characters who surpass the human intellect, as the thoughts of such an intellect would be beyond the ability of humans to express. Vinge named this event "the Singularity".</p>
<p><a href="Damien_Broderick" title="Damien Broderick">Damien Broderick</a>'s <a href="Popular_science" title="Popular science">popular science</a> book <a href="The_Spike_(1997)" title="The Spike (1997)">The Spike (1997)</a> was the first to investigate the technological singularity in detail.</p>
<p>In 2000, <a href="Bill_Joy" title="Bill Joy">Bill Joy</a>, a prominent technologist and founder of <a href="Sun_Microsystems" title="Sun Microsystems">Sun Microsystems</a>, voiced concern over the potential dangers of the singularity.<sup id="cite_ref-JoyFuture_38-0" class="reference"><a href="#cite_note-JoyFuture-38"><span>[</span>38<span>]</span></a></sup></p>
<p>In 2005, Ray Kurzweil published <i><a href="The_Singularity_is_Near" title="The Singularity is Near" class="mw-redirect">The Singularity is Near</a></i>, which brought the idea of the singularity to the popular media both through the book's accessibility and a publicity campaign that included an appearance on <i><a href="The_Daily_Show_with_Jon_Stewart" title="The Daily Show with Jon Stewart" class="mw-redirect">The Daily Show with Jon Stewart</a></i>.<sup id="cite_ref-episode_39-0" class="reference"><a href="#cite_note-episode-39"><span>[</span>39<span>]</span></a></sup> The book stirred intense controversy, in part because Kurzweil's <a href="Utopian" title="Utopian" class="mw-redirect">utopian</a> predictions contrasted starkly with other, darker visions of the possibilities of the singularity. Kurzweil, his theories, and the controversies surrounding it were the subject of <a href="Barry_Ptolemy" title="Barry Ptolemy">Barry Ptolemy</a>'s documentary <i><a href="Transcendent_Man_(film)" title="Transcendent Man (film)" class="mw-redirect">Transcendent Man</a></i>.</p>
<p>In 2007, <a href="Eliezer_Yudkowsky" title="Eliezer Yudkowsky">Eliezer Yudkowsky</a> suggested that many of the different definitions that have been assigned to "singularity" are mutually incompatible rather than mutually supporting.<sup id="cite_ref-yudkowsky.net_8-2" class="reference"><a href="#cite_note-yudkowsky.net-8"><span>[</span>8<span>]</span></a></sup> For example, Kurzweil extrapolates current technological trajectories past the arrival of self-improving AI or superhuman intelligence, which Yudkowsky argues represents a tension with both I. J. Good's proposed discontinuous upswing in intelligence and Vinge's thesis on unpredictability.</p>
<p>In 2008, <a href="Robin_Hanson" title="Robin Hanson">Robin Hanson</a> (taking "singularity" to refer to sharp increases in the exponent of economic growth) lists the <a href="Neolithic_Revolution" title="Neolithic Revolution">Agricultural</a> and <a href="Industrial_Revolution" title="Industrial Revolution">Industrial Revolutions</a> as past singularities. Extrapolating from such past events, Hanson proposes that the next economic singularity should increase <a href="Economic_growth" title="Economic growth">economic growth</a> between 60 and 250 times. An innovation that allowed for the replacement of virtually all human labor could trigger this event.<sup id="cite_ref-Hanson_40-0" class="reference"><a href="#cite_note-Hanson-40"><span>[</span>40<span>]</span></a></sup></p>
<p>In 2009, Kurzweil and <a href="X-Prize" title="X-Prize" class="mw-redirect">X-Prize</a> founder <a href="Peter_Diamandis" title="Peter Diamandis">Peter Diamandis</a> announced the establishment of <a href="Singularity_University" title="Singularity University">Singularity University</a>, whose stated mission is "to assemble, educate and inspire a cadre of leaders who strive to understand and facilitate the development of exponentially advancing technologies in order to address humanity’s grand challenges."<sup id="cite_ref-singularityu_41-0" class="reference"><a href="#cite_note-singularityu-41"><span>[</span>41<span>]</span></a></sup> Funded by <a href="Google" title="Google">Google</a>, <a href="Autodesk" title="Autodesk">Autodesk</a>, <a href="EPlanet_Ventures" title="EPlanet Ventures" class="mw-redirect">ePlanet Ventures</a>, and a group of technology industry leaders, Singularity University is based at <a href="NASA" title="NASA">NASA</a>'s <a href="NASA_Ames_Research_Center" title="NASA Ames Research Center" class="mw-redirect">Ames Research Center</a> in <a href="Mountain_View,_California" title="Mountain View, California">Mountain View</a>, <a href="California" title="California">California</a>. The not-for-profit organization runs an annual ten-week graduate program during the summer that covers ten different technology and allied tracks, and a series of executive programs throughout the year.</p>
<p>In 2010, <a href="Aubrey_de_Grey" title="Aubrey de Grey">Aubrey de Grey</a> applied the term the "<a href="Methuselah#Use_of_the_word_in_modern_life" title="Methuselah">Methuselarity</a>"<sup id="cite_ref-sens_42-0" class="reference"><a href="#cite_note-sens-42"><span>[</span>42<span>]</span></a></sup> to the point at which medical technology improves so fast that <a href="Life_expectancy" title="Life expectancy">expected human lifespan</a> increases by more than one year per year. In 2010 in "Apocalyptic AI – Visions of Heaven in Robotics, Artificial Intelligence, and Virtual Reality"<sup id="cite_ref-Apocalyptic_AI_-_Visions_of_Heaven_in_Robotics.2C_Artificial_Intelligence.2C_and_Virtual_Reality_43-0" class="reference"><a href="#cite_note-Apocalyptic_AI_-_Visions_of_Heaven_in_Robotics.2C_Artificial_Intelligence.2C_and_Virtual_Reality-43"><span>[</span>43<span>]</span></a></sup> Robert Geraci offers an account of the developing "cyber-theology" inspired by Singularity studies. A book exploring some of those themes is the 1996 <i><a href="Holy_Fire_(novel)" title="Holy Fire (novel)">Holy Fire</a></i> by Bruce Sterling, which postulates that a Methuselarity will become a <a href="Gerontocracy" title="Gerontocracy">gerontocracy</a>.</p>
<p>In 2011, Kurzweil noted existing trends and concluded that the singularity was becoming more probable to occur around 2045. He told <i>Time</i> magazine: "We will successfully reverse-engineer the human brain by the mid-2020s. By the end of that decade, computers will be capable of human-level intelligence."<sup id="cite_ref-time_44-0" class="reference"><a href="#cite_note-time-44"><span>[</span>44<span>]</span></a></sup></p>
<h2><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=3.php.html" title="Edit section: Intelligence explosion">edit</a>]</span> <span class="mw-headline" id="Intelligence_explosion">Intelligence explosion</span></h2>
<p>The notion of an "intelligence explosion" was first described thus by <a href="#CITEREFGood1965">Good (1965</a>), who speculated on the effects of superhuman machines:</p>
<blockquote class="templatequote">
<div class="Bug6200">Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make.</div>
</blockquote>
<p>Most proposed methods for creating superhuman or <a href="Transhuman" title="Transhuman">transhuman</a> minds fall into one of two categories: intelligence amplification of human brains and artificial intelligence. The means speculated to produce intelligence augmentation are numerous, and include <a href="Bioengineering" title="Bioengineering" class="mw-redirect">bioengineering</a>, <a href="Genetic_engineering" title="Genetic engineering">genetic engineering</a>, <a href="Nootropic" title="Nootropic">nootropic</a> drugs, AI assistants, direct brain-computer interfaces and <a href="Mind_uploading" title="Mind uploading">mind uploading</a>. The existence of multiple paths to an intelligence explosion makes a singularity more likely; for a singularity to not occur they would all have to fail.<sup id="cite_ref-singinst.org_6-2" class="reference"><a href="#cite_note-singinst.org-6"><span>[</span>6<span>]</span></a></sup></p>
<p><a href="#CITEREFHanson1998">Hanson (1998</a>) is skeptical of human intelligence augmentation, writing that once one has exhausted the "low-hanging fruit" of easy methods for increasing human intelligence, further improvements will become increasingly difficult to find. Despite the numerous speculated means for amplifying human intelligence, non-human artificial intelligence (specifically <a href="Seed_AI" title="Seed AI">seed AI</a>) is the most popular option for organizations trying to advance the singularity.<sup class="Template-Fact" style="white-space:nowrap;">[<i><a href="Wikipedia_Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources from July 2012">citation needed</span></a></i>]</sup></p>
<p>Whether or not an intelligence explosion occurs depends on three factors.<sup id="cite_ref-david_chalmers_singularity_lecture_resources_available_45-0" class="reference"><a href="#cite_note-david_chalmers_singularity_lecture_resources_available-45"><span>[</span>45<span>]</span></a></sup> The first, accelerating factor, is the new intelligence enhancements made possible by each previous improvement. Contrariwise, as the intelligences become more advanced, further advances will become more and more complicated, possibly overcoming the advantage of increased intelligence. Each improvement must be able to beget at least one more improvement, on average, for the singularity to continue. Finally, there is the issue of a hard upper limit. Absent <a href="Quantum_computer" title="Quantum computer">quantum computing</a>, eventually the laws of physics will prevent any further improvements.</p>
<p>There are two logically independent, but mutually reinforcing, accelerating effects: increases in the speed of computation, and improvements to the <a href="Algorithm" title="Algorithm">algorithms</a> used.<sup id="cite_ref-consc.net_46-0" class="reference"><a href="#cite_note-consc.net-46"><span>[</span>46<span>]</span></a></sup> The former is predicted by Moore’s Law and the forecast improvements in hardware,<sup id="cite_ref-itrs_47-0" class="reference"><a href="#cite_note-itrs-47"><span>[</span>47<span>]</span></a></sup> and is comparatively similar to previous technological advance. On the other hand, most AI researchers believe that software is more important than hardware.<sup class="Template-Fact" style="white-space:nowrap;">[<i><a href="Wikipedia_Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources from July 2012">citation needed</span></a></i>]</sup></p>
<h3><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=4.php.html" title="Edit section: Speed improvements">edit</a>]</span> <span class="mw-headline" id="Speed_improvements">Speed improvements</span></h3>
<p>The first is the improvements to the speed at which minds can be run. Whether human or AI, better hardware increases the rate of future hardware improvements. Oversimplified,<sup id="cite_ref-arstechnica_48-0" class="reference"><a href="#cite_note-arstechnica-48"><span>[</span>48<span>]</span></a></sup> Moore's Law suggests that if the first doubling of speed took 18 months, the second would take 18 subjective months; or 9 external months, whereafter, four months, two months, and so on towards a speed singularity.<sup id="cite_ref-singularity6_49-0" class="reference"><a href="#cite_note-singularity6-49"><span>[</span>49<span>]</span></a></sup> An upper limit on speed may eventually be reached, although it is unclear how high this would be. <a href="#CITEREFHawkins2008">Hawkins (2008</a>), responding to Good, argued that the upper limit is relatively low;</p>
<blockquote class="templatequote">
<div class="Bug6200">Belief in this idea is based on a naive understanding of what intelligence is. As an analogy, imagine we had a computer that could design new computers (chips, systems, and software) faster than itself. Would such a computer lead to infinitely fast computers or even computers that were faster than anything humans could ever build? No. It might accelerate the rate of improvements for a while, but in the end there are limits to how big and fast computers can run. We would end up in the same place; we'd just get there a bit faster. There would be no singularity.<br />
Whereas if it were a lot higher than current human levels of intelligence, the effects of the singularity would be enormous enough as to be indistinguishable (to humans) from a singularity with an upper limit. For example, if the speed of thought could be increased a million-fold, a subjective year would pass in 30 physical seconds.<sup id="cite_ref-singinst.org_6-3" class="reference"><a href="#cite_note-singinst.org-6"><span>[</span>6<span>]</span></a></sup></div>
</blockquote>
<p>It is difficult to directly compare <a href="Silicon" title="Silicon">silicon</a>-based hardware with <a href="Neuron" title="Neuron">neurons</a>. But <a href="#CITEREFBerglas2008">Berglas (2008</a>) notes that computer <a href="Speech_recognition" title="Speech recognition">speech recognition</a> is approaching human capabilities, and that this capability seems to require 0.01% of the volume of the brain. This analogy suggests that modern computer hardware is within a few orders of magnitude of being as powerful as the human brain.</p>
<h3><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=5.php.html" title="Edit section: Intelligence improvements">edit</a>]</span> <span class="mw-headline" id="Intelligence_improvements">Intelligence improvements</span></h3>
<p>Some intelligence technologies, like seed AI, may also have the potential to make themselves more intelligent, not just faster, by modifying their <a href="Source_code" title="Source code">source code</a>. These improvements would make further improvements possible, which would make further improvements possible, and so on.</p>
<p>This mechanism for an intelligence explosion differs from an increase in speed in two ways. First, it does not require external effect: machines designing faster hardware still require humans to create the improved hardware, or to program factories appropriately. An AI which was rewriting its own source code, however, could do so while contained in an <a href="AI_box" title="AI box">AI box</a>.</p>
<p>Second, as with Vernor Vinge’s conception of the singularity, it is much harder to predict the outcome. While speed increases seem to be only a quantitative difference from human intelligence, actual improvements in intelligence would be qualitatively different. Eliezer Yudkowsky compares it to the changes that human intelligence brought: humans changed the world thousands of times more rapidly than evolution had done, and in totally different ways. Similarly, the evolution of life had been a massive departure and acceleration from the previous geological rates of change, and improved intelligence could cause change to be as different again.<sup id="cite_ref-yudkowsky_50-0" class="reference"><a href="#cite_note-yudkowsky-50"><span>[</span>50<span>]</span></a></sup></p>
<p>There are substantial dangers associated with an intelligence explosion singularity. First, the goal structure of the AI may not be invariant under self-improvement, potentially causing the AI to optimise for something other than was intended.<sup id="cite_ref-selfawaresystems_51-0" class="reference"><a href="#cite_note-selfawaresystems-51"><span>[</span>51<span>]</span></a></sup><sup id="cite_ref-kurzweilai_52-0" class="reference"><a href="#cite_note-kurzweilai-52"><span>[</span>52<span>]</span></a></sup> Secondly, AIs could compete for the scarce resources mankind uses to survive.<sup id="cite_ref-selfawaresystems.com_53-0" class="reference"><a href="#cite_note-selfawaresystems.com-53"><span>[</span>53<span>]</span></a></sup></p>
<p>While not actively malicious, there is no reason to think that AIs would actively promote human goals unless they could be programmed as such, and if not, might use the resources currently used to support mankind to promote its own goals, causing human extinction.<sup id="cite_ref-kurzweilai.net_10-1" class="reference"><a href="#cite_note-kurzweilai.net-10"><span>[</span>10<span>]</span></a></sup><sup id="cite_ref-ReferenceB_54-0" class="reference"><a href="#cite_note-ReferenceB-54"><span>[</span>54<span>]</span></a></sup><sup id="cite_ref-nickbostrom7_55-0" class="reference"><a href="#cite_note-nickbostrom7-55"><span>[</span>55<span>]</span></a></sup></p>
<h3><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=6.php.html" title="Edit section: Impact">edit</a>]</span> <span class="mw-headline" id="Impact">Impact</span></h3>
<p>Dramatic changes in the rate of economic growth have occurred in the past because of some technological advancement. Based on population growth, the economy doubled every 250,000 years from the <a href="Paleolithic" title="Paleolithic">Paleolithic</a> era until the <a href="Neolithic_Revolution" title="Neolithic Revolution">Neolithic Revolution</a>. This new agricultural economy began to double every 900 years, a remarkable increase. In the current era, beginning with the Industrial Revolution, the world’s economic output doubles every fifteen years, sixty times faster than during the agricultural era. If the rise of superhuman intelligence causes a similar revolution, argues Robin Hanson, one would expect the economy to double at least quarterly and possibly on a weekly basis.<sup id="cite_ref-Hanson_40-1" class="reference"><a href="#cite_note-Hanson-40"><span>[</span>40<span>]</span></a></sup></p>
<h4><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=7.php.html" title="Edit section: Existential risk">edit</a>]</span> <span class="mw-headline" id="Existential_risk">Existential risk</span></h4>
<p><a href="#CITEREFBerglas2008">Berglas (2008</a>) notes that there is no direct evolutionary motivation for an AI to be friendly to humans. Evolution has no inherent tendency to produce outcomes valued by humans, and there is little reason to expect an arbitrary optimisation process to promote an outcome desired by mankind, rather than inadvertently leading to an AI behaving in a way not intended by its creators (such as Nick Bostrom's whimsical example of an AI which was originally programmed with the goal of manufacturing paper clips, so that when it achieves superintelligence it decides to convert the entire planet into a paper clip manufacturing facility;<sup id="cite_ref-nickbostrom8_56-0" class="reference"><a href="#cite_note-nickbostrom8-56"><span>[</span>56<span>]</span></a></sup><sup id="cite_ref-singinst_57-0" class="reference"><a href="#cite_note-singinst-57"><span>[</span>57<span>]</span></a></sup><sup id="cite_ref-singinst9_58-0" class="reference"><a href="#cite_note-singinst9-58"><span>[</span>58<span>]</span></a></sup> <a href="Anders_Sandberg" title="Anders Sandberg">Anders Sandberg</a> has also elaborated on this scenario, addressing various common counter-arguments.<sup id="cite_ref-aleph_59-0" class="reference"><a href="#cite_note-aleph-59"><span>[</span>59<span>]</span></a></sup>) AI researcher <a href="Hugo_de_Garis" title="Hugo de Garis">Hugo de Garis</a> suggests that artificial intelligences may simply eliminate the human race for access to scarce resources,<sup id="cite_ref-selfawaresystems.com_53-1" class="reference"><a href="#cite_note-selfawaresystems.com-53"><span>[</span>53<span>]</span></a></sup><sup id="cite_ref-selfawaresystems10_60-0" class="reference"><a href="#cite_note-selfawaresystems10-60"><span>[</span>60<span>]</span></a></sup> and humans would be powerless to stop them.<sup id="cite_ref-forbes_61-0" class="reference"><a href="#cite_note-forbes-61"><span>[</span>61<span>]</span></a></sup> Alternatively, AIs developed under evolutionary pressure to promote their own survival could outcompete humanity.<sup id="cite_ref-nickbostrom7_55-1" class="reference"><a href="#cite_note-nickbostrom7-55"><span>[</span>55<span>]</span></a></sup></p>
<p><a href="#CITEREFBostrom2002">Bostrom (2002</a>) discusses human extinction scenarios, and lists superintelligence as a possible cause:</p>
<blockquote class="templatequote">
<div class="Bug6200">When we create the first superintelligent entity, we might make a mistake and give it goals that lead it to annihilate humankind, assuming its enormous intellectual advantage gives it the power to do so. For example, we could mistakenly elevate a subgoal to the status of a supergoal. We tell it to solve a mathematical problem, and it complies by turning all the matter in the solar system into a giant calculating device, in the process killing the person who asked the question.</div>
</blockquote>
<p>A significant problem is that unfriendly artificial intelligence is likely to be much easier to create than friendly AI. While both require large advances in recursive optimisation process design, friendly AI also requires the ability to make goal structures invariant under self-improvement (or the AI could transform itself into something unfriendly) and a goal structure that aligns with human values and does not automatically destroy the human race. An unfriendly AI, on the other hand, can optimize for an arbitrary goal structure, which does not need to be invariant under self-modification.<sup id="cite_ref-singinst12_62-0" class="reference"><a href="#cite_note-singinst12-62"><span>[</span>62<span>]</span></a></sup></p>
<p><a href="Eliezer_Yudkowsky" title="Eliezer Yudkowsky">Eliezer Yudkowsky</a> proposed that research be undertaken to produce <a href="Friendly_artificial_intelligence" title="Friendly artificial intelligence">friendly artificial intelligence</a> in order to address the dangers. He noted that the first real AI would have a head start on self-improvement and, if friendly, could prevent unfriendly AIs from developing, as well as providing enormous benefits to mankind.<sup id="cite_ref-ReferenceB_54-1" class="reference"><a href="#cite_note-ReferenceB-54"><span>[</span>54<span>]</span></a></sup></p>
<p><a href="Bill_Hibbard" title="Bill Hibbard">Bill Hibbard</a> also addresses issues of AI safety and morality in his book <i><a href="Super-Intelligent_Machines" title="Super-Intelligent Machines" class="mw-redirect">Super-Intelligent Machines</a></i>. These ideas were refined in 2008<sup id="cite_ref-JET2008_63-0" class="reference"><a href="#cite_note-JET2008-63"><span>[</span>63<span>]</span></a></sup> and revised in 2012<sup id="cite_ref-JAGI2012_64-0" class="reference"><a href="#cite_note-JAGI2012-64"><span>[</span>64<span>]</span></a></sup><sup id="cite_ref-AGI-12a_65-0" class="reference"><a href="#cite_note-AGI-12a-65"><span>[</span>65<span>]</span></a></sup><sup id="cite_ref-AGI-12b_66-0" class="reference"><a href="#cite_note-AGI-12b-66"><span>[</span>66<span>]</span></a></sup>.</p>
<p>One hypothetical approach towards attempting to control an artificial intelligence is an <a href="AI_box" title="AI box">AI box</a>, where the artificial intelligence is kept constrained inside a <a href="Computer_simulation" title="Computer simulation">simulated world</a> and not allowed to affect the external world. However, a sufficiently intelligent AI may simply be able to escape by outsmarting its less intelligent human captors.<sup id="cite_ref-positive-and-negative_22-2" class="reference"><a href="#cite_note-positive-and-negative-22"><span>[</span>22<span>]</span></a></sup><sup id="cite_ref-berglas_67-0" class="reference"><a href="#cite_note-berglas-67"><span>[</span>67<span>]</span></a></sup><sup id="cite_ref-philosophical_68-0" class="reference"><a href="#cite_note-philosophical-68"><span>[</span>68<span>]</span></a></sup></p>
<h3><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=8.php.html" title="Edit section: Implications for human society">edit</a>]</span> <span class="mw-headline" id="Implications_for_human_society">Implications for human society</span></h3>
<p>In 2009, leading computer scientists, artificial intelligence researchers, and roboticists met at the Asilomar Conference Grounds near <a href="Monterey_Bay" title="Monterey Bay">Monterey Bay</a> in California. The goal was to discuss the potential impact of the hypothetical possibility that robots could become self-sufficient and able to make their own decisions. They discussed the extent to which computers and robots might be able to acquire <a href="Autonomy" title="Autonomy">autonomy</a>, and to what degree they could use such abilities to pose threats or hazards.</p>
<p>Some machines have acquired various forms of semi-autonomy, including the ability to locate their own power sources and choose targets to attack with weapons. Also, some <a href="Computer_viruses" title="Computer viruses" class="mw-redirect">computer viruses</a> can evade elimination and have achieved "cockroach intelligence."<sup class="Template-Fact" style="white-space:nowrap;">[<i><a href="Wikipedia_Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources from July 2012">citation needed</span></a></i>]</sup> The conference attendees noted that self-awareness as depicted in science-fiction is probably unlikely, but that other potential hazards and pitfalls exist.<sup id="cite_ref-nytimes_july09_69-0" class="reference"><a href="#cite_note-nytimes_july09-69"><span>[</span>69<span>]</span></a></sup></p>
<p>Some experts and academics have questioned the use of <a href="Robot" title="Robot">robots</a> for military combat, especially when such robots are given some degree of autonomous functions.<sup id="cite_ref-palmer_70-0" class="reference"><a href="#cite_note-palmer-70"><span>[</span>70<span>]</span></a></sup> A <a href="United_States_Navy" title="United States Navy">United States Navy</a> report indicates that, as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions.<sup id="cite_ref-dailytech_71-0" class="reference"><a href="#cite_note-dailytech-71"><span>[</span>71<span>]</span></a></sup><sup id="cite_ref-engadget_72-0" class="reference"><a href="#cite_note-engadget-72"><span>[</span>72<span>]</span></a></sup></p>
<p>The <a href="Association_for_the_Advancement_of_Artificial_Intelligence" title="Association for the Advancement of Artificial Intelligence">Association for the Advancement of Artificial Intelligence</a> has commissioned a study to examine this issue,<sup id="cite_ref-microsoft_73-0" class="reference"><a href="#cite_note-microsoft-73"><span>[</span>73<span>]</span></a></sup> pointing to programs like the <a href="Language_Acquisition_Device_(computer)" title="Language Acquisition Device (computer)">Language Acquisition Device</a>, which can emulate human interaction.</p>
<p>Some support the design of friendly artificial intelligence, meaning that the advances which are already occurring with AI should also include an effort to make AI intrinsically friendly and humane.<sup id="cite_ref-asimovlaws_74-0" class="reference"><a href="#cite_note-asimovlaws-74"><span>[</span>74<span>]</span></a></sup></p>
<p><a href="Isaac_Asimov" title="Isaac Asimov">Isaac Asimov</a>'s <a href="Three_Laws_of_Robotics" title="Three Laws of Robotics">Three Laws of Robotics</a> is one of the earliest examples of proposed safety measures for AI. The laws are intended to prevent artificially intelligent robots from harming humans. In Asimov’s stories, any perceived problems with the laws tend to arise as a result of a misunderstanding on the part of some human operator; the robots themselves are merely acting to their best interpretation of their rules. In the <a href="2004_in_film" title="2004 in film">2004</a> film <i><a href="I,_Robot_(film)" title="I, Robot (film)">I, Robot</a></i>, loosely based on Asimov's <a href="Robot_series_(Asimov)" title="Robot series (Asimov)"><i>Robot</i> stories</a>, an AI attempts to take complete control over humanity for the purpose of protecting humanity from itself due to <a href="Zeroth_Law" title="Zeroth Law" class="mw-redirect">an extrapolation of the Three Laws</a>. In 2004, the Singularity Institute launched an Internet campaign called <i>3 Laws Unsafe</i> to raise awareness of AI safety issues and the inadequacy of Asimov’s laws in particular.<sup id="cite_ref-75" class="reference"><a href="#cite_note-75"><span>[</span>75<span>]</span></a></sup></p>
<h2><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=9.php.html" title="Edit section: Accelerating change">edit</a>]</span> <span class="mw-headline" id="Accelerating_change">Accelerating change</span></h2>
<div class="thumb tright">
<div class="thumbinner" style="width:197px;"><a href="http://en.wikipedia.org/wiki/File:ParadigmShiftsFrr15Events.svg" class="image"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/45/ParadigmShiftsFrr15Events.svg/195px-ParadigmShiftsFrr15Events.svg.png" width="195" height="152" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/4/45/ParadigmShiftsFrr15Events.svg/293px-ParadigmShiftsFrr15Events.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/45/ParadigmShiftsFrr15Events.svg/390px-ParadigmShiftsFrr15Events.svg.png 2x" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="http://en.wikipedia.org/wiki/File:ParadigmShiftsFrr15Events.svg" class="internal" title="Enlarge"><img src="http://bits.wikimedia.org/static-1.21wmf9/skins/common/images/magnify-clip.png" width="15" height="11" alt="" /></a></div>
According to Kurzweil, his <a href="Logarithmic_scale" title="Logarithmic scale">logarithmic graph</a> of 15 lists of <a href="Paradigm_shift" title="Paradigm shift">paradigm shifts</a> for key <a href="Human_history" title="Human history" class="mw-redirect">historic</a> events shows an <a href="Exponential_growth" title="Exponential growth">exponential</a> trend. The lists' compilers include <a href="Carl_Sagan" title="Carl Sagan">Carl Sagan</a><sup class="Template-Fact" style="white-space:nowrap;">[<i><a href="Wikipedia_Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources from November 2010">citation needed</span></a></i>]</sup>, <a href="../Paul_D._Boyer" title="Paul D. Boyer">Paul D. Boyer</a>, <i><a href="Encyclop%C3%A6dia_Britannica" title="Encyclopædia Britannica">Encyclopædia Britannica</a></i>, <a href="American_Museum_of_Natural_History" title="American Museum of Natural History">American Museum of Natural History</a>, and <a href="University_of_Arizona" title="University of Arizona">University of Arizona</a>. Click to enlarge.</div>
</div>
</div>
<div class="rellink relarticle mainarticle">Main article: <a href="Accelerating_change" title="Accelerating change">Accelerating change</a></div>
<p>Some singularity proponents argue its inevitability through extrapolation of past trends, especially those pertaining to shortening gaps between improvements to technology. In one of the first uses of the term "singularity" in the context of technological progress, Stanislaw <a href="#CITEREFUlam1958">Ulam (1958</a>) tells of a conversation with <a href="John_von_Neumann" title="John von Neumann">John von Neumann</a> about accelerating change:</p>
<blockquote class="templatequote">
<div class="Bug6200">One conversation centered on the ever accelerating progress of technology and changes in the mode of human life, which gives the appearance of approaching some essential singularity in the history of the race beyond which human affairs, as we know them, could not continue.</div>
</blockquote>
<p><a href="#CITEREFHawkins1983">Hawkins (1983</a>) writes that "mindsteps", dramatic and irreversible changes to paradigms or world views, are accelerating in frequency as quantified in his mindstep equation. He cites the inventions of writing, mathematics, and the computer as examples of such changes.</p>
<p>Kurzweil's analysis of history concludes that technological progress follows a pattern of <a href="Exponential_growth" title="Exponential growth">exponential growth</a>, following what he calls the "<a href="Accelerating_change#Kurzweil.27s_The_Law_of_Accelerating_Returns" title="Accelerating change">Law of Accelerating Returns</a>". Whenever technology approaches a barrier, Kurzweil writes, new technologies will surmount it. He predicts <a href="Paradigm_shift" title="Paradigm shift">paradigm shifts</a> will become increasingly common, leading to "technological change so rapid and profound it represents a rupture in the fabric of human history".<sup id="cite_ref-76" class="reference"><a href="#cite_note-76"><span>[</span>76<span>]</span></a></sup> Kurzweil believes that the singularity will occur before the end of the 21st century, setting the <a href="Predictions_made_by_Raymond_Kurzweil#2045:_The_Singularity" title="Predictions made by Raymond Kurzweil" class="mw-redirect">date at 2045</a>.<sup id="cite_ref-77" class="reference"><a href="#cite_note-77"><span>[</span>77<span>]</span></a></sup> His predictions differ from Vinge’s in that he predicts a gradual ascent to the singularity, rather than Vinge’s rapidly self-improving superhuman intelligence.</p>
<p>Presumably, a technological singularity would lead to rapid development of a <a href="Kardashev_scale" title="Kardashev scale">Kardashev Type I civilization</a>, one that has achieved mastery of the resources of its home planet.<sup id="cite_ref-civilization_78-0" class="reference"><a href="#cite_note-civilization-78"><span>[</span>78<span>]</span></a></sup></p>
<p>Oft-cited dangers include those commonly associated with molecular nanotechnology and genetic engineering. These threats are major issues for both singularity advocates and critics, and were the subject of Bill Joy's <i><a href="Wired_(magazine)" title="Wired (magazine)">Wired</a></i> magazine article "<a href="Why_the_future_doesn't_need_us" title="Why the future doesn't need us" class="mw-redirect">Why the future doesn't need us</a>".<sup id="cite_ref-79" class="reference"><a href="#cite_note-79"><span>[</span>79<span>]</span></a></sup></p>
<p>The <a href="Acceleration_Studies_Foundation" title="Acceleration Studies Foundation">Acceleration Studies Foundation</a>, an educational non-profit foundation founded by <a href="John_Smart_(futurist)" title="John Smart (futurist)">John Smart</a>, engages in outreach, education, research and advocacy concerning accelerating change.<sup id="cite_ref-80" class="reference"><a href="#cite_note-80"><span>[</span>80<span>]</span></a></sup> It produces the Accelerating Change conference at Stanford University, and maintains the educational site <a rel="nofollow" class="external text" href="http://www.accelerationwatch.com/">Acceleration Watch</a>.</p>
<h2><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=10.php.html" title="Edit section: Criticisms">edit</a>]</span> <span class="mw-headline" id="Criticisms">Criticisms</span></h2>
<p>Some critics assert that no computer or machine will ever achieve human intelligence, while others hold that the definition of intelligence is irrelevant if the net result is the same.<sup id="cite_ref-dreyfus_81-0" class="reference"><a href="#cite_note-dreyfus-81"><span>[</span>81<span>]</span></a></sup></p>
<p><a href="Steven_Pinker" title="Steven Pinker">Steven Pinker</a> stated in 2008,</p>
<blockquote class="templatequote">
<div class="Bug6200">"(...) There is not the slightest reason to believe in a coming singularity. The fact that you can visualize a future in your imagination is not evidence that it is likely or even possible. Look at domed cities, jet-pack commuting, underwater cities, mile-high buildings, and nuclear-powered automobiles—all staples of futuristic fantasies when I was a child that have never arrived. Sheer processing power is not a pixie dust that magically solves all your problems. (...)"<sup id="cite_ref-spectrum.ieee.org_26-1" class="reference"><a href="#cite_note-spectrum.ieee.org-26"><span>[</span>26<span>]</span></a></sup></div>
</blockquote>
<p>Martin Ford in <i>The Lights in the Tunnel: Automation, Accelerating Technology and the Economy of the Future</i><sup id="cite_ref-thelightsinthetunnel_82-0" class="reference"><a href="#cite_note-thelightsinthetunnel-82"><span>[</span>82<span>]</span></a></sup> postulates a "technology paradox" in that before the singularity could occur most routine jobs in the economy would be automated, since this would require a level of technology inferior to that of the singularity. This would cause massive unemployment and plummeting consumer demand, which in turn would destroy the incentive to invest in the technologies that would be required to bring about the Singularity. Job displacement is increasingly no longer limited to work traditionally considered to be "routine."<sup id="cite_ref-nytimes_83-0" class="reference"><a href="#cite_note-nytimes-83"><span>[</span>83<span>]</span></a></sup></p>
<p><a href="Jared_Diamond" title="Jared Diamond">Jared Diamond</a>, in <i><a href="Collapse__How_Societies_Choose_to_Fail_or_Succeed" title="Collapse: How Societies Choose to Fail or Succeed">Collapse: How Societies Choose to Fail or Succeed</a></i>, argues that cultures self-limit when they exceed the sustainable carrying capacity of their environment, and the consumption of strategic resources (frequently timber, soils or water) creates a deleterious positive feedback loop that leads eventually to social collapse and technological retrogression.</p>
<p><a href="Theodore_Modis" title="Theodore Modis">Theodore Modis</a><sup id="cite_ref-google13_84-0" class="reference"><a href="#cite_note-google13-84"><span>[</span>84<span>]</span></a></sup><sup id="cite_ref-Singularity_Myth_85-0" class="reference"><a href="#cite_note-Singularity_Myth-85"><span>[</span>85<span>]</span></a></sup> and <a href="Jonathan_Huebner" title="Jonathan Huebner">Jonathan Huebner</a><sup id="cite_ref-technological14_86-0" class="reference"><a href="#cite_note-technological14-86"><span>[</span>86<span>]</span></a></sup> argue that the rate of technological innovation has not only ceased to rise, but is actually now declining (<a href="John_Smart_(futurist)" title="John Smart (futurist)">John Smart</a>, however, criticizes Huebner's analysis<sup id="cite_ref-accelerating_87-0" class="reference"><a href="#cite_note-accelerating-87"><span>[</span>87<span>]</span></a></sup>). Evidence for this decline is that the rise in computer <a href="Clock_rate" title="Clock rate">clock rates</a> is slowing, even while Moore's prediction of exponentially increasing circuit density continues to hold. This is due to excessive heat build-up from the chip, which cannot be dissipated quickly enough to prevent the chip from melting when operating at higher speeds. Advancements in speed may be possible in the future by virtue of more power-efficient CPU designs and multi-cell processors.<sup id="cite_ref-cnet_88-0" class="reference"><a href="#cite_note-cnet-88"><span>[</span>88<span>]</span></a></sup> While Kurzweil used Modis' resources, and Modis' work was around accelerating change, Modis distanced himself from Kurzweil's thesis of a "technological singularity", claiming that it lacks scientific rigor.<sup id="cite_ref-Singularity_Myth_85-1" class="reference"><a href="#cite_note-Singularity_Myth-85"><span>[</span>85<span>]</span></a></sup></p>
<p>Others propose that other "singularities" can be found through analysis of trends in <a href="World_population" title="World population">world population</a>, world <a href="Gross_domestic_product" title="Gross domestic product">gross domestic product</a>, and other indices. <a href="Andrey_Korotayev" title="Andrey Korotayev">Andrey Korotayev</a> and others argue that historical <a href="Hyperbolic_growth" title="Hyperbolic growth">hyperbolic growth</a> curves can be attributed to <a href="Feedback_loop" title="Feedback loop" class="mw-redirect">feedback loops</a> that ceased to affect global trends in the 1970s, and thus hyperbolic growth should not be expected in the future.<sup id="cite_ref-cliodynamics_89-0" class="reference"><a href="#cite_note-cliodynamics-89"><span>[</span>89<span>]</span></a></sup><sup id="cite_ref-90" class="reference"><a href="#cite_note-90"><span>[</span>90<span>]</span></a></sup></p>
<p>In <i>The Progress of Computing</i>, <a href="William_Nordhaus" title="William Nordhaus">William Nordhaus</a> argued that, prior to 1940, computers followed the much slower growth of a traditional industrial economy, thus rejecting extrapolations of Moore's law to 19th-century computers. <a href="#CITEREFSchmidhuber2006">Schmidhuber (2006</a>) suggests differences in memory of recent and distant events create an illusion of accelerating change, and that such phenomena may be responsible for past apocalyptic predictions.</p>
<p>Andrew Kennedy, in his 2006 paper for the <a href="British_Interplanetary_Society" title="British Interplanetary Society">British Interplanetary Society</a> discussing <a href="Wait_Calculation" title="Wait Calculation">change and the growth in space travel velocities</a>,<sup id="cite_ref-interstellar_91-0" class="reference"><a href="#cite_note-interstellar-91"><span>[</span>91<span>]</span></a></sup> stated that although long-term overall growth is inevitable, it is small, embodying both ups and downs, and noted, "New technologies follow known laws of power use and information spread and are obliged to connect with what already exists. Remarkable theoretical discoveries, if they end up being used at all, play their part in maintaining the growth rate: they do not make its plotted curve... redundant." He stated that exponential growth is no predictor in itself, and illustrated this with examples such as <a href="Quantum_mechanics" title="Quantum mechanics">quantum theory</a>. The quantum was conceived in 1900, and quantum theory was in existence and accepted approximately 25 years later. However, it took over 40 years for <a href="Richard_Feynman" title="Richard Feynman">Richard Feynman</a> and others to produce meaningful numbers from the theory. <a href="Hans_Bethe" title="Hans Bethe">Bethe</a> understood nuclear fusion in 1935, but 75 years later fusion reactors are still only used in experimental settings. Similarly, <a href="Quantum_entanglement" title="Quantum entanglement">quantum entanglement</a> was understood in 1935 but not at the point of being used in practice until the 21st century.</p>
<p>A study of patents per thousand persons shows that human creativity does not show accelerating returns, but in fact, as suggested by <a href="Joseph_Tainter" title="Joseph Tainter">Joseph Tainter</a> in his seminal <i>The Collapse of Complex Societies</i>,<sup id="cite_ref-university_92-0" class="reference"><a href="#cite_note-university-92"><span>[</span>92<span>]</span></a></sup> a law of <a href="Diminishing_returns" title="Diminishing returns">diminishing returns</a>. The number of patents per thousand peaked in the period from 1850 to 1900, and has been declining since.<sup id="cite_ref-technological14_86-1" class="reference"><a href="#cite_note-technological14-86"><span>[</span>86<span>]</span></a></sup> The growth of complexity eventually becomes self-limiting, and leads to a widespread "general systems collapse".</p>
<p>In addition to general criticisms of the singularity concept, several critics have raised issues with Kurzweil's iconic chart. One line of criticism is that a <a href="Log-log_plot" title="Log-log plot">log-log</a> chart of this nature is inherently biased toward a straight-line result. Others identify selection bias in the points that Kurzweil chooses to use. For example, biologist <a href="PZ_Myers" title="PZ Myers">PZ Myers</a> points out that many of the early evolutionary "events" were picked arbitrarily.<sup id="cite_ref-PZMyers_93-0" class="reference"><a href="#cite_note-PZMyers-93"><span>[</span>93<span>]</span></a></sup> Kurzweil has rebutted this by charting evolutionary events from 15 neutral sources, and showing that they fit a straight line on <a href="http://en.wikipedia.org/wiki/File:ParadigmShiftsFrr15Events.svg" title="File:ParadigmShiftsFrr15Events.svg">a log-log chart</a>. <i><a href="The_Economist" title="The Economist">The Economist</a></i> mocked the concept with a graph extrapolating that the number of blades on a razor, which has increased over the years from one to as many as five, will increase ever-faster to infinity.<sup id="cite_ref-moreblades_94-0" class="reference"><a href="#cite_note-moreblades-94"><span>[</span>94<span>]</span></a></sup></p>
<h2><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=11.php.html" title="Edit section: In popular culture">edit</a>]</span> <span class="mw-headline" id="In_popular_culture">In popular culture</span></h2>
<div class="rellink boilerplate seealso">See also: <a href="List_of_fictional_computers" title="List of fictional computers">List of fictional computers</a></div>
<p><a href="Isaac_Asimov" title="Isaac Asimov">Isaac Asimov</a>'s 1950 story "<a href="The_Evitable_Conflict" title="The Evitable Conflict">The Evitable Conflict</a>", (the last part of the <i><a href="I,_Robot" title="I, Robot">I, Robot</a></i> collection) features the Machines, four supercomputers managing the world's economy. The computers are incomprehensible to humans and are impossible to analyze for errors, having been created through 10 stages of <a href="Bootstrapping" title="Bootstrapping">bootstrapping</a>. In the end of the story, it is implied that from now on (it occurs in 2052), no major conflict can occur, and the Machines are going to guide humanity toward a better future, one only they are capable of seeing (and know to truly be the best). <a href="Susan_Calvin" title="Susan Calvin">Susan Calvin</a> states that "For all time, all conflicts are finally evitable. Only the Machines, from now on, are inevitable!"</p>
<p><a href="../James_P._Hogan_(writer)" title="James P. Hogan (writer)" class="mw-redirect">James P. Hogan</a>'s 1979 novel <i>The Two Faces of Tomorrow</i> is an explicit description of what is now called the Singularity. An artificial intelligence system solves an excavation problem on the moon in a brilliant and novel way, but nearly kills a work crew in the process. Realizing that systems are becoming too sophisticated and complex to predict or manage, a scientific team sets out to teach a sophisticated computer network how to think more humanly. The story documents the rise of self-awareness in the computer system, the humans' loss of control and failed attempts to shut down the experiment as the computer desperately defends itself, and the computer intelligence reaching maturity.</p>
<p>While discussing the singularity's growing recognition, Vernor Vinge wrote in 1993 that "it was the science-fiction writers who felt the first concrete impact." In addition to his own short story "Bookworm, Run!", whose protagonist is a chimpanzee with intelligence augmented by a government experiment, he cites <a href="Greg_Bear" title="Greg Bear">Greg Bear</a>'s novel <i><a href="Blood_Music_(novel)" title="Blood Music (novel)">Blood Music</a></i> (1983) as an example of the singularity in fiction. Vinge described surviving the singularity in his 1986 novel <i><a href="Marooned_in_Realtime" title="Marooned in Realtime">Marooned in Realtime</a></i>. Vinge later expanded the notion of the singularity to a galactic scale in <i><a href="A_Fire_Upon_the_Deep" title="A Fire Upon the Deep">A&#160;Fire Upon the Deep</a></i> (1992), a novel populated by transcendent beings, each the product of a different race and possessed of distinct agendas and overwhelming power.</p>
<p>In <a href="William_Gibson" title="William Gibson">William Gibson</a>'s 1984 novel <i><a href="Neuromancer" title="Neuromancer">Neuromancer</a></i>, artificial intelligences capable of improving their own programs are strictly regulated by special "Turing police" to ensure they never exceed a certain level of intelligence, and the plot centers on the efforts of one such AI to circumvent their control. The 1994 novel <i><a href="The_Metamorphosis_of_Prime_Intellect" title="The Metamorphosis of Prime Intellect">The Metamorphosis of Prime Intellect</a></i> features an AI that augments itself so quickly as to gain low-level control of all matter in the universe in a matter of hours.</p>
<p><a href="William_Gibson" title="William Gibson">William Gibson</a> and <a href="Bruce_Sterling" title="Bruce Sterling">Bruce Sterling</a>'s <a href="Alternate_history" title="Alternate history">alternate history</a> <a href="Steampunk" title="Steampunk">Steampunk</a> novel <i><a href="The_Difference_Engine" title="The Difference Engine">The Difference Engine</a></i> ends with a vision of the singularity occurring in 1991 with a superintelligent computer that has merged its mind with the inhabitants of London.</p>
<p>A more malevolent AI achieves similar levels of omnipotence in <a href="Harlan_Ellison" title="Harlan Ellison">Harlan Ellison</a>'s short story <i><a href="I_Have_No_Mouth,_and_I_Must_Scream" title="I Have No Mouth, and I Must Scream">I&#160;Have No Mouth, and I Must Scream</a></i> (1967).</p>
<p><a href="William_Thomas_Quick" title="William Thomas Quick">William Thomas Quick</a>'s novels <i>Dreams of Flesh and Sand</i> (1988), <i>Dreams of Gods and Men</i> (1989), and <i>Singularities</i> (1990) present an account of the transition through the singularity; in the last novel, one of the characters states that mankind's survival requires it to integrate with the emerging machine intelligences, or it will be crushed under the dominance of the machines—the greatest risk to the survival of a species reaching this point (and alluding to large numbers of other species that either survived or failed this test, although no actual contact with alien species occurs in the novels).</p>
<p>The singularity is sometimes addressed in fictional works to explain the event's absence. <a href="Neal_Asher" title="Neal Asher">Neal Asher</a>'s <i><a href="Gridlinked" title="Gridlinked">Gridlinked</a></i> series features a future where humans living in the Polity are governed by AIs and while some are resentful, most believe that they are far better governors than any human. In the fourth novel, <i><a href="Polity_Agent" title="Polity Agent">Polity Agent</a></i>, it is mentioned that the singularity is far overdue yet most AIs have decided not to partake in it for reasons that only they know. A flashback character in <a href="Ken_MacLeod" title="Ken MacLeod">Ken MacLeod</a>'s 1998 novel <i>The Cassini Division</i> dismissively refers to the singularity as "the <a href="Rapture" title="Rapture">Rapture</a> for nerds", though the singularity goes on to happen anyway.</p>
<p>Popular movies in which computers become intelligent and violently overpower the human race include <i><a href="Colossus__The_Forbin_Project" title="Colossus: The Forbin Project">Colossus: The Forbin Project</a></i>, the <i><a href="Terminator_(franchise)" title="Terminator (franchise)">Terminator</a></i> series, the very loose film adaptation of <i><a href="I,_Robot_(film)" title="I, Robot (film)">I,&#160;Robot</a></i>, and <i><a href="The_Matrix_(series)" title="The Matrix (series)" class="mw-redirect">The Matrix</a></i> series. The television series <i><a href="Battlestar_Galactica_(2004_TV_series)" title="Battlestar Galactica (2004 TV series)">Battlestar Galactica</a></i> also explores these themes.</p>
<p><a href="Isaac_Asimov" title="Isaac Asimov">Isaac Asimov</a> expressed ideas similar to a post-Kurzweilian singularity in his short story "<a href="The_Last_Question" title="The Last Question">The Last Question</a>". Asimov's future envisions a reality where a combination of <a href="Strong_artificial_intelligence" title="Strong artificial intelligence" class="mw-redirect">strong artificial intelligence</a> and <a href="Post-human" title="Post-human" class="mw-redirect">post-humans</a> consume the cosmos, during a time Kurzweil describes as when "the universe wakes up", the last of his six stages of cosmic evolution as described in <i><a href="The_Singularity_is_Near" title="The Singularity is Near" class="mw-redirect">The Singularity is Near</a></i>. Post-human entities throughout various time periods of the story inquire of the artificial intelligence within the story as to how <a href="Heat_death_of_the_universe" title="Heat death of the universe">entropy death</a> will be avoided. The AI responds that it lacks sufficient information to come to a conclusion, until the end of the story when the AI does indeed arrive at a solution. Notably, it does so in order to fulfill its <a href="Three_Laws_of_Robotics" title="Three Laws of Robotics">duty</a> to answer the humans' question.</p>
<p><a href="../St._Edward's_University" title="St. Edward's University">St. Edward's University</a> chemist <a href="Eamonn_Healy" title="Eamonn Healy">Eamonn Healy</a> discusses accelerating change in the film <i><a href="Waking_Life" title="Waking Life">Waking Life</a></i>. He divides history into increasingly shorter periods, estimating "two billion years for life, six million years for the hominid, a hundred-thousand years for mankind as we know it". He proceeds to human cultural evolution, giving time scales of ten thousand years for agriculture, four hundred years for the scientific revolution, and one hundred fifty years for the industrial revolution. Information is emphasized as providing the basis for the new evolutionary paradigm, with artificial intelligence its culmination. He concludes we will eventually create "neohumans" which will usurp humanity’s present role in scientific and technological progress and allow the exponential trend of accelerating change to continue past the limits of human ability.</p>
<p>Accelerating progress features in some science fiction works, and is a central theme in <a href="Charles_Stross" title="Charles Stross">Charles Stross</a>'s <a href="Accelerando_(book)" title="Accelerando (book)" class="mw-redirect"><i>Accelerando</i></a>. Other notable authors that address singularity-related issues include <a href="Karl_Schroeder" title="Karl Schroeder">Karl Schroeder</a>, <a href="Greg_Egan" title="Greg Egan">Greg Egan</a>, <a href="Ken_MacLeod" title="Ken MacLeod">Ken MacLeod</a>, <a href="Rudy_Rucker" title="Rudy Rucker">Rudy Rucker</a>, <a href="David_Brin" title="David Brin">David Brin</a>, <a href="../Iain_M._Banks" title="Iain M. Banks" class="mw-redirect">Iain M. Banks</a>, <a href="Neal_Stephenson" title="Neal Stephenson">Neal Stephenson</a>, <a href="Tony_Ballantyne" title="Tony Ballantyne">Tony Ballantyne</a>, <a href="Bruce_Sterling" title="Bruce Sterling">Bruce Sterling</a>, <a href="Dan_Simmons" title="Dan Simmons">Dan Simmons</a>, <a href="Damien_Broderick" title="Damien Broderick">Damien Broderick</a>, <a href="Fredric_Brown" title="Fredric Brown">Fredric Brown</a>, <a href="Jacek_Dukaj" title="Jacek Dukaj">Jacek Dukaj</a>, <a href="Stanislav_Lem" title="Stanislav Lem" class="mw-redirect">Stanislav Lem</a>, <a href="Nagaru_Tanigawa" title="Nagaru Tanigawa">Nagaru Tanigawa</a>, <a href="Douglas_Adams" title="Douglas Adams">Douglas Adams</a>, <a href="Michael_Crichton" title="Michael Crichton">Michael Crichton</a> and <a href="Ian_McDonald_(author)" title="Ian McDonald (author)" class="mw-redirect">Ian McDonald</a>.</p>
<p>The feature-length documentary film <i><a href="Transcendent_Man_(film)" title="Transcendent Man (film)" class="mw-redirect">Transcendent Man</a></i> by <a href="Barry_Ptolemy" title="Barry Ptolemy">Barry Ptolemy</a> is based on Kurzweil and his book <i>The Singularity Is Near</i>. The film documents Kurzweil's quest to reveal what he believes to be mankind's destiny. Another documentary, <i><a href="Plug_&_Pray" title="Plug &amp; Pray">Plug &amp; Pray</a></i>, focuses on the promise, problems and ethics of artificial intelligence and robotics, with <a href="Joseph_Weizenbaum" title="Joseph Weizenbaum">Joseph Weizenbaum</a> and Kurzweil as the main subjects of the film.<sup id="cite_ref-plugandpray-film_95-0" class="reference"><a href="#cite_note-plugandpray-film-95"><span>[</span>95<span>]</span></a></sup></p>
<p>In 2009, scientists at Aberystwyth University in Wales and the U.K's University of Cambridge designed a robot called Adam that they believe to be the first machine to independently discover new scientific findings.<sup id="cite_ref-cnet15_96-0" class="reference"><a href="#cite_note-cnet15-96"><span>[</span>96<span>]</span></a></sup> Also in 2009, researchers at <a href="Cornell" title="Cornell" class="mw-redirect">Cornell</a> developed a computer program that extrapolated the laws of motion from a pendulum's swings.<sup id="cite_ref-wired_97-0" class="reference"><a href="#cite_note-wired-97"><span>[</span>97<span>]</span></a></sup><sup id="cite_ref-cornell_98-0" class="reference"><a href="#cite_note-cornell-98"><span>[</span>98<span>]</span></a></sup></p>
<p>A Tamil film Enthiran deals with a humanoid robot having an intelligence equivalent to that of a human and wreaking havoc causing struggle for existence.</p>
<p>The web comic <a href="Dresden_Codak" title="Dresden Codak">Dresden Codak</a> deals with trans-humanistic themes and the singularity.</p>
<p>The plot of an episode of the TV program <i><a href="The_Big_Bang_Theory" title="The Big Bang Theory">The Big Bang Theory</a></i> (season&#160;4, episode&#160;2, "The Cruciferous Vegetable Amplification") revolves around the anticipated date of the coming Singularity.</p>
<p>The seventeenth episode of the sixth season of the TV sitcom <i>Futurama</i>, "Benderama" references Bender reaching the technological singularity and being able to infinitely produce smaller versions of himself to wreak havoc on the world.</p>
<p><a href="Industrial_Music" title="Industrial Music" class="mw-redirect">Industrial</a>/<a href="Steampunk" title="Steampunk">Steampunk</a> entertainer <a href="Doctor_Steel" title="Doctor Steel">Doctor Steel</a> weaves the concept of a technological singularity into his music and videos, even having a song entitled <i>The Singularity</i>. He has been interviewed on his views by the <a href="Institute_for_Ethics_and_Emerging_Technologies" title="Institute for Ethics and Emerging Technologies">Institute for Ethics and Emerging Technologies</a>,<sup id="cite_ref-IEET_interview_99-0" class="reference"><a href="#cite_note-IEET_interview-99"><span>[</span>99<span>]</span></a></sup> and has also authored a paper on the subject.<sup id="cite_ref-Paranoia_magazine_100-0" class="reference"><a href="#cite_note-Paranoia_magazine-100"><span>[</span>100<span>]</span></a></sup><sup id="cite_ref-Paranoia_magazine_clipping_101-0" class="reference"><a href="#cite_note-Paranoia_magazine_clipping-101"><span>[</span>101<span>]</span></a></sup></p>
<p>In 2012, concept band <a rel="nofollow" class="external text" href="http://sola-mi.com">SOLA-MI</a>, released "NEXUS (Original Motion Picture Soundtrack)," an album about the first waking machine.</p>
<p>In the sci-fi webseries <a rel="nofollow" class="external text" href="http://imdb.com/title/tt2317127/">Sync</a>, a <a href="Computer_virus" title="Computer virus">computer virus</a> takes over a computerized human and becomes a singularity.</p>
<h2><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=12.php.html" title="Edit section: See also">edit</a>]</span> <span class="mw-headline" id="See_also">See also</span></h2>
<div class="column-count column-count-2" style="-moz-column-count: 2; -webkit-column-count: 2; column-count: 2;">
<ul>
<li><a href="Democratic_transhumanism" title="Democratic transhumanism">Democratic transhumanism</a></li>
<li><a href="Development_criticism" title="Development criticism">Development criticism</a></li>
<li><a href="Doomsday_argument" title="Doomsday argument">Doomsday argument</a></li>
<li><a href="Eschatology#Empirical_and_Rationalist_based" title="Eschatology">Eschatology#Empirical and Rationalist based</a></li>
<li><a href="Exocortex" title="Exocortex">Exocortex</a></li>
<li><a href="Future_Shock" title="Future Shock">Future Shock</a></li>
<li><a href="Hyperbolic_growth" title="Hyperbolic growth">Hyperbolic growth</a></li>
<li><a href="Kardashev_scale" title="Kardashev scale">Kardashev scale</a></li>
<li><a href="List_of_emerging_technologies" title="List of emerging technologies">List of emerging technologies</a></li>
<li><a href="Logarithmic_timeline" title="Logarithmic timeline">Logarithmic timeline</a> and <a href="Detailed_logarithmic_timeline" title="Detailed logarithmic timeline">detailed logarithmic timeline</a></li>
<li><a href="Molecular_engineering" title="Molecular engineering">Molecular engineering</a></li>
<li><a href="Novelty_theory#Timewave_zero_and_the_I_Ching" title="Novelty theory" class="mw-redirect">Novelty theory</a></li>
<li><a href="Omega_Point" title="Omega Point">Omega Point</a></li>
<li><a href="Positive_feedback" title="Positive feedback">Positive feedback</a></li>
<li><a href="Post-scarcity_economy" title="Post-scarcity economy">Post-scarcity economy</a></li>
<li><a href="Predictive_medicine" title="Predictive medicine">Predictive medicine</a></li>
<li><a href="Sentience_quotient" title="Sentience quotient">Sentience quotient</a></li>
<li><a href="Simulated_reality" title="Simulated reality">Simulated reality</a></li>
<li><a href="Singularitarianism" title="Singularitarianism">Singularitarianism</a></li>
<li><a href="Strong_AI" title="Strong AI">Strong AI</a></li>
<li><a href="Technocapitalism" title="Technocapitalism">Technocapitalism</a></li>
<li><a href="Technological_determinism" title="Technological determinism">Technological determinism</a></li>
<li><a href="Technological_evolution" title="Technological evolution">Technological evolution</a></li>
<li><a href="Technological_utopianism" title="Technological utopianism">Technological utopianism</a></li>
<li><a href="Transhumanism" title="Transhumanism">Transhumanism</a></li>
<li><a href="Transcension_Hypothesis" title="Transcension Hypothesis" class="mw-redirect">Transcension Hypothesis</a></li>
</ul>
</div>
<h2><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=13.php.html" title="Edit section: Notes">edit</a>]</span> <span class="mw-headline" id="Notes">Notes</span></h2>
<div class="reflist references-column-count references-column-count-2" style="-moz-column-count: 2; -webkit-column-count: 2; column-count: 2; list-style-type: decimal;">
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text">Superintelligence. Answer to the 2009 EDGE QUESTION: "WHAT WILL CHANGE EVERYTHING?": <a rel="nofollow" class="external free" href="http://www.nickbostrom.com/views/superintelligence.pdf">http://www.nickbostrom.com/views/superintelligence.pdf</a></span></li>
<li id="cite_note-Singularity.2C_Intelligence_Explosion_2010-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-Singularity.2C_Intelligence_Explosion_2010_2-0">^</a></b></span> <span class="reference-text">David Chalmers on Singularity, Intelligence Explosion. April 8th, 2010. Singularity Institute for Artificial Intelligence: <a rel="nofollow" class="external free" href="http://singinst.org/blog/2010/04/08/david-chalmers-on-singularity-intelligence-explosion/">http://singinst.org/blog/2010/04/08/david-chalmers-on-singularity-intelligence-explosion/</a></span></li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text">Editor's Blog Why an Intelligence Explosion is Probable By: Richard Loosemore and Ben Goertzel. March 7, 2011; hplusmagazine: <a rel="nofollow" class="external free" href="http://hplusmagazine.com/2011/03/07/why-an-intelligence-explosion-is-probable/">http://hplusmagazine.com/2011/03/07/why-an-intelligence-explosion-is-probable/</a></span></li>
<li id="cite_note-vinge1993-4"><span class="mw-cite-backlink">^ <a href="#cite_ref-vinge1993_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-vinge1993_4-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-vinge1993_4-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text">Vinge, Vernor. <a rel="nofollow" class="external text" href="http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html">"The Coming Technological Singularity: How to Survive in the Post-Human Era"</a>, originally in <i>Vision-21: Interdisciplinary Science and Engineering in the Era of Cyberspace</i>, G. A. Landis, ed., NASA Publication CP-10129, pp. 11-22, 1993</span></li>
<li id="cite_note-singularity-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-singularity_5-0">^</a></b></span> <span class="reference-text">Ray Kurzweil, The Singularity is Near, pp. 135–136. Penguin Group, 2005.</span></li>
<li id="cite_note-singinst.org-6"><span class="mw-cite-backlink">^ <a href="#cite_ref-singinst.org_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-singinst.org_6-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-singinst.org_6-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-singinst.org_6-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><span class="citation web"><a rel="nofollow" class="external text" href="http://singinst.org/overview/whatisthesingularity">"What is the Singularity? | Singularity Institute for Artificial Intelligence"</a>. Singinst.org<span class="printonly">. <a rel="nofollow" class="external free" href="http://singinst.org/overview/whatisthesingularity">http://singinst.org/overview/whatisthesingularity</a></span><span class="reference-accessdate">. Retrieved 2011-09-09</span>.</span></span></li>
<li id="cite_note-hplusmagazine-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-hplusmagazine_7-0">^</a></b></span> <span class="reference-text"><span class="citation web"><a rel="nofollow" class="external text" href="http://www.hplusmagazine.com/articles/nano/singularity-nanotech-or-ai">"h+ Magazine | Covering technological, scientific, and cultural trends that are changing human beings in fundamental ways"</a>. Hplusmagazine.com<span class="printonly">. <a rel="nofollow" class="external free" href="http://www.hplusmagazine.com/articles/nano/singularity-nanotech-or-ai">http://www.hplusmagazine.com/articles/nano/singularity-nanotech-or-ai</a></span><span class="reference-accessdate">. Retrieved 2011-09-09</span>.</span></span></li>
<li id="cite_note-yudkowsky.net-8"><span class="mw-cite-backlink">^ <a href="#cite_ref-yudkowsky.net_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-yudkowsky.net_8-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-yudkowsky.net_8-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><a href="Eliezer_Yudkowsky" title="Eliezer Yudkowsky">Yudkowsky, Eliezer</a>. <a rel="nofollow" class="external text" href="http://yudkowsky.net/singularity/schools">The Singularity: Three Major Schools</a></span></li>
<li id="cite_note-agi-conf-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-agi-conf_9-0">^</a></b></span> <span class="reference-text"><a href="Anders_Sandberg" title="Anders Sandberg">Sandberg, Anders</a>. <a rel="nofollow" class="external text" href="http://agi-conf.org/2010/wp-content/uploads/2009/06/agi10singmodels2.pdf">An overview of models of technological singularity</a></span></li>
<li id="cite_note-kurzweilai.net-10"><span class="mw-cite-backlink">^ <a href="#cite_ref-kurzweilai.net_10-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-kurzweilai.net_10-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><span class="citation web"><a rel="nofollow" class="external text" href="http://www.kurzweilai.net/max-more-and-ray-kurzweil-on-the-singularity-2">"Max More and Ray Kurzweil on the Singularity"</a>. KurzweilAI<span class="printonly">. <a rel="nofollow" class="external free" href="http://www.kurzweilai.net/max-more-and-ray-kurzweil-on-the-singularity-2">http://www.kurzweilai.net/max-more-and-ray-kurzweil-on-the-singularity-2</a></span><span class="reference-accessdate">. Retrieved 2011-09-09</span>.</span></span></li>
<li id="cite_note-stat-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-stat_11-0">^</a></b></span> <span class="reference-text">Good, I. J. <a rel="nofollow" class="external text" href="http://www.stat.vt.edu/tech_reports/2005/GoodTechReport.pdf">"Speculations Concerning the First Ultraintelligent Machine"</a>, <i>Advances in Computers</i>, vol. 6, 1965.</span></li>
<li id="cite_note-Paul_Ehrlich_June_2008-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-Paul_Ehrlich_June_2008_12-0">^</a></b></span> <span class="reference-text">Ehrlich, Paul. <a rel="nofollow" class="external text" href="http://www.longnow.org/seminars/02008/jun/27/dominant-animal-human-evolution-and-environment/">The Dominant Animal: Human Evolution and the Environment</a></span></li>
<li id="cite_note-businessweek-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-businessweek_13-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.businessweek.com/1999/99_35/b3644021.htm">Superbrains born of silicon will change everything.</a></span></li>
<li id="cite_note-ultraintelligent-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-ultraintelligent_14-0">^</a></b></span> <span class="reference-text">Good, I. J., "Speculations Concerning the First Ultraintelligent Machine", Franz L. Alt and Morris Rubinoff, ed., Advances in Computers (Academic Press) 6: 31–88, 1965.</span></li>
<li id="cite_note-acceleratingfuture-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-acceleratingfuture_15-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.acceleratingfuture.com/people-blog/2007/the-human-importance-of-the-intelligence-explosion/">The Human Importance of the Intelligence Explosion</a></span></li>
<li id="cite_note-ultraintelligent1-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-ultraintelligent1_16-0">^</a></b></span> <span class="reference-text">Good, I. J. 1965 Speculations Concerning the First Ultraintelligent Machine. pp. 31–88 in Advances in Computers, 6, F. L. Alt and M Rubinoff, eds. New York: Academic Press.</span></li>
<li id="cite_note-google-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-google_17-0">^</a></b></span> <span class="reference-text">Ray Kurzweil, <i>The Age of Spiritual Machines</i>, Viking, 1999, <a rel="nofollow" class="external text" href="http://books.google.com/books?id=ldAGcyh0bkUC&lpg=PP1&pg=PA630#v=onepage&amp;q&amp;f=false">p. 30</a> and <a rel="nofollow" class="external text" href="http://books.google.com/books?id=ldAGcyh0bkUC&lpg=PP1&pg=PA632#v=onepage&amp;q&amp;f=false">p. 32</a></span></li>
<li id="cite_note-singularity2-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-singularity2_18-0">^</a></b></span> <span class="reference-text">Ray Kurzweil, <i>The Singularity is Near</i>, Penguin Group, 2005</span></li>
<li id="cite_note-HilbertLopez2011-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-HilbertLopez2011_19-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.sciencemag.org/content/332/6025/60">"The World’s Technological Capacity to Store, Communicate, and Compute Information"</a>, Martin Hilbert and Priscila López (2011), <a href="Science_(journal)" title="Science (journal)">Science (journal)</a>, 332(6025), 60-65; free access to the article through here: martinhilbert.net/WorldInfoCapacity.html</span></li>
<li id="cite_note-singularity3-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-singularity3_20-0">^</a></b></span> <span class="reference-text">Ray Kurzweil, The Singularity is Near, p. 9. Penguin Group, 2005</span></li>
<li id="cite_note-transformation-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-transformation_21-0">^</a></b></span> <span class="reference-text">Ray Kurzweil, <i>The Singularity is Near</i>, pp. 135–136. Penguin Group, 2005. The context for this statement is as follows: "we will be producing about 10<sup>26</sup> to 10<sup>29</sup> cps of nonbiological computation per year in the early 2030s. This is roughly equal to our estimate for the capacity of all living biological human intelligence ... This state of computation in the early 2030s will not represent the Singularity, however, because it does not yet correspond to a profound expansion of our intelligence. By the mid-2040s, however, that one thousand dollars' worth of computation will be equal to 10<sup>26</sup> cps, so the intelligence created per year (at a total cost of about $10<sup>12</sup>) will be about one billion times more powerful than all human intelligence today. That <i>will</i> indeed represent a profound change, and it is for that reason that I set the date for the Singularity—representing a profound and disruptive transformation in human capability—as 2045."</span></li>
<li id="cite_note-positive-and-negative-22"><span class="mw-cite-backlink">^ <a href="#cite_ref-positive-and-negative_22-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-positive-and-negative_22-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-positive-and-negative_22-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><span class="citation" id="CITEREFYudkowsky2008">Yudkowsky, Eliezer (2008), Bostrom, Nick; Cirkovic, Milan, eds., <a rel="nofollow" class="external text" href="http://singinst.org/AIRisk.pdf">"Artificial Intelligence as a Positive and Negative Factor in Global Risk"</a>, <i>Global Catastrophic Risks</i> (Oxford University Press): 303, <a href="Bibcode" title="Bibcode">Bibcode</a> <a rel="nofollow" class="external text" href="http://adsabs.harvard.edu/abs/2008gcr..book..303Y">2008gcr..book..303Y</a>, <a href="International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="Special_BookSources/978-0-19-857050-9" title="Special:BookSources/978-0-19-857050-9">978-0-19-857050-9</a><span class="printonly">, <a rel="nofollow" class="external free" href="http://singinst.org/AIRisk.pdf">http://singinst.org/AIRisk.pdf</a></span></span></span></li>
<li id="cite_note-theuncertainfuture-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-theuncertainfuture_23-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.theuncertainfuture.com/">The Uncertain Future; a future technology and world-modeling project</a></span></li>
<li id="cite_note-catastrophic-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-catastrophic_24-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0020/3854/global-catastrophic-risks-report.pdf">GLOBAL CATASTROPHIC RISKS SURVEY (2008) Technical Report 2008/1 Published by Future of Humanity Institute, Oxford University. Anders Sandberg and Nick Bostrom</a></span></li>
<li id="cite_note-nickbostrom-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-nickbostrom_25-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.nickbostrom.com/existential/risks.html">Existential Risks; Analyzing Human Extinction Scenarios and Related Hazards, Nick Bostrom</a></span></li>
<li id="cite_note-spectrum.ieee.org-26"><span class="mw-cite-backlink">^ <a href="#cite_ref-spectrum.ieee.org_26-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-spectrum.ieee.org_26-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><span class="citation web"><a rel="nofollow" class="external text" href="http://spectrum.ieee.org/computing/hardware/tech-luminaries-address-singularity">"Tech Luminaries Address Singularity – IEEE Spectrum"</a>. Spectrum.ieee.org<span class="printonly">. <a rel="nofollow" class="external free" href="http://spectrum.ieee.org/computing/hardware/tech-luminaries-address-singularity">http://spectrum.ieee.org/computing/hardware/tech-luminaries-address-singularity</a></span><span class="reference-accessdate">. Retrieved 2011-09-09</span>.</span></span></li>
<li id="cite_note-ieee-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-ieee_27-0">^</a></b></span> <span class="reference-text"><span class="citation web"><a rel="nofollow" class="external text" href="http://spectrum.ieee.org/computing/hardware/whos-who-in-the-singularity">"Who's Who In The Singularity – IEEE Spectrum"</a>. Spectrum.ieee.org<span class="printonly">. <a rel="nofollow" class="external free" href="http://spectrum.ieee.org/computing/hardware/whos-who-in-the-singularity">http://spectrum.ieee.org/computing/hardware/whos-who-in-the-singularity</a></span><span class="reference-accessdate">. Retrieved 2011-09-09</span>.</span></span></li>
<li id="cite_note-The_Expounder_of_Primitive_Christianity-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-The_Expounder_of_Primitive_Christianity_28-0">^</a></b></span> <span class="reference-text"><span class="citation" id="CITEREFThornton1847">Thornton, Richard (1847), <a rel="nofollow" class="external text" href="http://books.google.com/?id=ZM_hAAAAMAAJ&dq=%22Primitive%20Expounder%22%20thornton%201847&pg=PA281#v=onepage&amp;q=thinking%20machine&amp;f=false"><i>The Expounder of Primitive Christianity</i></a>, <b>4</b>, Ann Arbor, Michigan, p.&#160;281<span class="printonly">, <a rel="nofollow" class="external free" href="http://books.google.com/?id=ZM_hAAAAMAAJ&dq=%22Primitive%20Expounder%22%20thornton%201847&pg=PA281#v=onepage&amp;q=thinking%20machine&amp;f=false">http://books.google.com/?id=ZM_hAAAAMAAJ&amp;dq=%22Primitive%20Expounder%22%20thornton%201847&amp;pg=PA281#v=onepage&amp;q=thinking%20machine&amp;f=false</a></span></span></span></li>
<li id="cite_note-oxfordjournals-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-oxfordjournals_29-0">^</a></b></span> <span class="reference-text">A M Turing, <i>Intelligent Machinery, A Heretical Theory</i>, 1951, reprinted <i>Philosophia Mathematica</i> (1996) 4(3): 256–260 <a href="Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="http://dx.doi.org/10.1093/philmat/4.3.256">10.1093/philmat/4.3.256</a> <a rel="nofollow" class="external autonumber" href="http://philmat.oxfordjournals.org/content/4/3/256.full.pdf">[1]</a></span></li>
<li id="cite_note-google4-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-google4_30-0">^</a></b></span> <span class="reference-text">Dooling, Richard. <i>Rapture for the Geeks: When AI Outsmarts IQ</i> (2008), <a rel="nofollow" class="external text" href="http://books.google.com/books?id=VbBRsv1lxsUC&lpg=PP1&pg=PA88#v=onepage&amp;q&amp;f=false">p. 88</a></span></li>
<li id="cite_note-technological-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-technological_31-0">^</a></b></span> <span class="reference-text">Vinge did not actually use the phrase "technological singularity" in the Omni op-ed, but he did use this phrase in the short story collection <i>Threats and Other Promises</i> from 1988, writing in the introduction to his story "The Whirligig of Time" (p. 72): <i>Barring a worldwide catastrophe, I believe that technology will achieve our wildest dreams, and</i> soon. <i>When we raise our own intelligence and that of our creations, we are no longer in a world of human-sized characters. At that point we have fallen into a technological "black hole," a technological singularity.</i></span></li>
<li id="cite_note-std-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-std_32-0">^</a></b></span> <span class="reference-text">Solomonoff, R.J. "The Time Scale of Artificial Intelligence: Reflections on Social Effects," Human Systems Management, Vol 5, pp. 149–153, 1985, <a rel="nofollow" class="external free" href="http://world.std.com/~rjs/timesc.pdf">http://world.std.com/~rjs/timesc.pdf</a>.</span></li>
<li id="cite_note-When_will_computer_hardware_match_the_human_brain.3F-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-When_will_computer_hardware_match_the_human_brain.3F_33-0">^</a></b></span> <span class="reference-text"><span class="citation" id="CITEREFMoravec1998">Moravec, Hans (1998), <a rel="nofollow" class="external text" href="http://www.transhumanist.com/volume1/moravec.htm">"When will computer hardware match the human brain?"</a>, <i>Journal of Evolution and Technology</i> <b>1</b><span class="printonly">, <a rel="nofollow" class="external free" href="http://www.transhumanist.com/volume1/moravec.htm">http://www.transhumanist.com/volume1/moravec.htm</a></span><span class="reference-accessdate">, retrieved 2006-06-23</span>.</span></span></li>
<li id="cite_note-The_Age_of_Robots-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-The_Age_of_Robots_34-0">^</a></b></span> <span class="reference-text"><span class="citation web">Moravec, Hans (June 1993). <a rel="nofollow" class="external text" href="http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1993/Robot93.html">"The Age of Robots"</a><span class="printonly">. <a rel="nofollow" class="external free" href="http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1993/Robot93.html">http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1993/Robot93.html</a></span><span class="reference-accessdate">. Retrieved 2006-06-23</span>.</span></span></li>
<li id="cite_note-Robot_Predictions_Evolution-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-Robot_Predictions_Evolution_35-0">^</a></b></span> <span class="reference-text"><span class="citation web">Moravec, Hans (April 2004). <a rel="nofollow" class="external text" href="http://www.frc.ri.cmu.edu/~hpm/project.archive/robot.papers/2004/Predictions.html">"Robot Predictions Evolution"</a><span class="printonly">. <a rel="nofollow" class="external free" href="http://www.frc.ri.cmu.edu/~hpm/project.archive/robot.papers/2004/Predictions.html">http://www.frc.ri.cmu.edu/~hpm/project.archive/robot.papers/2004/Predictions.html</a></span><span class="reference-accessdate">. Retrieved 2006-06-23</span>.</span></span></li>
<li id="cite_note-google5-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-google5_36-0">^</a></b></span> <span class="reference-text">Dooling, Richard. <i>Rapture for the Geeks: When AI Outsmarts IQ</i> (2008), <a rel="nofollow" class="external text" href="http://books.google.com/books?id=VbBRsv1lxsUC&lpg=PP1&pg=PA89#v=onepage&amp;q&amp;f=false">p. 89</a></span></li>
<li id="cite_note-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-37">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html">The Coming Technological Singularity: How to Survive in the Post-Human Era</a>, by Vernor Vinge, Department of Mathematical Sciences, San Diego State University, (c) 1993 by Vernor Vinge.</span></li>
<li id="cite_note-JoyFuture-38"><span class="mw-cite-backlink"><b><a href="#cite_ref-JoyFuture_38-0">^</a></b></span> <span class="reference-text"><span class="citation" id="CITEREFJoy2000"><a href="Bill_Joy" title="Bill Joy">Joy, Bill</a> (April 2000), <a rel="nofollow" class="external text" href="http://www.wired.com/wired/archive/8.04/joy.html">"Why the future doesn’t need us"</a>, <i><a href="Wired_(magazine)" title="Wired (magazine)">Wired Magazine</a></i> (Viking Adult) (8.04), <a href="International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="Special_BookSources/0-670-03249-2" title="Special:BookSources/0-670-03249-2">0-670-03249-2</a><span class="printonly">, <a rel="nofollow" class="external free" href="http://www.wired.com/wired/archive/8.04/joy.html">http://www.wired.com/wired/archive/8.04/joy.html</a></span><span class="reference-accessdate">, retrieved 2007-08-07</span></span></span></li>
<li id="cite_note-episode-39"><span class="mw-cite-backlink"><b><a href="#cite_ref-episode_39-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.imdb.com/title/tt847969/"><i>Episode dated 23 August 2006</i></a> at the <a href="Internet_Movie_Database" title="Internet Movie Database">Internet Movie Database</a></span></li>
<li id="cite_note-Hanson-40"><span class="mw-cite-backlink">^ <a href="#cite_ref-Hanson_40-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Hanson_40-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><span class="citation" id="CITEREFRobin_Hanson">Robin Hanson, <a rel="nofollow" class="external text" href="http://www.spectrum.ieee.org/robotics/robotics-software/economics-of-the-singularity">"Economics Of The Singularity"</a>, <i>IEEE Spectrum Special Report: The Singularity</i><span class="printonly">, <a rel="nofollow" class="external free" href="http://www.spectrum.ieee.org/robotics/robotics-software/economics-of-the-singularity">http://www.spectrum.ieee.org/robotics/robotics-software/economics-of-the-singularity</a></span><span class="reference-accessdate">, retrieved 2008-09-11</span></span> &amp; <a rel="nofollow" class="external text" href="http://hanson.gmu.edu/longgrow.pdf">Long-Term Growth As A Sequence of Exponential Modes</a></span></li>
<li id="cite_note-singularityu-41"><span class="mw-cite-backlink"><b><a href="#cite_ref-singularityu_41-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://singularityu.org/about/">About Singularity University</a> at its official website</span></li>
<li id="cite_note-sens-42"><span class="mw-cite-backlink"><b><a href="#cite_ref-sens_42-0">^</a></b></span> <span class="reference-text"><a href="Aubrey_de_Grey" title="Aubrey de Grey">de Grey, Aubrey</a>. <a rel="nofollow" class="external text" href="http://www.sens.org/node/514">The singularity and the Methuselarity: similarities and differences</a></span></li>
<li id="cite_note-Apocalyptic_AI_-_Visions_of_Heaven_in_Robotics.2C_Artificial_Intelligence.2C_and_Virtual_Reality-43"><span class="mw-cite-backlink"><b><a href="#cite_ref-Apocalyptic_AI_-_Visions_of_Heaven_in_Robotics.2C_Artificial_Intelligence.2C_and_Virtual_Reality_43-0">^</a></b></span> <span class="reference-text"><span class="citation" id="CITEREFGeraci">Geraci, Robert M., <i>Apocalyptic AI – Visions of Heaven in Robotics, Artificial Intelligence, and Virtual Reality</i>, <a href="International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="Special_BookSources/978-0-19-539302-6" title="Special:BookSources/978-0-19-539302-6">978-0-19-539302-6</a></span></span></li>
<li id="cite_note-time-44"><span class="mw-cite-backlink"><b><a href="#cite_ref-time_44-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.time.com/time/magazine/article/0,9171,2048299,00.html">2045: The Year Man Becomes Immortal</a>, By Lev Grossman Thursday, Feb. 10, 2011 time.com.</span></li>
<li id="cite_note-david_chalmers_singularity_lecture_resources_available-45"><span class="mw-cite-backlink"><b><a href="#cite_ref-david_chalmers_singularity_lecture_resources_available_45-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external autonumber" href="http://www.fhi.ox.ac.uk/news/2010/david_chalmers_singularity_lecture_resources_available">[2]</a> David Chalmers John Locke Lecture, 10 May, Exam Schools, Oxford, presenting a philosophical analysis of the possibility of a technological singularity or "intelligence explosion" resulting from recursively self-improving AI.</span></li>
<li id="cite_note-consc.net-46"><span class="mw-cite-backlink"><b><a href="#cite_ref-consc.net_46-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://consc.net/papers/singularity.pdf">The Singularity: A Philosophical Analysis, David J. Chalmers</a></span></li>
<li id="cite_note-itrs-47"><span class="mw-cite-backlink"><b><a href="#cite_ref-itrs_47-0">^</a></b></span> <span class="reference-text"><span class="citation web"><a rel="nofollow" class="external text" href="http://www.itrs.net/Links/2007ITRS/ExecSum2007.pdf">"ITRS"</a> (PDF)<span class="printonly">. <a rel="nofollow" class="external free" href="http://www.itrs.net/Links/2007ITRS/ExecSum2007.pdf">http://www.itrs.net/Links/2007ITRS/ExecSum2007.pdf</a></span><span class="reference-accessdate">. Retrieved 2011-09-09</span>.</span></span></li>
<li id="cite_note-arstechnica-48"><span class="mw-cite-backlink"><b><a href="#cite_ref-arstechnica_48-0">^</a></b></span> <span class="reference-text"><span class="citation web">Siracusa, John (2009-08-31). <a rel="nofollow" class="external text" href="http://arstechnica.com/apple/reviews/2009/08/mac-os-x-10-6.ars/8">"Mac OS X 10.6 Snow Leopard: the Ars Technica review"</a>. Arstechnica.com<span class="printonly">. <a rel="nofollow" class="external free" href="http://arstechnica.com/apple/reviews/2009/08/mac-os-x-10-6.ars/8">http://arstechnica.com/apple/reviews/2009/08/mac-os-x-10-6.ars/8</a></span><span class="reference-accessdate">. Retrieved 2011-09-09</span>.</span></span></li>
<li id="cite_note-singularity6-49"><span class="mw-cite-backlink"><b><a href="#cite_ref-singularity6_49-0">^</a></b></span> <span class="reference-text">Eliezer Yudkowsky, 1996 "Staring at the Singularity</span></li>
<li id="cite_note-yudkowsky-50"><span class="mw-cite-backlink"><b><a href="#cite_ref-yudkowsky_50-0">^</a></b></span> <span class="reference-text"><span class="citation web">Eliezer S. Yudkowsky. <a rel="nofollow" class="external text" href="http://yudkowsky.net/singularity/power">"Power of Intelligence"</a>. Yudkowsky<span class="printonly">. <a rel="nofollow" class="external free" href="http://yudkowsky.net/singularity/power">http://yudkowsky.net/singularity/power</a></span><span class="reference-accessdate">. Retrieved 2011-09-09</span>.</span></span></li>
<li id="cite_note-selfawaresystems-51"><span class="mw-cite-backlink"><b><a href="#cite_ref-selfawaresystems_51-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://selfawaresystems.com/2007/11/30/paper-on-the-basic-ai-drives/">Omohundro, Stephen M., "The Basic AI Drives." Artificial General Intelligence, 2008 proceedings of the First AGI Conference, eds. Pei Wang, Ben Goertzel, and Stan Franklin. Vol. 171. Amsterdam: IOS, 2008</a></span></li>
<li id="cite_note-kurzweilai-52"><span class="mw-cite-backlink"><b><a href="#cite_ref-kurzweilai_52-0">^</a></b></span> <span class="reference-text"><span class="citation web"><a rel="nofollow" class="external text" href="http://www.kurzweilai.net/artificial-general-intelligence-now-is-the-time">"Artificial General Intelligence: Now Is the Time"</a>. KurzweilAI<span class="printonly">. <a rel="nofollow" class="external free" href="http://www.kurzweilai.net/artificial-general-intelligence-now-is-the-time">http://www.kurzweilai.net/artificial-general-intelligence-now-is-the-time</a></span><span class="reference-accessdate">. Retrieved 2011-09-09</span>.</span></span></li>
<li id="cite_note-selfawaresystems.com-53"><span class="mw-cite-backlink">^ <a href="#cite_ref-selfawaresystems.com_53-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-selfawaresystems.com_53-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://selfawaresystems.com/2007/10/05/paper-on-the-nature-of-self-improving-artificial-intelligence/">Omohundro, Stephen M., "The Nature of Self-Improving Artificial Intelligence." Self-Aware Systems. 21 Jan. 2008. Web. 07 Jan. 2010.</a></span></li>
<li id="cite_note-ReferenceB-54"><span class="mw-cite-backlink">^ <a href="#cite_ref-ReferenceB_54-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-ReferenceB_54-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><span class="citation web"><a rel="nofollow" class="external text" href="http://singinst.org/riskintro/index.html">"Concise Summary | Singularity Institute for Artificial Intelligence"</a>. Singinst.org<span class="printonly">. <a rel="nofollow" class="external free" href="http://singinst.org/riskintro/index.html">http://singinst.org/riskintro/index.html</a></span><span class="reference-accessdate">. Retrieved 2011-09-09</span>.</span></span></li>
<li id="cite_note-nickbostrom7-55"><span class="mw-cite-backlink">^ <a href="#cite_ref-nickbostrom7_55-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-nickbostrom7_55-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.nickbostrom.com/fut/evolution.html">Bostrom, Nick, The Future of Human Evolution, Death and Anti-Death: Two Hundred Years After Kant, Fifty Years After Turing, ed. Charles Tandy, pp. 339–371, 2004, Ria University Press.</a></span></li>
<li id="cite_note-nickbostrom8-56"><span class="mw-cite-backlink"><b><a href="#cite_ref-nickbostrom8_56-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.nickbostrom.com/ethics/ai.html">Ethical Issues in Advanced Artificial Intelligence, Nick Bostrom, in Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, Vol. 2, ed. I. Smit et al., Int. Institute of Advanced Studies in Systems Research and Cybernetics, 2003, pp. 12–17</a></span></li>
<li id="cite_note-singinst-57"><span class="mw-cite-backlink"><b><a href="#cite_ref-singinst_57-0">^</a></b></span> <span class="reference-text"><a href="Eliezer_Yudkowsky" title="Eliezer Yudkowsky">Eliezer Yudkowsky</a>: <a rel="nofollow" class="external text" href="http://singinst.org/upload/artificial-intelligence-risk.pdf">Artificial Intelligence as a Positive and Negative Factor in Global Risk</a>. Draft for a publication in <i>Global Catastrophic Risk</i> from August 31, 2006, retrieved July 18, 2011 (PDF file)</span></li>
<li id="cite_note-singinst9-58"><span class="mw-cite-backlink"><b><a href="#cite_ref-singinst9_58-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.singinst.org/blog/2007/06/11/the-stamp-collecting-device/">The Stamp Collecting Device, Nick Hay</a></span></li>
<li id="cite_note-aleph-59"><span class="mw-cite-backlink"><b><a href="#cite_ref-aleph_59-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.aleph.se/andart/archives/2011/02/why_we_should_fear_the_paperclipper.html">'Why we should fear the Paperclipper'</a>, 2011-02-14 entry of Sandberg's blog 'Andart'</span></li>
<li id="cite_note-selfawaresystems10-60"><span class="mw-cite-backlink"><b><a href="#cite_ref-selfawaresystems10_60-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://selfawaresystems.com/2007/11/30/paper-on-the-basic-ai-drives/">Omohundro, Stephen M., "The Basic AI Drives." Artificial General Intelligence, 2008 proceedings of the First AGI Conference, eds. Pei Wang, Ben Goertzel, and Stan Franklin. Vol. 171. Amsterdam: IOS, 2008.</a></span></li>
<li id="cite_note-forbes-61"><span class="mw-cite-backlink"><b><a href="#cite_ref-forbes_61-0">^</a></b></span> <span class="reference-text">de Garis, Hugo. <a rel="nofollow" class="external text" href="http://www.forbes.com/2009/06/18/cosmist-terran-cyborgist-opinions-contributors-artificial-intelligence-09-hugo-de-garis.html">"The Coming Artilect War"</a>, Forbes.com, 22 June 2009.</span></li>
<li id="cite_note-singinst12-62"><span class="mw-cite-backlink"><b><a href="#cite_ref-singinst12_62-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://singinst.org/upload/CEV.html">Coherent Extrapolated Volition, Eliezer S. Yudkowsky, May 2004</a></span></li>
<li id="cite_note-JET2008-63"><span class="mw-cite-backlink"><b><a href="#cite_ref-JET2008_63-0">^</a></b></span> <span class="reference-text"><span class="citation" id="CITEREFHibbard2008">Hibbard, Bill (2008), <a rel="nofollow" class="external text" href="http://jetpress.org/v17/hibbard.htm">"The Technology of Mind and a New Social Contract"</a>, <i>Journal of Evolution and Technology</i> <b>17</b><span class="printonly">, <a rel="nofollow" class="external free" href="http://jetpress.org/v17/hibbard.htm">http://jetpress.org/v17/hibbard.htm</a></span>.</span></span></li>
<li id="cite_note-JAGI2012-64"><span class="mw-cite-backlink"><b><a href="#cite_ref-JAGI2012_64-0">^</a></b></span> <span class="reference-text"><span class="citation" id="CITEREFHibbard2012">Hibbard, Bill (2012), <a rel="nofollow" class="external text" href="http://dx.doi.org/10.2478/v10229-011-0013-5">"Model-Based Utility Functions"</a>, <i>Journal of Artificial General Intelligence</i> <b>3</b><span class="printonly">, <a rel="nofollow" class="external free" href="http://dx.doi.org/10.2478/v10229-011-0013-5">http://dx.doi.org/10.2478/v10229-011-0013-5</a></span>.</span></span></li>
<li id="cite_note-AGI-12a-65"><span class="mw-cite-backlink"><b><a href="#cite_ref-AGI-12a_65-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://agi-conference.org/2012/wp-content/uploads/2012/12/paper_56.pdf">Avoiding Unintended AI Behaviors.</a> Bill Hibbard. 2012 proceedings of the Fifth Conference on Artificial General Intelligence, eds. Joscha Bach, Ben Goertzel and Matthew Ikle. This paper won the Singularity Institute's 2012 Turing Prize for the Best AGI Safety Paper <a rel="nofollow" class="external autonumber" href="http://singularity.org/blog/2012/12/19/december-2012-newsletter/">[3]</a> .</span></li>
<li id="cite_note-AGI-12b-66"><span class="mw-cite-backlink"><b><a href="#cite_ref-AGI-12b_66-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://agi-conference.org/2012/wp-content/uploads/2012/12/paper_57.pdf">Decision Support for Safe AI Design|.</a> Bill Hibbard. 2012 proceedings of the Fifth Conference on Artificial General Intelligence, eds. Joscha Bach, Ben Goertzel and Matthew Ikle.</span></li>
<li id="cite_note-berglas-67"><span class="mw-cite-backlink"><b><a href="#cite_ref-berglas_67-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html#mozTocId817119">Artificial Intelligence Will Kill Our Grandchildren (Singularity), Dr Anthony Berglas</a></span></li>
<li id="cite_note-philosophical-68"><span class="mw-cite-backlink"><b><a href="#cite_ref-philosophical_68-0">^</a></b></span> <span class="reference-text">The Singularity: A Philosophical Analysis David J. Chalmers</span></li>
<li id="cite_note-nytimes_july09-69"><span class="mw-cite-backlink"><b><a href="#cite_ref-nytimes_july09_69-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.nytimes.com/2009/07/26/science/26robot.html?_r=1&ref=todayspaper">Scientists Worry Machines May Outsmart Man</a> By JOHN MARKOFF, NY Times, July 26, 2009.</span></li>
<li id="cite_note-palmer-70"><span class="mw-cite-backlink"><b><a href="#cite_ref-palmer_70-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://news.bbc.co.uk/2/hi/technology/8182003.stm">Call for debate on killer robots</a>, By Jason Palmer, Science and technology reporter, BBC News, 8/3/09.</span></li>
<li id="cite_note-dailytech-71"><span class="mw-cite-backlink"><b><a href="#cite_ref-dailytech_71-0">^</a></b></span> <span class="reference-text">Mick, Jason. <a rel="nofollow" class="external text" href="http://www.dailytech.com/New%20Navyfunded%20Report%20Warns%20of%20War%20Robots%20Going%20Terminator/article14298.htm">New Navy-funded Report Warns of War Robots Going "Terminator"</a>, Blog, dailytech.com, February 17, 2009.</span></li>
<li id="cite_note-engadget-72"><span class="mw-cite-backlink"><b><a href="#cite_ref-engadget_72-0">^</a></b></span> <span class="reference-text">Flatley, Joseph L. <a rel="nofollow" class="external text" href="http://www.engadget.com/2009/02/18/navy-report-warns-of-robot-uprising-suggests-a-strong-moral-com/">Navy report warns of robot uprising, suggests a strong moral compass</a>, engadget.com, 18 February 2009.</span></li>
<li id="cite_note-microsoft-73"><span class="mw-cite-backlink"><b><a href="#cite_ref-microsoft_73-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://research.microsoft.com/en-us/um/people/horvitz/AAAI_Presidential_Panel_2008-2009.htm">AAAI Presidential Panel on Long-Term AI Futures 2008–2009 Study</a>, Association for the Advancement of Artificial Intelligence, Accessed 7/26/09.</span></li>
<li id="cite_note-asimovlaws-74"><span class="mw-cite-backlink"><b><a href="#cite_ref-asimovlaws_74-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.asimovlaws.com/articles/archives/2004/07/why_we_need_fri_1.html">Article at Asimovlaws.com</a>, July 2004, accessed 7/27/2009.</span></li>
<li id="cite_note-75"><span class="mw-cite-backlink"><b><a href="#cite_ref-75">^</a></b></span> <span class="reference-text">(<a href="#CITEREFSingularity_Institute_for_Artificial_Intelligence2004">Singularity Institute for Artificial Intelligence 2004</a>)</span></li>
<li id="cite_note-76"><span class="mw-cite-backlink"><b><a href="#cite_ref-76">^</a></b></span> <span class="reference-text">(<a href="#CITEREFKurzweil2001">Kurzweil 2001</a>)</span></li>
<li id="cite_note-77"><span class="mw-cite-backlink"><b><a href="#cite_ref-77">^</a></b></span> <span class="reference-text">(<a href="#CITEREFKurzweil2005">Kurzweil 2005</a>)</span></li>
<li id="cite_note-civilization-78"><span class="mw-cite-backlink"><b><a href="#cite_ref-civilization_78-0">^</a></b></span> <span class="reference-text">Zubrin, Robert. 1999, <i>Entering Space – Creating a Spacefaring Civilization</i></span></li>
<li id="cite_note-79"><span class="mw-cite-backlink"><b><a href="#cite_ref-79">^</a></b></span> <span class="reference-text">(<a href="#CITEREFJoy2000">Joy 2000</a>)</span></li>
<li id="cite_note-80"><span class="mw-cite-backlink"><b><a href="#cite_ref-80">^</a></b></span> <span class="reference-text">(<a href="#CITEREFAcceleration_Studies_Foundation2007">Acceleration Studies Foundation 2007</a>)</span></li>
<li id="cite_note-dreyfus-81"><span class="mw-cite-backlink"><b><a href="#cite_ref-dreyfus_81-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFDreyfusDreyfus2000">Dreyfus &amp; Dreyfus 2000</a>, p.&#160;xiv:</span>
<blockquote>
<p><span class="reference-text">"(...) The truth is that human intelligence can never be replaced with machine intelligence simply because we are not ourselves "thinking machines" in the sense in which that term is commonly understood.<a href="#CITEREFHawking1998">Hawking (1998</a>) (...)"</span></p>
</blockquote>
<span class="reference-text">&#160;:</span>
<blockquote>
<p><span class="reference-text">Some people say that computers can never show true intelligence whatever that may be. But it seems to me that if very complicated chemical molecules can operate in humans to make them intelligent then equally complicated electronic circuits can also make computers act in an intelligent way. And if they are intelligent they can presumably design computers that have even greater complexity and intelligence.</span></p>
</blockquote>
</li>
<li id="cite_note-thelightsinthetunnel-82"><span class="mw-cite-backlink"><b><a href="#cite_ref-thelightsinthetunnel_82-0">^</a></b></span> <span class="reference-text">Ford, Martin, <i><a rel="nofollow" class="external text" href="http://www.thelightsinthetunnel.com">The Lights in the Tunnel: Automation, Accelerating Technology and the Economy of the Future</a></i>, Acculant Publishing, 2009, <a href="Special_BookSources/9781448659814" class="internal mw-magiclink-isbn">ISBN 978-1-4486-5981-4</a></span></li>
<li id="cite_note-nytimes-83"><span class="mw-cite-backlink"><b><a href="#cite_ref-nytimes_83-0">^</a></b></span> <span class="reference-text"><span class="citation news">Markoff, John (2011-03-04). <a rel="nofollow" class="external text" href="http://www.nytimes.com/2011/03/05/science/05legal.html">"Armies of Expensive Lawyers, Replaced by Cheaper Software"</a>. <i>The New York Times</i><span class="printonly">. <a rel="nofollow" class="external free" href="http://www.nytimes.com/2011/03/05/science/05legal.html">http://www.nytimes.com/2011/03/05/science/05legal.html</a></span>.</span></span></li>
<li id="cite_note-google13-84"><span class="mw-cite-backlink"><b><a href="#cite_ref-google13_84-0">^</a></b></span> <span class="reference-text">Theodore Modis, <a rel="nofollow" class="external text" href="http://www.google.com/search?q=cache:5qYje63ynXwJ:ourworld.compuserve.com/homepages/tmodis/TedWEB.htm+http://ourworld.compuserve.com/homepages/tmodis/TedWEB.htm&cd=1&hl=en&ct=clnk&gl=us">Forecasting the Growth of Complexity and Change</a>, <i>Technological Forecasting &amp; Social Change</i>, 69, No 4, 2002</span></li>
<li id="cite_note-Singularity_Myth-85"><span class="mw-cite-backlink">^ <a href="#cite_ref-Singularity_Myth_85-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Singularity_Myth_85-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.growth-dynamics.com/articles/Kurzweil.htm">Modis, Theodore. <i>The Singularity Myth</i></a></span></li>
<li id="cite_note-technological14-86"><span class="mw-cite-backlink">^ <a href="#cite_ref-technological14_86-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-technological14_86-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Huebner, Jonathan (2005) A Possible Declining Trend for Worldwide Innovation, <i>Technological Forecasting &amp; Social Change</i>, October 2005, pp. 980–6</span></li>
<li id="cite_note-accelerating-87"><span class="mw-cite-backlink"><b><a href="#cite_ref-accelerating_87-0">^</a></b></span> <span class="reference-text">Smart, John (September 2005), On Huebner Innovation, Acceleration Studies Foundation, <a rel="nofollow" class="external free" href="http://accelerating.org/articles/huebnerinnovation.html">http://accelerating.org/articles/huebnerinnovation.html</a>, retrieved on 2007-08-07</span></li>
<li id="cite_note-cnet-88"><span class="mw-cite-backlink"><b><a href="#cite_ref-cnet_88-0">^</a></b></span> <span class="reference-text">Krazit, Tom. <a rel="nofollow" class="external text" href="http://news.cnet.com/2100-1006_3-6119618.html">Intel pledges 80 cores in five years</a>, <i>CNET News</i>, 26 September 2006.</span></li>
<li id="cite_note-cliodynamics-89"><span class="mw-cite-backlink"><b><a href="#cite_ref-cliodynamics_89-0">^</a></b></span> <span class="reference-text">See, e.g., Korotayev A., Malkov A., Khaltourina D. <a rel="nofollow" class="external text" href="http://cliodynamics.ru/index.php?option=com_content&task=view&id=124&Itemid=70"><i>Introduction to Social Macrodynamics: Compact Macromodels of the World System Growth</i></a>. Moscow: URSS Publishers, 2006; Korotayev A. V. <a rel="nofollow" class="external text" href="http://jwsr.ucr.edu/archive/vol11/number1/pdf/jwsr-v11n1-korotayev.pdf">A Compact Macromodel of World System Evolution // Journal of World-Systems Research 11/1 (2005): 79–93.</a></span></li>
<li id="cite_note-90"><span class="mw-cite-backlink"><b><a href="#cite_ref-90">^</a></b></span> <span class="reference-text">For a detailed mathematical analysis of this issue see <a rel="nofollow" class="external text" href="http://arxiv.org/abs/1206.0496">A Compact Mathematical Model of the World System Economic and Demographic Growth, 1 CE – 1973 CE</a>.</span></li>
<li id="cite_note-interstellar-91"><span class="mw-cite-backlink"><b><a href="#cite_ref-interstellar_91-0">^</a></b></span> <span class="reference-text">Interstellar Travel: The Wait Calculation and the Incentive Trap of Progress, JBIS Vol 59, N.7 July 2006</span></li>
<li id="cite_note-university-92"><span class="mw-cite-backlink"><b><a href="#cite_ref-university_92-0">^</a></b></span> <span class="reference-text">Tainter, Joseph (1988) "The Collapse of Complex Societies" (Cambridge University Press)</span></li>
<li id="cite_note-PZMyers-93"><span class="mw-cite-backlink"><b><a href="#cite_ref-PZMyers_93-0">^</a></b></span> <span class="reference-text"><span class="citation" id="CITEREFMyers">Myers, PZ, <a rel="nofollow" class="external text" href="http://scienceblogs.com/pharyngula/2009/02/singularly_silly_singularity.php"><i>Singularly Silly Singularity</i></a><span class="printonly">, <a rel="nofollow" class="external free" href="http://scienceblogs.com/pharyngula/2009/02/singularly_silly_singularity.php">http://scienceblogs.com/pharyngula/2009/02/singularly_silly_singularity.php</a></span><span class="reference-accessdate">, retrieved 2009-04-13</span></span></span></li>
<li id="cite_note-moreblades-94"><span class="mw-cite-backlink"><b><a href="#cite_ref-moreblades_94-0">^</a></b></span> <span class="reference-text"><span class="citation" id="CITEREFAnonymous2006">Anonymous (18 March 2006), <a rel="nofollow" class="external text" href="http://www.economist.com/science/displaystory.cfm?story_id=5624861">"More blades good"</a>, <i>The Economist</i> (London) <b>378</b> (8469): 85<span class="printonly">, <a rel="nofollow" class="external free" href="http://www.economist.com/science/displaystory.cfm?story_id=5624861">http://www.economist.com/science/displaystory.cfm?story_id=5624861</a></span></span></span></li>
<li id="cite_note-plugandpray-film-95"><span class="mw-cite-backlink"><b><a href="#cite_ref-plugandpray-film_95-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.plugandpray-film.de/en/">Plug &amp; Pray</a> Documentary film (2010) about the promise, problems and ethics of artificial intelligence and robotics</span></li>
<li id="cite_note-cnet15-96"><span class="mw-cite-backlink"><b><a href="#cite_ref-cnet15_96-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://news.cnet.com/robo-scientist-makes-gene-discovery-on-its-own/?tag=newsLatestHeadlinesArea.0">Robo-scientist makes gene discovery-on its own | Crave – CNET</a></span></li>
<li id="cite_note-wired-97"><span class="mw-cite-backlink"><b><a href="#cite_ref-wired_97-0">^</a></b></span> <span class="reference-text"><span class="citation news">Keim, Brandon (2009-04-02). <a rel="nofollow" class="external text" href="http://www.wired.com/wiredscience/2009/04/newtonai/">"Computer Program Self-Discovers Laws of Physics"</a>. <i>Wired</i><span class="printonly">. <a rel="nofollow" class="external free" href="http://www.wired.com/wiredscience/2009/04/newtonai/">http://www.wired.com/wiredscience/2009/04/newtonai/</a></span>.</span></span></li>
<li id="cite_note-cornell-98"><span class="mw-cite-backlink"><b><a href="#cite_ref-cornell_98-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.news.cornell.edu/stories/April09/NaturalLaws.ws.html">Cornell Chronicle: Computer derives natural laws</a></span></li>
<li id="cite_note-IEET_interview-99"><span class="mw-cite-backlink"><b><a href="#cite_ref-IEET_interview_99-0">^</a></b></span> <span class="reference-text"><span class="citation web">Michael Anissimov. <a rel="nofollow" class="external text" href="http://ieet.org/index.php/IEET/more/2572/">"Interview with Dr. Steel"</a>. Institute for Ethics and Emerging Technologies<span class="printonly">. <a rel="nofollow" class="external free" href="http://ieet.org/index.php/IEET/more/2572/">http://ieet.org/index.php/IEET/more/2572/</a></span><span class="reference-accessdate">. Retrieved 2009-08-29</span>.</span></span></li>
<li id="cite_note-Paranoia_magazine-100"><span class="mw-cite-backlink"><b><a href="#cite_ref-Paranoia_magazine_100-0">^</a></b></span> <span class="reference-text"><span class="citation news">Dr. Steel (Spring 2005). <a rel="nofollow" class="external text" href="http://www.paranoiamagazine.com/backissues.html">"Multi-Media Symbiosis and the Evolution of Electronic Life"</a>. Paranoia: The Conspiracy Reader, Issue 38 (back issue)<span class="printonly">. <a rel="nofollow" class="external free" href="http://www.paranoiamagazine.com/backissues.html">http://www.paranoiamagazine.com/backissues.html</a></span><span class="reference-accessdate">. Retrieved 2010-04-16</span>.</span></span></li>
<li id="cite_note-Paranoia_magazine_clipping-101"><span class="mw-cite-backlink"><b><a href="#cite_ref-Paranoia_magazine_clipping_101-0">^</a></b></span> <span class="reference-text"><span class="citation news">Dr. Steel (Spring 2005). <a rel="nofollow" class="external text" href="http://worlddominationtoys.com/drsteel/clippings_paranoia.html">"Multi-Media Symbiosis and the Evolution of Electronic Life"</a>. <i>World Domination Toys</i> (clipping from Paranoia: The Conspiracy Reader)<span class="printonly">. <a rel="nofollow" class="external free" href="http://worlddominationtoys.com/drsteel/clippings_paranoia.html">http://worlddominationtoys.com/drsteel/clippings_paranoia.html</a></span><span class="reference-accessdate">. Retrieved 2010-04-16</span>.</span></span></li>
</ol>
</div>
<h2><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=14.php.html" title="Edit section: References">edit</a>]</span> <span class="mw-headline" id="References">References</span></h2>
<div class="refbegin references-column-count references-column-count-2" style="-moz-column-count: 2; -webkit-column-count: 2; column-count: 2;">
<ul>
<li><span class="citation" id="CITEREFAcceleration_Studies_Foundation2007">Acceleration Studies Foundation (2007), <a rel="nofollow" class="external text" href="http://www.accelerating.org/about.html"><i>ASF: About the Foundation</i></a><span class="printonly">, <a rel="nofollow" class="external free" href="http://www.accelerating.org/about.html">http://www.accelerating.org/about.html</a></span><span class="reference-accessdate">, retrieved 2007-11-13</span></span></li>
<li><span class="citation" id="CITEREFAnonymous2006">Anonymous (18 March 2006), <a rel="nofollow" class="external text" href="http://www.economist.com/science/displaystory.cfm?story_id=5624861">"More blades good"</a>, <i>The Economist</i> (London) <b>378</b> (8469): 85<span class="printonly">, <a rel="nofollow" class="external free" href="http://www.economist.com/science/displaystory.cfm?story_id=5624861">http://www.economist.com/science/displaystory.cfm?story_id=5624861</a></span></span></li>
<li><span class="citation" id="CITEREFBell2002"><a href="James_John_Bell" title="James John Bell">Bell, James John</a> (2002), <a rel="nofollow" class="external text" href="http://www.earthisland.org/journal/index.php/eij/article/technotopia_the_death_of_nature/"><i>Technotopia and the Death of Nature: Clones, Supercomputers, and Robots</i></a>, Earth Island Journal (first published in the November/December 2001 issue of the <i>Earth First! Journal</i>)<span class="printonly">, <a rel="nofollow" class="external free" href="http://www.earthisland.org/journal/index.php/eij/article/technotopia_the_death_of_nature/">http://www.earthisland.org/journal/index.php/eij/article/technotopia_the_death_of_nature/</a></span><span class="reference-accessdate">, retrieved 2007-08-07</span></span></li>
<li><span class="citation" id="CITEREFBell2003">Bell, James John (1 May 2003), <a rel="nofollow" class="external text" href="http://www.mindfully.org/Technology/2003/Singularity-Bell1may03.htm">"Exploring The "Singularity""</a>, <i>The Futurist</i> (<a href="World_Future_Society" title="World Future Society">World Future Society</a> (mindfully.org))<span class="printonly">, <a rel="nofollow" class="external free" href="http://www.mindfully.org/Technology/2003/Singularity-Bell1may03.htm">http://www.mindfully.org/Technology/2003/Singularity-Bell1may03.htm</a></span><span class="reference-accessdate">, retrieved 2007-08-07</span></span></li>
<li><span class="citation" id="CITEREFBerglas2008">Berglas, Anthony (2008), <a rel="nofollow" class="external text" href="http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html"><i>Artificial Intelligence will Kill our Grandchildren</i></a><span class="printonly">, <a rel="nofollow" class="external free" href="http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html">http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html</a></span><span class="reference-accessdate">, retrieved 2008-06-13</span></span></li>
<li><span class="citation" id="CITEREFBroderick2001"><a href="Damien_Broderick" title="Damien Broderick">Broderick, Damien</a> (2001), <i>The Spike: How Our Lives Are Being Transformed by Rapidly Advancing Technologies</i>, New York: Forge, <a href="International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="Special_BookSources/0-312-87781-1" title="Special:BookSources/0-312-87781-1">0-312-87781-1</a></span></li>
<li><span class="citation" id="CITEREFBostrom2002"><a href="Nick_Bostrom" title="Nick Bostrom">Bostrom, Nick</a> (2002), <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/existential/risks.html">"Existential Risks"</a>, <i><a href="Journal_of_Evolution_and_Technology" title="Journal of Evolution and Technology" class="mw-redirect">Journal of Evolution and Technology</a></i> <b>9</b><span class="printonly">, <a rel="nofollow" class="external free" href="http://www.nickbostrom.com/existential/risks.html">http://www.nickbostrom.com/existential/risks.html</a></span><span class="reference-accessdate">, retrieved 2007-08-07</span></span></li>
<li><span class="citation" id="CITEREFBostrom2003">Bostrom, Nick (2003), <a rel="nofollow" class="external text" href="http://www.nickbostrom.com/ethics/ai.html">"Ethical Issues in Advanced Artificial Intelligence"</a>, <i>Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence</i> <b>2</b>: 12–17<span class="printonly">, <a rel="nofollow" class="external free" href="http://www.nickbostrom.com/ethics/ai.html">http://www.nickbostrom.com/ethics/ai.html</a></span><span class="reference-accessdate">, retrieved 2007-08-07</span></span></li>
<li><span class="citation" id="CITEREFDreyfusDreyfus2000"><a href="Hubert_Dreyfus" title="Hubert Dreyfus">Dreyfus, Hubert L.</a>; <a href="Stuart_Dreyfus" title="Stuart Dreyfus">Dreyfus, Stuart E.</a> (1 March 2000), <i>Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer</i> (1 ed.), New York: Free Press, <a href="International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="Special_BookSources/0-7432-0551-0" title="Special:BookSources/0-7432-0551-0">0-7432-0551-0</a></span></li>
<li><span class="citation" id="CITEREFFord2009">Ford, Martin (2009), <a rel="nofollow" class="external text" href="http://www.thelightsinthetunnel.com"><i>The Lights in the Tunnel: Automation, Accelerating Technology and the Economy of the Future</i></a>, CreateSpace, <a href="International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="Special_BookSources/978-1-4486-5981-4" title="Special:BookSources/978-1-4486-5981-4">978-1-4486-5981-4</a><span class="printonly">, <a rel="nofollow" class="external free" href="http://www.thelightsinthetunnel.com">http://www.thelightsinthetunnel.com</a></span>.</span></li>
<li><span class="citation" id="CITEREFGood1965"><a href="../I._J._Good" title="I. J. Good">Good, I. J.</a> (1965), Franz L. Alt and Morris Rubinoff, ed., <a rel="nofollow" class="external text" href="http://web.archive.org/web/20010527181244/http:/www.aeiveos.com/~bradbury/Authors/Computing/Good-IJ/SCtFUM.html">"Speculations Concerning the First Ultraintelligent Machine"</a>, <i>Advances in Computers</i> (<a href="Academic_Press" title="Academic Press">Academic Press</a>) <b>6</b>: 31–88, archived from <a rel="nofollow" class="external text" href="http://www.aeiveos.com/~bradbury/Authors/Computing/Good-IJ/SCtFUM.html">the original</a> on 2001-05-27<span class="printonly">, <a rel="nofollow" class="external free" href="http://web.archive.org/web/20010527181244/http:/www.aeiveos.com/~bradbury/Authors/Computing/Good-IJ/SCtFUM.html">http://web.archive.org/web/20010527181244/http://www.aeiveos.com/~bradbury/Authors/Computing/Good-IJ/SCtFUM.html</a></span><span class="reference-accessdate">, retrieved 2007-08-07</span></span></li>
<li><span class="citation" id="CITEREFHanson1998"><a href="Robin_Hanson" title="Robin Hanson">Hanson, Robin</a> (1998), <a rel="nofollow" class="external text" href="http://hanson.gmu.edu/vc.html#hanson"><i>Some Skepticism</i></a>, Robin Hanson<span class="printonly">, <a rel="nofollow" class="external free" href="http://hanson.gmu.edu/vc.html#hanson">http://hanson.gmu.edu/vc.html#hanson</a></span><span class="reference-accessdate">, retrieved 2009-06-19</span></span><sup class="noprint Inline-Template"><span title="&#160;since July 2009" style="white-space: nowrap;">[<i><a href="Wikipedia_Link_rot" title="Wikipedia:Link rot">dead link</a></i>]</span></sup></li>
<li><span class="citation" id="CITEREFHanson2008">Hanson, Robin (June 2008), "Economics of the Singularity", <i>IEEE Spectrum</i></span></li>
<li><span class="citation" id="CITEREFHawking1998"><a href="Stephen_Hawking" title="Stephen Hawking">Hawking, Stephen</a> (1998), <a rel="nofollow" class="external text" href="http://clinton2.nara.gov/Initiatives/Millennium/shawking.html"><i>Science in the Next Millennium: Remarks by Stephen Hawking</i></a><span class="printonly">, <a rel="nofollow" class="external free" href="http://clinton2.nara.gov/Initiatives/Millennium/shawking.html">http://clinton2.nara.gov/Initiatives/Millennium/shawking.html</a></span><span class="reference-accessdate">, retrieved 2007-11-13</span></span></li>
<li><span class="citation" id="CITEREFHawkins1983"><a href="Gerald_Hawkins" title="Gerald Hawkins">Hawkins, Gerald S.</a> (August 1983), <i>Mindsteps to the Cosmos</i>, HarperCollins, <a href="International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="Special_BookSources/0-06-015156-0" title="Special:BookSources/0-06-015156-0">0-06-015156-0</a></span></li>
<li><span class="citation" id="CITEREFHeylighen2007"><a href="Francis_Heylighen" title="Francis Heylighen">Heylighen, Francis</a> (2007), <a rel="nofollow" class="external text" href="http://pespmc1.vub.ac.be/Papers/AcceleratingEvolution.pdf">"Accelerating Socio-Technological Evolution: from ephemeralization and stigmergy to the global brain"</a>, in <a href="George_Modelski" title="George Modelski">Modelski</a>, G.; Devezas, T.; Thompson, W., <i>Globalization as an Evolutionary Process: Modeling Global Change</i>, London: Routledge, <a href="International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="Special_BookSources/978-0-415-77361-4" title="Special:BookSources/978-0-415-77361-4">978-0-415-77361-4</a><span class="printonly">, <a rel="nofollow" class="external free" href="http://pespmc1.vub.ac.be/Papers/AcceleratingEvolution.pdf">http://pespmc1.vub.ac.be/Papers/AcceleratingEvolution.pdf</a></span></span></li>
<li><span class="citation" id="CITEREFJohansenSornette2001">Johansen, Anders; Sornette, Didier (25 January 2001), <a rel="nofollow" class="external text" href="http://hjem.get2net.dk/kgs/growthphysA.pdf">"Finite-time singularity in the dynamics of the world population, economic and financial indices"</a> (PDF), <i>Physica A</i> <b>294</b> (3–4): 465–502, <a href="ArXiv" title="ArXiv">arXiv</a>:<a rel="nofollow" class="external text" href="http://arxiv.org/abs/cond-mat/0002075">cond-mat/0002075</a>, <a href="Bibcode" title="Bibcode">Bibcode</a> <a rel="nofollow" class="external text" href="http://adsabs.harvard.edu/abs/2001PhyA..294..465J">2001PhyA..294..465J</a>, <a href="Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="http://dx.doi.org/10.1016/S0378-4371(01)00105-4">10.1016/S0378-4371(01)00105-4</a><span class="printonly">, <a rel="nofollow" class="external free" href="http://hjem.get2net.dk/kgs/growthphysA.pdf">http://hjem.get2net.dk/kgs/growthphysA.pdf</a></span><span class="reference-accessdate">, retrieved 2007-10-30</span></span></li>
<li><span class="citation" id="CITEREFJoy2000"><a href="Bill_Joy" title="Bill Joy">Joy, Bill</a> (April 2000), <a rel="nofollow" class="external text" href="http://www.wired.com/wired/archive/8.04/joy.html">"Why the future doesn’t need us"</a>, <i><a href="Wired_(magazine)" title="Wired (magazine)">Wired Magazine</a></i> (Viking Adult) (8.04), <a href="International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="Special_BookSources/0-670-03249-2" title="Special:BookSources/0-670-03249-2">0-670-03249-2</a><span class="printonly">, <a rel="nofollow" class="external free" href="http://www.wired.com/wired/archive/8.04/joy.html">http://www.wired.com/wired/archive/8.04/joy.html</a></span><span class="reference-accessdate">, retrieved 2007-08-07</span></span></li>
<li><span class="citation" id="CITEREFKurzweil2001"><a href="Raymond_Kurzweil" title="Raymond Kurzweil" class="mw-redirect">Kurzweil, Raymond</a> (2001), <a rel="nofollow" class="external text" href="http://lifeboat.com/ex/law.of.accelerating.returns"><i>The Law of Accelerating Returns</i></a>, Lifeboat Foundation<span class="printonly">, <a rel="nofollow" class="external free" href="http://lifeboat.com/ex/law.of.accelerating.returns">http://lifeboat.com/ex/law.of.accelerating.returns</a></span><span class="reference-accessdate">, retrieved 2007-08-07</span></span></li>
<li><span class="citation" id="CITEREFKurzweil2005">Kurzweil, Raymond (2005), <i><a href="The_Singularity_Is_Near" title="The Singularity Is Near">The Singularity Is Near</a></i>, New York: Viking, <a href="International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="Special_BookSources/0-670-03384-7" title="Special:BookSources/0-670-03384-7">0-670-03384-7</a></span></li>
<li><span class="citation" id="CITEREFMoravec1992"><a href="Hans_Moravec" title="Hans Moravec">Moravec, Hans</a> (January 1992), <a rel="nofollow" class="external text" href="http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1992/CyberPigs.html">"Pigs in Cyberspace"</a>, <i>On the Cosmology and Ecology of Cyberspace</i><span class="printonly">, <a rel="nofollow" class="external free" href="http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1992/CyberPigs.html">http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1992/CyberPigs.html</a></span><span class="reference-accessdate">, retrieved 2007-11-21</span></span></li>
<li><span class="citation Journal" id="CITEREFSchmidhuber2006"><a href="J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">Schmidhuber, Jürgen</a> (29 June 2006). "New Millennium AI and the Convergence of History". <a href="ArXiv" title="ArXiv">arXiv</a>:<a rel="nofollow" class="external text" href="http://arxiv.org/abs/cs/0606081">cs/0606081</a>&#160;[<a rel="nofollow" class="external text" href="http://arxiv.org/archive/cs.AI">cs.AI</a>].</span></li>
<li><span class="citation" id="CITEREFSingularity_Institute_for_Artificial_Intelligence2002"><a href="Singularity_Institute_for_Artificial_Intelligence" title="Singularity Institute for Artificial Intelligence" class="mw-redirect">Singularity Institute for Artificial Intelligence</a> (2002), <i>Why Artificial Intelligence?</i></span> <a rel="nofollow" class="external text" href="http://web.archive.org/20061004201151/www.singinst.org/intro/whyAI-print.html">Archived</a> October 4, 2006 at the <a href="Wayback_Machine" title="Wayback Machine">Wayback Machine</a></li>
<li><span class="citation" id="CITEREFSingularity_Institute_for_Artificial_Intelligence2004">Singularity Institute for Artificial Intelligence (2004), <a rel="nofollow" class="external text" href="http://www.asimovlaws.com/"><i>3 Laws Unsafe</i></a><span class="printonly">, <a rel="nofollow" class="external free" href="http://www.asimovlaws.com/">http://www.asimovlaws.com/</a></span><span class="reference-accessdate">, retrieved 2007-08-07</span></span></li>
<li><span class="citation" id="CITEREFSingularity_Institute_for_Artificial_Intelligence2007">Singularity Institute for Artificial Intelligence (2007), <a rel="nofollow" class="external text" href="http://www.singinst.org/overview/whatisthesingularity"><i>What is the Singularity?</i></a><span class="printonly">, <a rel="nofollow" class="external free" href="http://www.singinst.org/overview/whatisthesingularity">http://www.singinst.org/overview/whatisthesingularity</a></span><span class="reference-accessdate">, retrieved 2008-01-04</span></span></li>
<li><span class="citation" id="CITEREFSmart2005"><a href="John_Smart_(futurist)" title="John Smart (futurist)">Smart, John</a> (September 2005), <a rel="nofollow" class="external text" href="http://accelerating.org/articles/huebnerinnovation.html"><i>On Huebner Innovation</i></a>, Acceleration Studies Foundation<span class="printonly">, <a rel="nofollow" class="external free" href="http://accelerating.org/articles/huebnerinnovation.html">http://accelerating.org/articles/huebnerinnovation.html</a></span><span class="reference-accessdate">, retrieved 2007-08-07</span></span></li>
<li><span class="citation" id="CITEREFUlam1958"><a href="Stanislaw_Ulam" title="Stanislaw Ulam">Ulam, Stanislaw</a> (May 1958), "Tribute to John von Neumann", <i>Bulletin of the American Mathematical Society</i> <b>64</b> (nr 3, part 2): 1–49</span></li>
<li><span class="citation" id="CITEREFVinge"><a href="Vernor_Vinge" title="Vernor Vinge">Vinge, Vernor</a> (30–31 March 1993), <a rel="nofollow" class="external text" href="http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html">"The Coming Technological Singularity"</a>, <i>Vision-21: Interdisciplinary Science &amp; Engineering in the Era of CyberSpace, proceedings of a Symposium held at NASA Lewis Research Center</i> (<a href="NASA" title="NASA">NASA</a> Conference Publication CP-10129)<span class="printonly">, <a rel="nofollow" class="external free" href="http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html">http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html</a></span><span class="reference-accessdate">, retrieved 2007-08-07</span></span>. See also <a rel="nofollow" class="external text" href="http://mindstalk.net/vinge/vinge-sing.html">this HTML version</a>, retrieved on 2009-03-29.</li>
<li><span class="citation" id="CITEREFWarwick2004"><a href="Kevin_Warwick" title="Kevin Warwick">Warwick, Kevin</a> (2004), <i>March of The Machines</i>, University of Illinois Press, <a href="International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="Special_BookSources/978-0-252-07223-9" title="Special:BookSources/978-0-252-07223-9">978-0-252-07223-9</a></span></li>
</ul>
</div>
<h2><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=15.php.html" title="Edit section: External links">edit</a>]</span> <span class="mw-headline" id="External_links">External links</span></h2>
<table class="metadata plainlinks ambox ambox-style ambox-external_links" style="">
<tr>
<td class="mbox-image">
<div style="width: 52px;"><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/40px-Edit-clear.svg.png" width="40" height="40" srcset="//upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/60px-Edit-clear.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/f/f2/Edit-clear.svg/80px-Edit-clear.svg.png 2x" /></div>
</td>
<td class="mbox-text" style=""><span class="mbox-text-span">This article's <b>use of <a href="Wikipedia_External_links" title="Wikipedia:External links">external links</a> may not follow Wikipedia's policies or guidelines</b>. <span class="hide-when-compact">Please <a class="external text" href="../../w/index-title=Technological_singularity&action=edit.php.html">improve this article</a> by removing <a href="Wikipedia_What_Wikipedia_is_not#Wikipedia_is_not_a_mirror_or_a_repository_of_links.2C_images.2C_or_media_files" title="Wikipedia:What Wikipedia is not">excessive</a> or <a href="Wikipedia_External_links" title="Wikipedia:External links">inappropriate</a> external links, and converting useful links where appropriate into <a href="Wikipedia_Citing_sources" title="Wikipedia:Citing sources">footnote references</a>.</span> <small><i>(March 2011)</i></small> </span></td>
</tr>
</table>
<div id="section_SpokenWikipedia" class="infobox sisterproject plainlinks haudio">
<div style="text-align: center; white-space:nowrap"><b>Listen to this article</b> (<a href="../File_TechSingularity.ogg" title="File:TechSingularity.ogg">info/dl</a>)
<div class="center">
<div class="floatnone">
<div class="mediaContainer" style="position:relative;display:block;width:200px"><audio id="mwe_player_1" style="width:200px;height:23px" poster="//bits.wikimedia.org/static-1.21wmf9/skins/common/images/icons/fileicon-ogg.png" controls="" preload="none" class="kskin" data-durationhint="1679.9913151927" data-startoffset="0" data-mwtitle="TechSingularity.ogg" data-mwprovider="wikimediacommons"><source src="//upload.wikimedia.org/wikipedia/commons/5/5c/TechSingularity.ogg" type="audio/ogg; codecs=&quot;vorbis&quot;" data-title="Original ogg, 0 × 0 (98kbps)" data-shorttitle="Ogg source" data-width="0" data-height="0" data-bandwidth="97597"></source>Sorry, your browser either has JavaScript disabled or does not have any supported player.<br />
You can <a href="http://upload.wikimedia.org/wikipedia/commons/5/5c/TechSingularity.ogg">download the clip</a> or <a href="http://www.mediawiki.org/wiki/Extension:TimedMediaHandler/Client_download">download a player</a> to play the clip in your browser.</audio></div>
</div>
</div>
</div>
<div style="float: left; margin-left: 5px;">
<div class="floatnone"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Sound-icon.svg/45px-Sound-icon.svg.png" width="45" height="34" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/4/47/Sound-icon.svg/68px-Sound-icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/47/Sound-icon.svg/90px-Sound-icon.svg.png 2x" /></div>
</div>
<div style="font-size: xx-small; line-height: 1.6em; margin-left: 60px;">This audio file was created from a revision of the "<span class="fn">Technological singularity</span>" article dated 2010-04-03, and does not reflect subsequent edits to the article. (<a href="Wikipedia_Media_help" title="Wikipedia:Media help">Audio help</a>)</div>
<div style="text-align: center; clear: both"><b><a href="Wikipedia_Spoken_articles" title="Wikipedia:Spoken articles">More spoken articles</a></b></div>
</div>
<div style="right:30px; display:none;" class="metadata topicon" id="spoken-icon"><a href="../File_TechSingularity.ogg" title="File:TechSingularity.ogg"><img alt="Sound-icon.svg" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Sound-icon.svg/15px-Sound-icon.svg.png" width="15" height="11" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/4/47/Sound-icon.svg/23px-Sound-icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/47/Sound-icon.svg/30px-Sound-icon.svg.png 2x" /></a></div>
<ul>
<li><a rel="nofollow" class="external text" href="http://www.singularity.com/researchlinks.html#1">Singularity-related research links, from Ray Kurzweil, author of <i>The Singularity is Near</i></a></li>
</ul>
<h3><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=16.php.html" title="Edit section: Essays and articles">edit</a>]</span> <span class="mw-headline" id="Essays_and_articles">Essays and articles</span></h3>
<ul>
<li><a rel="nofollow" class="external text" href="http://lifeboat.com/ex/singularities.and.nightmares">Singularities and Nightmares: Extremes of Optimism and Pessimism About the Human Future</a> by <a href="David_Brin" title="David Brin">David Brin</a></li>
<li><a rel="nofollow" class="external text" href="http://hanson.gmu.edu/vi.html">A Critical Discussion of Vinge’s Singularity Concept</a> by <a href="Robin_Hanson" title="Robin Hanson">Robin Hanson</a></li>
<li><a rel="nofollow" class="external text" href="http://hanson.gmu.edu/fastgrow.html">Is a singularity just around the corner</a> by Robin Hanson</li>
<li><a rel="nofollow" class="external text" href="http://www.accelerationwatch.com/history_brief.html">Brief History of Intellectual Discussion of Accelerating Change</a> by <a href="John_Smart_(futurist)" title="John Smart (futurist)">John Smart</a></li>
<li><a rel="nofollow" class="external text" href="http://www.edge.org/documents/archive/edge74.html">One Half of a Manifesto</a> by <a href="Jaron_Lanier" title="Jaron Lanier">Jaron Lanier</a>—a critique of "cybernetic totalism"</li>
<li><a rel="nofollow" class="external text" href="http://www.kurzweilai.net/meme/frame.html?main=/articles/art0236.html">One Half of an Argument</a>—<a href="Ray_Kurzweil" title="Ray Kurzweil">Ray Kurzweil</a>'s response to Lanier</li>
<li><a rel="nofollow" class="external text" href="http://fortnightlyreview.co.uk/2010/08/the-wonders-of-man-in-the-age-of-simulations/">A discussion of Kurzweil, Turkel and Lanier</a> by Roger Berkowitz</li>
<li><a rel="nofollow" class="external text" href="http://www.kk.org/thetechnium/archives/2006/02/the_singularity.php">The Singularity Is Always Near</a> by <a href="Kevin_Kelly_(editor)" title="Kevin Kelly (editor)">Kevin Kelly</a></li>
<li><a rel="nofollow" class="external text" href="http://www.kk.org/thetechnium/archives/2007/03/the_maesgarreau.php">The Maes-Garreau Point</a> by Kevin Kelly</li>
<li><a rel="nofollow" class="external text" href="http://consc.net/papers/singularity.pdf">"The Singularity – A Philosophical Analysis"</a> by <a href="David_Chalmers" title="David Chalmers">David Chalmers</a></li>
<li><a rel="nofollow" class="external text" href="http://www.time.com/time/health/article/0,8599,2048138,00.html">2045: The Year Man Becomes Immortal</a>, By Lev Grossman, time.com, Feb. 10, 2011.</li>
</ul>
<h3><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=17.php.html" title="Edit section: Singularity AI projects">edit</a>]</span> <span class="mw-headline" id="Singularity_AI_projects">Singularity AI projects</span></h3>
<ul>
<li><a rel="nofollow" class="external text" href="http://www.singinst.org/">The Singularity Institute for Artificial Intelligence</a></li>
<li><a rel="nofollow" class="external text" href="http://www.ssec.wisc.edu/~billh/g/mi.html">The SSEC Machine Intelligence Project</a></li>
<li><a rel="nofollow" class="external text" href="http://www.agiri.org/">The Artificial General Intelligence Research Institute</a></li>
</ul>
<h3><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=18.php.html" title="Edit section: Fiction">edit</a>]</span> <span class="mw-headline" id="Fiction">Fiction</span></h3>
<ul>
<li><a rel="nofollow" class="external text" href="http://www.ssec.wisc.edu/~billh/g/mcnrs.html">[Message Contains No Recognizable Symbols]</a> by <a href="Bill_Hibbard" title="Bill Hibbard">Bill Hibbard</a> is a story about a technological singularity subject to the constraint that natural human authors are unable to depict the actions and dialog of super-intelligent minds.</li>
<li><a rel="nofollow" class="external text" href="http://sifter.org/~simon/AfterLife/">After Life</a> by Simon Funk uses a complex narrative structure to explore the relationships among uploaded minds in a technological singularity.</li>
<li>In "<a href="List_of_Terminator__The_Sarah_Connor_Chronicles_minor_characters#John_Henry" title="List of Terminator: The Sarah Connor Chronicles minor characters" class="mw-redirect">The Turk</a>", an episode of the science fiction television series <i><a href="Terminator__The_Sarah_Connor_Chronicles" title="Terminator: The Sarah Connor Chronicles">Terminator: The Sarah Connor Chronicles</a></i>, John tells his mother about the singularity, a point in time when machines will be able to build superior versions of themselves without the aid of humans.</li>
<li><i><a href="Accelerando_(book)" title="Accelerando (book)" class="mw-redirect">Accelerando</a></i> by <a href="Charles_Stross" title="Charles Stross">Charles Stross</a></li>
<li><i><a href="Dresden_Codak" title="Dresden Codak">Dresden Codak</a></i>, a webcomic by Aaron Diaz, often contains plots relating to the singularity and <a href="Transhumanism" title="Transhumanism">transhumanism</a>, especially in the <i><a rel="nofollow" class="external text" href="http://www.dresdencodak.com/cartoons/dc_032.htm">Hob</a></i> story arc</li>
<li><a href="Endgame__Singularity" title="Endgame: Singularity">Endgame: Singularity</a> is an <a href="Open_source" title="Open source">open source</a> game where the player is AI, whose goal is to attain technological singularity/apotheosis.</li>
</ul>
<h3><span class="editsection">[<a href="../../w/index-title=Technological_singularity&action=edit&section=19.php.html" title="Edit section: Other links">edit</a>]</span> <span class="mw-headline" id="Other_links">Other links</span></h3>
<ul>
<li><a rel="nofollow" class="external text" href="http://www.jerrypournelle.com/reports/jerryp/singularity.html">Report on <i>The Stanford Singularity Summit</i></a></li>
<li><a rel="nofollow" class="external text" href="http://www.singinst.org/summit2007/quotes/">2007 quotes, Singularity Summit, San Francisco</a></li>
<li><a rel="nofollow" class="external text" href="http://www.spectrum.ieee.org/static/singularity">An IEEE report on the Singularity.</a></li>
<li><a rel="nofollow" class="external text" href="http://www.house.gov/jec/publications/110/nanotechnology_03-22-07.pdf">March 2007 Congressional Report on the Singularity</a><a rel="nofollow" class="external text" href="http://www.thenewatlantis.com/docLib/20120213_TheFutureisComingSoonerThanYouThink.pdf">Alternate Link</a></li>
<li><a rel="nofollow" class="external text" href="http://www.theglobaltransition.com">The Global Transition</a></li>
</ul>
<table cellspacing="0" class="navbox" style="border-spacing:0;;">
<tr>
<td style="padding:2px;">
<table cellspacing="0" class="nowraplinks hlist collapsible collapsed navbox-inner" style="border-spacing:0;background:transparent;color:inherit;;">
<tr>
<th scope="col" style=";" class="navbox-title" colspan="2">
<div class="noprint plainlinks hlist navbar mini" style="">
<ul>
<li class="nv-view"><a href="Template_Technology" title="Template:Technology"><span title="View this template" style=";;background:none transparent;border:none;">v</span></a></li>
<li class="nv-talk"><a href="Template_talk_Technology" title="Template talk:Technology"><span title="Discuss this template" style=";;background:none transparent;border:none;">t</span></a></li>
<li class="nv-edit"><a class="external text" href="../../w/index-title=Template_Technology&action=edit.php.html"><span title="Edit this template" style=";;background:none transparent;border:none;">e</span></a></li>
</ul>
</div>
<div class="" style="font-size:110%;"><a href="Technology" title="Technology">Technology</a></div>
</th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td class="navbox-abovebelow" style=";" colspan="2">
<div>
<ul>
<li><a href="Outline_of_technology" title="Outline of technology">Outline of technology</a></li>
<li><a href="Outline_of_applied_science" title="Outline of applied science">Outline of applied science</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Fields</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks navbox-subgroup" style="border-spacing:0;;;;">
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Agriculture" title="Agriculture">Agriculture</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Agricultural_engineering" title="Agricultural engineering">Agricultural engineering</a></li>
<li><a href="Aquaculture" title="Aquaculture">Aquaculture</a></li>
<li><a href="Fisheries_science" title="Fisheries science">Fisheries science</a></li>
<li><a href="Food_chemistry" title="Food chemistry">Food chemistry</a></li>
<li><a href="Food_engineering" title="Food engineering">Food engineering</a></li>
<li><a href="Food_microbiology" title="Food microbiology">Food microbiology</a></li>
<li><a href="Food_technology" title="Food technology">Food technology</a></li>
<li><a href="Genetic_use_restriction_technology" title="Genetic use restriction technology">GURT</a></li>
<li><a href="ICT_in_agriculture" title="ICT in agriculture">ICT in agriculture</a></li>
<li><a href="Nutrition" title="Nutrition">Nutrition</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Biomedical_technology" title="Biomedical technology">Biomedical</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Bioinformatics" title="Bioinformatics">Bioinformatics</a></li>
<li><a href="Biological_engineering" title="Biological engineering">Biological engineering</a></li>
<li><a href="Biomechatronics" title="Biomechatronics">Biomechatronics</a></li>
<li><a href="Biomedical_engineering" title="Biomedical engineering">Biomedical engineering</a></li>
<li><a href="Biotechnology" title="Biotechnology">Biotechnology</a></li>
<li><a href="Cheminformatics" title="Cheminformatics">Cheminformatics</a></li>
<li><a href="Genetic_engineering" title="Genetic engineering">Genetic engineering</a></li>
<li><a href="Healthcare_science" title="Healthcare science">Healthcare science</a></li>
<li><a href="Medical_research" title="Medical research">Medical research</a></li>
<li><a href="Medical_technology" title="Medical technology" class="mw-redirect">Medical technology</a></li>
<li><a href="Nanomedicine" title="Nanomedicine">Nanomedicine</a></li>
<li><a href="Neuroscience" title="Neuroscience">Neuroscience</a></li>
<li><a href="Neurotechnology" title="Neurotechnology">Neurotechnology</a></li>
<li><a href="Pharmacology" title="Pharmacology">Pharmacology</a></li>
<li><a href="Reproductive_technology" title="Reproductive technology">Reproductive technology</a></li>
<li><a href="Tissue_engineering" title="Tissue engineering">Tissue engineering</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Buildings and<br />
<a href="Construction" title="Construction">Construction</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Acoustical_engineering" title="Acoustical engineering">Acoustical engineering</a></li>
<li><a href="Architectural_engineering" title="Architectural engineering">Architectural engineering</a></li>
<li><a href="Building_services_engineering" title="Building services engineering">Building services engineering</a></li>
<li><a href="Civil_engineering" title="Civil engineering">Civil engineering</a></li>
<li><a href="Construction_engineering" title="Construction engineering">Construction engineering</a></li>
<li><a href="Domestic_technology" title="Domestic technology">Domestic technology</a></li>
<li><a href="Facade_engineering" title="Facade engineering">Facade engineering</a></li>
<li><a href="Fire_protection_engineering" title="Fire protection engineering">Fire protection engineering</a></li>
<li><a href="Safety_engineering" title="Safety engineering">Safety engineering</a></li>
<li><a href="Sanitary_engineering" title="Sanitary engineering">Sanitary engineering</a></li>
<li><a href="Structural_engineering" title="Structural engineering">Structural engineering</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Educational_technology" title="Educational technology">Educational</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Educational_software" title="Educational software">Educational software</a></li>
<li><a href="Digital_technologies_in_education" title="Digital technologies in education">Digital technologies in education</a></li>
<li><a href="Information_and_communication_technologies_in_education" title="Information and communication technologies in education">ICT in education</a></li>
<li><a href="Impact_of_technology_on_the_educational_system" title="Impact of technology on the educational system">Impact</a></li>
<li><a href="Multimedia_learning" title="Multimedia learning">Multimedia learning</a></li>
<li><a href="Virtual_campus" title="Virtual campus">Virtual campus</a></li>
<li><a href="Virtual_education" title="Virtual education">Virtual education</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Energy_technology" title="Energy technology">Energy</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Nuclear_engineering" title="Nuclear engineering">Nuclear engineering</a></li>
<li><a href="Nuclear_technology" title="Nuclear technology">Nuclear technology</a></li>
<li><a href="Petroleum_engineering" title="Petroleum engineering">Petroleum engineering</a></li>
<li><a href="Soft_energy_technology" title="Soft energy technology">Soft energy technology</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Environmental_technology" title="Environmental technology">Environmental</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Clean_technology" title="Clean technology">Clean technology</a></li>
<li><a href="Clean_coal_technology" title="Clean coal technology">Clean coal technology</a></li>
<li><a href="Ecological_design" title="Ecological design">Ecological design</a></li>
<li><a href="Ecological_engineering" title="Ecological engineering">Ecological engineering</a></li>
<li><a href="Ecotechnology" title="Ecotechnology">Ecotechnology</a></li>
<li><a href="Environmental_engineering" title="Environmental engineering">Environmental engineering</a></li>
<li><a href="Environmental_engineering_science" title="Environmental engineering science">Environmental engineering science</a></li>
<li><a href="Green_building" title="Green building">Green building</a></li>
<li><a href="Green_nanotechnology" title="Green nanotechnology">Green nanotechnology</a></li>
<li><a href="Landscape_engineering" title="Landscape engineering">Landscape engineering</a></li>
<li><a href="Renewable_energy" title="Renewable energy">Renewable energy</a></li>
<li><a href="Sustainable_design" title="Sustainable design">Sustainable design</a></li>
<li><a href="Sustainable_engineering" title="Sustainable engineering">Sustainable engineering</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Industrial_technology" title="Industrial technology">Industrial</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Automation" title="Automation">Automation</a></li>
<li><a href="Business_informatics" title="Business informatics">Business informatics</a></li>
<li><a href="Engineering_management" title="Engineering management">Engineering management</a></li>
<li><a href="Enterprise_engineering" title="Enterprise engineering">Enterprise engineering</a></li>
<li><a href="Computational_finance" title="Computational finance">Financial engineering</a></li>
<li><a href="Industrial_biotechnology" title="Industrial biotechnology">Industrial biotechnology</a></li>
<li><a href="Industrial_engineering" title="Industrial engineering">Industrial engineering</a></li>
<li><a href="Metallurgy" title="Metallurgy">Metallurgy</a></li>
<li><a href="Mining_engineering" title="Mining engineering">Mining engineering</a></li>
<li><a href="Productivity_improving_technologies_(historical)" title="Productivity improving technologies (historical)">Productivity improving technologies</a></li>
<li><a href="Research_and_development" title="Research and development">Research and development</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Information_and_communications_technology" title="Information and communications technology">IT and communications</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Artificial_intelligence" title="Artificial intelligence">Artificial intelligence</a></li>
<li><a href="Broadcast_engineering" title="Broadcast engineering">Broadcast engineering</a></li>
<li><a href="Computer_engineering" title="Computer engineering">Computer engineering</a></li>
<li><a href="Computer_science" title="Computer science">Computer science</a></li>
<li><a href="Information_technology" title="Information technology">Information technology</a></li>
<li><a href="Music_technology" title="Music technology">Music technology</a></li>
<li><a href="Ontology_engineering" title="Ontology engineering">Ontology engineering</a></li>
<li><a href="RF_engineering" title="RF engineering">RF engineering</a></li>
<li><a href="Software_engineering" title="Software engineering">Software engineering</a></li>
<li><a href="Telecommunications_engineering" title="Telecommunications engineering">Telecommunications engineering</a></li>
<li><a href="Visual_technology" title="Visual technology">Visual technology</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Military_technology" title="Military technology">Military</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Army_engineering_maintenance" title="Army engineering maintenance">Army engineering maintenance</a></li>
<li><a href="Electronic_warfare" title="Electronic warfare">Electronic warfare</a></li>
<li><a href="Military_communications" title="Military communications">Military communications</a></li>
<li><a href="Military_engineering" title="Military engineering">Military engineering</a></li>
<li><a href="Stealth_technology" title="Stealth technology">Stealth technology</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Transport" title="Transport">Transport</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Aerospace_engineering" title="Aerospace engineering">Aerospace engineering</a></li>
<li><a href="Automotive_engineering" title="Automotive engineering">Automotive engineering</a></li>
<li><a href="Naval_architecture" title="Naval architecture">Naval architecture</a></li>
<li><a href="Space_technology" title="Space technology">Space technology</a></li>
<li><a href="Traffic_engineering_(transportation)" title="Traffic engineering (transportation)">Traffic engineering</a></li>
<li><a href="Transport_engineering" title="Transport engineering">Transport engineering</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Other <a href="Applied_science" title="Applied science">applied sciences</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Cryogenics" title="Cryogenics">Cryogenics</a></li>
<li><a href="Electro-optics" title="Electro-optics">Electro-optics</a></li>
<li><a href="Electronics" title="Electronics">Electronics</a></li>
<li><a href="Engineering_geology" title="Engineering geology">Engineering geology</a></li>
<li><a href="Engineering_physics" title="Engineering physics">Engineering physics</a></li>
<li><a href="Hydraulics" title="Hydraulics">Hydraulics</a></li>
<li><a href="Materials_science" title="Materials science">Materials science</a></li>
<li><a href="Microtechnology" title="Microtechnology">Microtechnology</a></li>
<li><a href="Nanotechnology" title="Nanotechnology">Nanotechnology</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Other <a href="Engineering" title="Engineering">engineering</a> <a href="List_of_engineering_branches" title="List of engineering branches">fields</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Audio_engineering" title="Audio engineering">Audio</a></li>
<li><a href="Biochemical_engineering" title="Biochemical engineering">Biochemical</a></li>
<li><a href="Ceramic_engineering" title="Ceramic engineering">Ceramic</a></li>
<li><a href="Chemical_engineering" title="Chemical engineering">Chemical</a></li>
<li><a href="Polymer_engineering" title="Polymer engineering">Polymer</a></li>
<li><a href="Control_engineering" title="Control engineering">Control</a></li>
<li><a href="Electrical_engineering" title="Electrical engineering">Electrical</a></li>
<li><a href="Electronic_engineering" title="Electronic engineering">Electronic</a></li>
<li><a href="Entertainment_technology" title="Entertainment technology">Entertainment</a></li>
<li><a href="Geotechnical_engineering" title="Geotechnical engineering">Geotechnical</a></li>
<li><a href="Hydraulic_engineering" title="Hydraulic engineering">Hydraulic</a></li>
<li><a href="Mechanical_engineering" title="Mechanical engineering">Mechanical</a></li>
<li><a href="Mechatronics" title="Mechatronics">Mechatronics</a></li>
<li><a href="Optical_engineering" title="Optical engineering">Optical</a></li>
<li><a href="Protein_engineering" title="Protein engineering">Protein</a></li>
<li><a href="Quantum_technology" title="Quantum technology">Quantum</a></li>
<li><a href="Robotics" title="Robotics">Robotics</a></li>
<li><a href="Systems_engineering" title="Systems engineering">Systems</a></li>
</ul>
</div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Components</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Infrastructure" title="Infrastructure">Infrastructure</a></li>
<li><a href="Invention" title="Invention">Invention</a>
<ul>
<li><a href="Timeline_of_historic_inventions" title="Timeline of historic inventions">Timeline</a></li>
</ul>
</li>
<li><a href="Knowledge" title="Knowledge">Knowledge</a></li>
<li><a href="Machine" title="Machine">Machine</a></li>
<li><a href="Skill" title="Skill">Skill</a>
<ul>
<li><a href="Craft" title="Craft">Craft</a></li>
</ul>
</li>
<li><a href="Tool" title="Tool">Tool</a>
<ul>
<li><a href="Gadget" title="Gadget">Gadget</a></li>
</ul>
</li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="History_of_technology" title="History of technology">History</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Outline_of_prehistoric_technology" title="Outline of prehistoric technology">Prehistoric technology</a></li>
<li><a href="Neolithic_Revolution" title="Neolithic Revolution">Neolithic Revolution</a></li>
<li><a href="Ancient_technology" title="Ancient technology">Ancient technology</a></li>
<li><a href="Medieval_technology" title="Medieval technology">Medieval technology</a></li>
<li><a href="Renaissance_technology" title="Renaissance technology">Renaissance technology</a></li>
<li><a href="Industrial_Revolution" title="Industrial Revolution">Industrial Revolution</a>
<ul>
<li><a href="Second_Industrial_Revolution" title="Second Industrial Revolution">Second</a></li>
</ul>
</li>
<li><a href="Jet_Age" title="Jet Age">Jet Age</a></li>
<li><a href="Digital_Revolution" title="Digital Revolution">Digital Revolution</a></li>
<li><a href="Information_Age" title="Information Age">Information Age</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Theories_of_technology" title="Theories of technology">Theories</a> and<br />
concepts</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Appropriate_technology" title="Appropriate technology">Appropriate technology</a></li>
<li><a href="Critique_of_technology" title="Critique of technology">Critique of technology</a></li>
<li><a href="Diffusion_of_innovations" title="Diffusion of innovations">Diffusion of innovations</a></li>
<li><a href="Disruptive_innovation" title="Disruptive innovation">Disruptive innovation</a></li>
<li><a href="Dual-use_technology" title="Dual-use technology">Dual-use technology</a></li>
<li><a href="Ephemeralization" title="Ephemeralization">Ephemeralization</a></li>
<li><a href="Ethics_of_technology" title="Ethics of technology">Ethics of technology</a></li>
<li><a href="High_tech" title="High tech">High tech</a></li>
<li><a href="Hype_cycle" title="Hype cycle">Hype cycle</a></li>
<li><a href="Inevitability_thesis" title="Inevitability thesis">Inevitability thesis</a></li>
<li><a href="Low-technology" title="Low-technology">Low-technology</a></li>
<li><a href="Mature_technology" title="Mature technology">Mature technology</a></li>
<li><a href="Philosophy_of_technology" title="Philosophy of technology">Philosophy of technology</a></li>
<li><a href="Strategy_of_Technology" title="Strategy of Technology">Strategy of Technology</a></li>
<li><a href="Technicism" title="Technicism">Technicism</a></li>
<li><a href="Techno-progressivism" title="Techno-progressivism">Techno-progressivism</a></li>
<li><a href="Technocapitalism" title="Technocapitalism">Technocapitalism</a></li>
<li><a href="Technocentrism" title="Technocentrism">Technocentrism</a></li>
<li><a href="Technocracy" title="Technocracy">Technocracy</a></li>
<li><a href="Technocriticism" title="Technocriticism">Technocriticism</a></li>
<li><a href="Technoetic" title="Technoetic">Technoetic</a></li>
<li><a href="Technological_change" title="Technological change">Technological change</a></li>
<li><a href="Technological_convergence" title="Technological convergence">Technological convergence</a></li>
<li><a href="Technological_determinism" title="Technological determinism">Technological determinism</a></li>
<li><a href="Technological_escalation" title="Technological escalation">Technological escalation</a></li>
<li><a href="Technological_evolution" title="Technological evolution">Technological evolution</a></li>
<li><a href="Technological_fix" title="Technological fix">Technological fix</a></li>
<li><a href="Technological_innovation_system" title="Technological innovation system">Technological innovation system</a></li>
<li><a href="Technological_momentum" title="Technological momentum">Technological momentum</a></li>
<li><a href="Technological_nationalism" title="Technological nationalism">Technological nationalism</a></li>
<li><a href="Technological_rationality" title="Technological rationality">Technological rationality</a></li>
<li><a href="Technological_revival" title="Technological revival">Technological revival</a></li>
<li><strong class="selflink">Technological singularity</strong></li>
<li><a href="Technological_somnambulism" title="Technological somnambulism">Technological somnambulism</a></li>
<li><a href="Technological_utopianism" title="Technological utopianism">Technological utopianism</a></li>
<li><a href="Technology_lifecycle" title="Technology lifecycle" class="mw-redirect">Technology lifecycle</a>
<ul>
<li><a href="Technology_acceptance_model" title="Technology acceptance model">Technology acceptance model</a></li>
<li><a href="Technology_adoption_lifecycle" title="Technology adoption lifecycle">Technology adoption lifecycle</a></li>
</ul>
</li>
<li><a href="Technorealism" title="Technorealism">Technorealism</a></li>
<li><a href="Transhumanism" title="Transhumanism">Transhumanism</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Other</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Emerging_technologies" title="Emerging technologies">Emerging technologies</a>
<ul>
<li><a href="List_of_emerging_technologies" title="List of emerging technologies">List</a></li>
</ul>
</li>
<li><a href="Fictional_technology" title="Fictional technology">Fictional technology</a></li>
<li><a href="Category_High-technology_business_districts" title="Category:High-technology business districts">High-technology business districts</a></li>
<li><a href="Kardashev_scale" title="Kardashev scale">Kardashev scale</a></li>
<li><a href="List_of_technologies" title="List of technologies">List of technologies</a></li>
<li><a href="Category_Science_and_technology_by_country" title="Category:Science and technology by country">Science and technology by country</a></li>
<li><a href="Technology_alignment" title="Technology alignment">Technology alignment</a></li>
<li><a href="Technology_assessment" title="Technology assessment">Technology assessment</a></li>
<li><a href="Technology_brokering" title="Technology brokering" class="mw-redirect">Technology brokering</a></li>
<li><a href="Category_Technology_companies" title="Category:Technology companies">Technology companies</a></li>
<li><a href="Technology_demonstration" title="Technology demonstration">Technology demonstration</a></li>
<li><a href="Technology_education" title="Technology education">Technology education</a>
<ul>
<li><a href="Category_Technical_universities_and_colleges" title="Category:Technical universities and colleges">Technical universities and colleges</a></li>
</ul>
</li>
<li><a href="Technology_evangelist" title="Technology evangelist">Technology evangelist</a></li>
<li><a href="Technology_governance" title="Technology governance">Technology governance</a></li>
<li><a href="Technology_integration" title="Technology integration">Technology integration</a></li>
<li><a href="Technology_journalism" title="Technology journalism">Technology journalism</a></li>
<li><a href="Technology_management" title="Technology management">Technology management</a></li>
<li><a href="Technology_shock" title="Technology shock">Technology shock</a></li>
<li><a href="Technology_strategy" title="Technology strategy">Technology strategy</a></li>
<li><a href="Technology_and_society" title="Technology and society">Technology and society</a></li>
<li><a href="Technology_transfer" title="Technology transfer">Technology transfer</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td class="navbox-abovebelow" style=";" colspan="2">
<div>
<ul>
<li><img alt="Wikipedia book" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/89/Symbol_book_class2.svg/16px-Symbol_book_class2.svg.png" width="16" height="16" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/8/89/Symbol_book_class2.svg/24px-Symbol_book_class2.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/89/Symbol_book_class2.svg/32px-Symbol_book_class2.svg.png 2x" /> <b><a href="Book_Technology" title="Book:Technology">Book</a></b></li>
<li><img alt="Category" src="http://upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/16px-Folder_Hexagonal_Icon.svg.png" width="16" height="14" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/24px-Folder_Hexagonal_Icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/32px-Folder_Hexagonal_Icon.svg.png 2x" /> <b><a href="Category_Technology" title="Category:Technology">Category</a></b></li>
<li><img alt="Commons page" src="http://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png" width="12" height="16" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x" /> <b><a href="http://commons.wikimedia.org/wiki/Category:Technology" class="extiw" title="commons:Category:Technology">Commons</a></b></li>
<li><img alt="Portal" src="http://upload.wikimedia.org/wikipedia/en/thumb/f/fd/Portal-puzzle.svg/16px-Portal-puzzle.svg.png" width="16" height="14" srcset="//upload.wikimedia.org/wikipedia/en/thumb/f/fd/Portal-puzzle.svg/24px-Portal-puzzle.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/f/fd/Portal-puzzle.svg/32px-Portal-puzzle.svg.png 2x" /> <b><a href="Portal_Technology" title="Portal:Technology">Portal</a></b></li>
<li><img alt="Wikiquote page" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/16px-Wikiquote-logo.svg.png" width="16" height="19" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/24px-Wikiquote-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/32px-Wikiquote-logo.svg.png 2x" /> <b><a href="http://en.wikiquote.org/wiki/Technology" class="extiw" title="wikiquote:Technology">Wikiquotes</a></b></li>
</ul>
</div>
</td>
</tr>
</table>
</td>
</tr>
</table>
<table cellspacing="0" class="navbox" style="border-spacing:0;;">
<tr>
<td style="padding:2px;">
<table cellspacing="0" class="nowraplinks hlist collapsible collapsed navbox-inner" style="border-spacing:0;background:transparent;color:inherit;;">
<tr>
<th scope="col" style=";" class="navbox-title" colspan="2">
<div class="noprint plainlinks hlist navbar mini" style="">
<ul>
<li class="nv-view"><a href="Template_Emerging_technologies" title="Template:Emerging technologies"><span title="View this template" style=";;background:none transparent;border:none;">v</span></a></li>
<li class="nv-talk"><a href="Template_talk_Emerging_technologies" title="Template talk:Emerging technologies"><span title="Discuss this template" style=";;background:none transparent;border:none;">t</span></a></li>
<li class="nv-edit"><a class="external text" href="../../w/index-title=Template_Emerging_technologies&action=edit.php.html"><span title="Edit this template" style=";;background:none transparent;border:none;">e</span></a></li>
</ul>
</div>
<div class="" style="font-size:110%;"><a href="Emerging_technologies" title="Emerging technologies">Emerging technologies</a></div>
</th>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td class="navbox-abovebelow" style=";" colspan="2">
<div><a href="Technology" title="Technology">Technology</a></div>
</td>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Fields</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em"></div>
<table cellspacing="0" class="nowraplinks navbox-subgroup" style="border-spacing:0;;;;">
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Agriculture" title="Agriculture">Agriculture</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Agricultural_robot" title="Agricultural robot">Agricultural robot</a></li>
<li><a href="In_vitro_meat" title="In vitro meat">In vitro meat</a></li>
<li><a href="Genetically_modified_food" title="Genetically modified food">Genetically modified food</a></li>
<li><a href="Precision_agriculture" title="Precision agriculture">Precision agriculture</a></li>
<li><a href="Vertical_farming" title="Vertical farming">Vertical farming</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Biomedical_technology" title="Biomedical technology">Biomedical</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Ampakine" title="Ampakine">Ampakine</a></li>
<li><a href="Brain_transplant" title="Brain transplant">Brain transplant</a></li>
<li><a href="Cryonics" title="Cryonics">Cryonics</a>
<ul>
<li><span style="font-size:85%;"><a href="Cells_Alive_System" title="Cells Alive System">Cells Alive System</a> freezers</span></li>
</ul>
</li>
<li><a href="Full_genome_sequencing" title="Full genome sequencing" class="mw-redirect">Full genome sequencing</a></li>
<li><a href="Genetic_engineering" title="Genetic engineering">Genetic engineering</a>
<ul>
<li><span style="font-size:85%;"><a href="Gene_therapy" title="Gene therapy">Gene therapy</a></span></li>
</ul>
</li>
<li><a href="Personalized_medicine" title="Personalized medicine">Personalized medicine</a></li>
<li><a href="Regenerative_medicine" title="Regenerative medicine">Regenerative medicine</a>
<ul>
<li><span style="font-size:85%;"><a href="Stem_cell_treatments" title="Stem cell treatments" class="mw-redirect">Stem cell treatments</a></span></li>
<li><span style="font-size:85%;"><a href="Tissue_engineering" title="Tissue engineering">Tissue engineering</a></span></li>
</ul>
</li>
<li><a href="Head_transplant" title="Head transplant">Head transplant</a></li>
<li><a href="Isolated_brain" title="Isolated brain">Isolated brain</a></li>
<li><a href="Robotic_surgery" title="Robotic surgery">Robotic surgery</a></li>
<li><a href="Strategies_for_Engineered_Negligible_Senescence" title="Strategies for Engineered Negligible Senescence">Strategies for Engineered Negligible Senescence</a></li>
<li><a href="Suspended_animation" title="Suspended animation">Suspended animation</a></li>
<li><a href="Synthetic_biology" title="Synthetic biology">Synthetic biology</a>
<ul>
<li><span style="font-size:85%;"><a href="Synthetic_genomics" title="Synthetic genomics">Synthetic genomics</a></span></li>
</ul>
</li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Displays</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Autostereoscopy" title="Autostereoscopy">Autostereoscopy</a></li>
<li><a href="Holographic_display" title="Holographic display">Holographic display</a></li>
<li><a href="Next_generation_of_display_technology" title="Next generation of display technology">Next generation of display technology</a></li>
<li><a href="Screenless" title="Screenless">Screenless display</a>
<ul>
<li><span style="font-size:85%;"><a href="Bionic_contact_lens" title="Bionic contact lens">Bionic contact lens</a></span></li>
<li><span style="font-size:85%;"><a href="Head-mounted_display" title="Head-mounted display">Head-mounted display</a></span></li>
<li><span style="font-size:85%;"><a href="Head-up_display" title="Head-up display">Head-up display</a></span></li>
<li><span style="font-size:85%;"><a href="Virtual_retinal_display" title="Virtual retinal display">Virtual retinal display</a></span></li>
</ul>
</li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Electronics</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Electronic_nose" title="Electronic nose">Electronic nose</a></li>
<li><a href="Electronic_textile" title="Electronic textile" class="mw-redirect">Electronic textile</a></li>
<li><a href="Flexible_electronics" title="Flexible electronics">Flexible electronics</a></li>
<li><a href="Memristor" title="Memristor">Memristor</a></li>
<li><a href="Spintronics" title="Spintronics">Spintronics</a></li>
<li><a href="Thermal_copper_pillar_bump" title="Thermal copper pillar bump">Thermal copper pillar bump</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Energy</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Energy_storage" title="Energy storage">Energy storage</a>
<ul>
<li><span style="font-size:85%;"><a href="Beltway_battery" title="Beltway battery" class="mw-redirect">Beltway battery</a></span></li>
<li><span style="font-size:85%;"><a href="Carbon_neutral_fuel" title="Carbon neutral fuel">Carbon neutral fuel</a></span></li>
<li><span style="font-size:85%;"><a href="Compressed_air_energy_storage" title="Compressed air energy storage">Compressed air energy storage</a></span></li>
<li><span style="font-size:85%;"><a href="Flywheel_energy_storage" title="Flywheel energy storage">Flywheel energy storage</a></span></li>
<li><span style="font-size:85%;"><a href="Grid_energy_storage" title="Grid energy storage">Grid energy storage</a></span></li>
<li><span style="font-size:85%;"><a href="Lithium_air_battery" title="Lithium air battery" class="mw-redirect">Lithium air battery</a></span></li>
<li><span style="font-size:85%;"><a href="Molten_salt_battery" title="Molten salt battery">Molten salt battery</a></span></li>
<li><span style="font-size:85%;"><a href="Nanowire_battery" title="Nanowire battery">Nanowire battery</a></span></li>
<li><span style="font-size:85%;"><a href="Silicon_air_battery" title="Silicon air battery" class="mw-redirect">Silicon air battery</a></span></li>
<li><span style="font-size:85%;"><a href="Thermal_energy_storage" title="Thermal energy storage">Thermal energy storage</a></span></li>
<li><span style="font-size:85%;"><a href="Electric_double-layer_capacitor" title="Electric double-layer capacitor">Ultracapacitor</a></span></li>
</ul>
</li>
<li><a href="Fusion_power" title="Fusion power">Fusion power</a></li>
<li><a href="Molten_salt_reactor" title="Molten salt reactor">Molten salt reactor</a></li>
<li><a href="Renewable_energy" title="Renewable energy">Renewable energy</a>
<ul>
<li><span style="font-size:85%;"><a href="Airborne_wind_turbine" title="Airborne wind turbine">Airborne wind turbine</a></span></li>
<li><span style="font-size:85%;"><a href="Artificial_photosynthesis" title="Artificial photosynthesis">Artificial photosynthesis</a></span></li>
<li><span style="font-size:85%;"><a href="Biofuel" title="Biofuel">Biofuels</a></span></li>
<li><span style="font-size:85%;"><a href="Carbon_negative_fuel" title="Carbon negative fuel" class="mw-redirect">Carbon negative fuel</a></span></li>
<li><span style="font-size:85%;"><a href="Concentrated_solar_power" title="Concentrated solar power">Concentrated solar power</a></span></li>
<li><span style="font-size:85%;"><a href="Home_fuel_cell" title="Home fuel cell">Home fuel cell</a></span></li>
<li><span style="font-size:85%;"><a href="Hydrogen_economy" title="Hydrogen economy">Hydrogen economy</a></span></li>
<li><span style="font-size:85%;"><a href="Nantenna" title="Nantenna">Nantenna</a></span></li>
<li><span style="font-size:85%;"><a href="Solar_roadway" title="Solar roadway">Solar roadway</a></span></li>
<li><span style="font-size:85%;"><a href="Space-based_solar_power" title="Space-based solar power">Space-based solar power</a></span></li>
</ul>
</li>
<li><a href="Smart_grid" title="Smart grid">Smart grid</a></li>
<li><a href="Contactless_energy_transfer" title="Contactless energy transfer" class="mw-redirect">Contactless energy transfer</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Information_and_communication_technologies" title="Information and communication technologies" class="mw-redirect">IT and<br />
communications</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Artificial_intelligence" title="Artificial intelligence">Artificial intelligence</a>
<ul>
<li><span style="font-size:85%;"><a href="Applications_of_artificial_intelligence" title="Applications of artificial intelligence">Applications of artificial intelligence</a></span></li>
<li><span style="font-size:85%;"><a href="Progress_in_artificial_intelligence" title="Progress in artificial intelligence">Progress in artificial intelligence</a></span></li>
<li><span style="font-size:85%;"><a href="Machine_translation" title="Machine translation">Machine translation</a></span></li>
<li><span style="font-size:85%;"><a href="Machine_vision" title="Machine vision">Machine vision</a></span></li>
<li><span style="font-size:85%;"><a href="Semantic_Web" title="Semantic Web">Semantic Web</a></span></li>
<li><span style="font-size:85%;"><a href="Speech_recognition" title="Speech recognition">Speech recognition</a></span></li>
</ul>
</li>
<li><a href="Atomtronics" title="Atomtronics">Atomtronics</a></li>
<li><a href="Cybermethodology" title="Cybermethodology">Cybermethodology</a></li>
<li><a href="Optical_disc#Fourth-generation" title="Optical disc">Fourth-generation optical discs</a>
<ul>
<li><span style="font-size:85%;"><a href="3D_optical_data_storage" title="3D optical data storage">3D optical data storage</a></span></li>
<li><span style="font-size:85%;"><a href="Holographic_data_storage" title="Holographic data storage">Holographic data storage</a></span></li>
</ul>
</li>
<li><a href="GPGPU" title="GPGPU">GPGPU</a></li>
<li>Memory
<ul>
<li><span style="font-size:85%;"><a href="CBRAM" title="CBRAM" class="mw-redirect">CBRAM</a></span></li>
<li><span style="font-size:85%;"><a href="Ferroelectric_RAM" title="Ferroelectric RAM">FRAM</a></span></li>
<li><span style="font-size:85%;"><a href="Millipede_memory" title="Millipede memory">Millipede</a></span></li>
<li><span style="font-size:85%;"><a href="Magnetoresistive_random-access_memory" title="Magnetoresistive random-access memory">MRAM</a></span></li>
<li><span style="font-size:85%;"><a href="Nano-RAM" title="Nano-RAM">NRAM</a></span></li>
<li><span style="font-size:85%;"><a href="Phase-change_memory" title="Phase-change memory">PRAM</a></span></li>
<li><span style="font-size:85%;"><a href="Racetrack_memory" title="Racetrack memory">Racetrack memory</a></span></li>
<li><span style="font-size:85%;"><a href="RRAM" title="RRAM" class="mw-redirect">RRAM</a></span></li>
<li><span style="font-size:85%;"><a href="SONOS" title="SONOS">SONOS</a></span></li>
</ul>
</li>
<li><a href="Optical_computing" title="Optical computing">Optical computing</a></li>
<li><a href="Quantum_computer" title="Quantum computer">Quantum computing</a></li>
<li><a href="Quantum_cryptography" title="Quantum cryptography">Quantum cryptography</a></li>
<li><a href="Radio-frequency_identification" title="Radio-frequency identification">RFID</a></li>
<li><a href="Three-dimensional_integrated_circuit" title="Three-dimensional integrated circuit">Three-dimensional integrated circuit</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Manufacturing</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="3D_printing" title="3D printing">3D printing</a>
<ul>
<li><span style="font-size:85%;"><a href="Contour_Crafting" title="Contour Crafting" class="mw-redirect">Contour Crafting</a></span></li>
</ul>
</li>
<li><a href="Claytronics" title="Claytronics">Claytronics</a></li>
<li><a href="Molecular_assembler" title="Molecular assembler">Molecular assembler</a></li>
<li><a href="Utility_fog" title="Utility fog">Utility fog</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Materials_science" title="Materials science">Materials science</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Graphene" title="Graphene">Graphene</a></li>
<li><a href="High-temperature_superconductivity" title="High-temperature superconductivity">High-temperature superconductivity</a></li>
<li><a href="Superfluid" title="Superfluid" class="mw-redirect">High-temperature superfluidity</a></li>
<li><a href="Metamaterial" title="Metamaterial">Metamaterials</a>
<ul>
<li><span style="font-size:85%;"><a href="Metamaterial_cloaking" title="Metamaterial cloaking">Metamaterial cloaking</a></span></li>
</ul>
</li>
<li><a href="Multi-function_structure" title="Multi-function structure">Multi-function structures</a></li>
<li><a href="Nanotechnology" title="Nanotechnology">Nanotechnology</a>
<ul>
<li><span style="font-size:85%;"><a href="Carbon_nanotube" title="Carbon nanotube">Carbon nanotubes</a></span></li>
<li><span style="font-size:85%;"><a href="Molecular_nanotechnology" title="Molecular nanotechnology">Molecular nanotechnology</a></span></li>
<li><span style="font-size:85%;"><a href="Nanomaterials" title="Nanomaterials">Nanomaterials</a></span></li>
</ul>
</li>
<li><a href="Programmable_matter" title="Programmable matter">Programmable matter</a></li>
<li><a href="Quantum_dot" title="Quantum dot">Quantum dots</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Military_technology" title="Military technology">Military</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Antimatter_weapon" title="Antimatter weapon">Antimatter weapon</a></li>
<li><a href="Directed-energy_weapon" title="Directed-energy weapon">Directed-energy weapon</a>
<ul>
<li><span style="font-size:85%;"><a href="Laser" title="Laser">Laser</a></span></li>
<li><span style="font-size:85%;"><a href="Maser" title="Maser">Maser</a></span></li>
<li><span style="font-size:85%;"><a href="Particle_beam_weapon" title="Particle beam weapon">Particle beam weapon</a></span></li>
<li><span style="font-size:85%;"><a href="Sonic_weapon" title="Sonic weapon">Sonic weapon</a></span></li>
</ul>
</li>
<li><a href="Electromagnetic_weapon" title="Electromagnetic weapon">Electromagnetic weapon</a>
<ul>
<li><span style="font-size:85%;"><a href="Coilgun" title="Coilgun">Coilgun</a></span></li>
<li><span style="font-size:85%;"><a href="Railgun" title="Railgun">Railgun</a></span></li>
</ul>
</li>
<li><a href="Plasma_weapon" title="Plasma weapon">Plasma weapon</a></li>
<li><a href="Pure_fusion_weapon" title="Pure fusion weapon">Pure fusion weapon</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Neuroscience" title="Neuroscience">Neuroscience</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Artificial_brain" title="Artificial brain">Artificial brain</a>
<ul>
<li><span style="font-size:85%;"><a href="Blue_Brain_Project" title="Blue Brain Project">Blue Brain Project</a></span></li>
</ul>
</li>
<li><a href="Electroencephalography" title="Electroencephalography">Electroencephalography</a></li>
<li><a href="Mind_uploading" title="Mind uploading">Mind uploading</a>
<ul>
<li><span style="font-size:85%;"><a href="Brain-reading" title="Brain-reading">Brain-reading</a></span></li>
<li><span style="font-size:85%;"><a href="Neuroinformatics" title="Neuroinformatics">Neuroinformatics</a></span></li>
</ul>
</li>
<li><a href="Neuroprosthetics" title="Neuroprosthetics">Neuroprosthetics</a>
<ul>
<li><span style="font-size:85%;"><a href="Visual_prosthesis" title="Visual prosthesis">Bionic eye</a></span></li>
<li><span style="font-size:85%;"><a href="Brain_implant" title="Brain implant">Brain implant</a></span></li>
<li><span style="font-size:85%;"><a href="Exocortex" title="Exocortex">Exocortex</a></span></li>
<li><span style="font-size:85%;"><a href="Retinal_implant" title="Retinal implant">Retinal implant</a></span></li>
</ul>
</li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;"><a href="Future_of_robotics" title="Future of robotics">Robotics</a></th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Nanorobotics" title="Nanorobotics">Nanorobotics</a></li>
<li><a href="Powered_exoskeleton" title="Powered exoskeleton">Powered exoskeleton</a></li>
<li><a href="Self-reconfiguring_modular_robot" title="Self-reconfiguring modular robot">Self-reconfiguring modular robot</a></li>
<li><a href="Swarm_robotics" title="Swarm robotics">Swarm robotics</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Transport</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Adaptive_Compliant_Wing" title="Adaptive Compliant Wing" class="mw-redirect">Adaptive Compliant Wing</a></li>
<li><a href="Alternative_fuel_vehicle" title="Alternative fuel vehicle">Alternative fuel vehicle</a>
<ul>
<li><span style="font-size:85%;"><a href="Hydrogen_vehicle" title="Hydrogen vehicle">Hydrogen vehicle</a></span></li>
</ul>
</li>
<li><a href="Backpack_helicopter" title="Backpack helicopter">Backpack helicopter</a></li>
<li><a href="Autonomous_car" title="Autonomous car">Driverless car</a></li>
<li><a href="Flying_car_(aircraft)" title="Flying car (aircraft)">Flying car</a></li>
<li><a href="Ground_effect_train" title="Ground effect train">Ground effect train</a></li>
<li><a href="Jet_pack" title="Jet pack">Jet pack</a></li>
<li><a href="Interstellar_travel" title="Interstellar travel">Interstellar travel</a></li>
<li><a href="Laser_propulsion" title="Laser propulsion">Laser propulsion</a></li>
<li><a href="Maglev" title="Maglev">Maglev train</a></li>
<li><a href="Non-rocket_spacelaunch" title="Non-rocket spacelaunch">Non-rocket spacelaunch</a>
<ul>
<li><span style="font-size:85%;"><a href="Mass_driver" title="Mass driver">Mass driver</a></span></li>
<li><span style="font-size:85%;"><a href="Orbital_ring" title="Orbital ring">Orbital ring</a></span></li>
<li><span style="font-size:85%;"><a href="Skyhook_(structure)" title="Skyhook (structure)">Skyhook</a></span></li>
<li><span style="font-size:85%;"><a href="Space_elevator" title="Space elevator">Space elevator</a></span></li>
<li><span style="font-size:85%;"><a href="Space_fountain" title="Space fountain">Space fountain</a></span></li>
<li><span style="font-size:85%;"><a href="Space_tether" title="Space tether">Space tether</a></span></li>
</ul>
</li>
<li><a href="Personal_rapid_transit" title="Personal rapid transit">Personal rapid transit</a></li>
<li><a href="Plasma_propulsion_engine" title="Plasma propulsion engine">Plasma propulsion engine</a>
<ul>
<li><span style="font-size:85%;"><a href="Helicon_Double_Layer_Thruster" title="Helicon Double Layer Thruster">Helicon thruster</a></span></li>
<li><span style="font-size:85%;"><a href="Variable_Specific_Impulse_Magnetoplasma_Rocket" title="Variable Specific Impulse Magnetoplasma Rocket">VASIMR</a></span></li>
</ul>
</li>
<li><a href="Pulse_detonation_engine" title="Pulse detonation engine">Pulse detonation engine</a></li>
<li><a href="Nuclear_pulse_propulsion" title="Nuclear pulse propulsion">Nuclear pulse propulsion</a></li>
<li><a href="Scramjet" title="Scramjet">Scramjet</a></li>
<li><a href="Solar_sail" title="Solar sail">Solar sail</a></li>
<li><a href="Spaceplane" title="Spaceplane">Spaceplane</a></li>
<li><a href="Supersonic_transport" title="Supersonic transport">Supersonic transport</a></li>
<li><a href="Tweel" title="Tweel">Tweel</a></li>
<li><a href="Vactrain" title="Vactrain">Vactrain</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Other</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-odd">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Anti-gravity" title="Anti-gravity">Anti-gravity</a></li>
<li><a href="Arcology" title="Arcology">Arcology</a></li>
<li><a href="Cloak_of_invisibility" title="Cloak of invisibility">Cloak of invisibility</a></li>
<li><a href="Digital_scent_technology" title="Digital scent technology">Digital scent technology</a></li>
<li><a href="Domed_city" title="Domed city">Domed city</a></li>
<li><a href="Force_shield" title="Force shield">Force field</a>
<ul>
<li><span style="font-size:85%;"><a href="Plasma_window" title="Plasma window">Plasma window</a></span></li>
</ul>
</li>
<li><a href="Immersion_(virtual_reality)" title="Immersion (virtual reality)">Immersive virtual reality</a></li>
<li><a href="Magnetic_refrigeration" title="Magnetic refrigeration">Magnetic refrigeration</a></li>
<li><a href="Phased-array_optics" title="Phased-array optics">Phased-array optics</a></li>
<li><a href="Quantum_technology" title="Quantum technology">Quantum technology</a>
<ul>
<li><span style="font-size:85%;"><a href="Quantum_teleportation" title="Quantum teleportation">Quantum teleportation</a></span></li>
</ul>
</li>
</ul>
</div>
</td>
</tr>
</table>
</td>
</tr>
<tr style="height:2px">
<td></td>
</tr>
<tr>
<th scope="row" class="navbox-group" style=";;">Topics</th>
<td style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px;;;" class="navbox-list navbox-even">
<div style="padding:0em 0.25em">
<ul>
<li><a href="Collingridge_dilemma" title="Collingridge dilemma">Collingridge dilemma</a></li>
<li><a href="Differential_technological_development" title="Differential technological development">Differential technological development</a></li>
<li><a href="Ephemeralization" title="Ephemeralization">Ephemeralization</a></li>
<li><a href="Exploratory_engineering" title="Exploratory engineering">Exploratory engineering</a></li>
<li><a href="Fictional_technology" title="Fictional technology">Fictional technology</a></li>
<li><a href="Proactionary_principle" title="Proactionary principle">Proactionary principle</a></li>
<li><a href="Technological_change" title="Technological change">Technological change</a></li>
<li><a href="Technological_convergence" title="Technological convergence">Technological convergence</a></li>
<li><a href="Technological_evolution" title="Technological evolution">Technological evolution</a></li>
<li><a href="Technological_unemployment" title="Technological unemployment">Technological unemployment</a></li>
<li><a href="Technology_forecasting" title="Technology forecasting">Technology forecasting</a>
<ul>
<li><span style="font-size:85%;"><a href="Accelerating_change" title="Accelerating change">Accelerating change</a></span></li>
<li><span style="font-size:85%;"><a href="Moore's_law" title="Moore's law">Moore's law</a></span></li>
<li><span style="font-size:85%;"><a href="Timeline_of_the_future_in_forecasts" title="Timeline of the future in forecasts">Timeline of the future in forecasts</a></span></li>
<li><span style="font-size:85%;"><strong class="selflink">Technological singularity</strong></span></li>
<li><span style="font-size:85%;"><a href="Technology_scouting" title="Technology scouting">Technology scouting</a></span></li>
</ul>
</li>
<li><a href="Technology_readiness_level" title="Technology readiness level">Technology readiness level</a></li>
<li><a href="Technology_roadmap" title="Technology roadmap">Technology roadmap</a></li>
<li><a href="Transhumanism" title="Transhumanism">Transhumanism</a></li>
<li><a href="Virtusphere" title="Virtusphere" class="mw-redirect">Virtusphere</a></li>
</ul>
</div>
</td>
</tr>
<tr style="height:2px;">
<td></td>
</tr>
<tr>
<td class="navbox-abovebelow" style=";" colspan="2">
<div>
<ul>
<li><img alt="Category" src="http://upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/16px-Folder_Hexagonal_Icon.svg.png" width="16" height="14" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/24px-Folder_Hexagonal_Icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/32px-Folder_Hexagonal_Icon.svg.png 2x" /> <b><a href="Category_Emerging_technologies" title="Category:Emerging technologies">Category</a></b></li>
<li><img alt="List-Class article" src="http://upload.wikimedia.org/wikipedia/en/thumb/d/db/Symbol_list_class.svg/16px-Symbol_list_class.svg.png" width="16" height="16" srcset="//upload.wikimedia.org/wikipedia/en/thumb/d/db/Symbol_list_class.svg/24px-Symbol_list_class.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/d/db/Symbol_list_class.svg/32px-Symbol_list_class.svg.png 2x" /> <b><a href="List_of_emerging_technologies" title="List of emerging technologies">List</a></b></li>
</ul>
</div>
</td>
</tr>
</table>
</td>
</tr>
</table>
<p><span id="interwiki-hu-fa"></span></p>


<!-- 
NewPP limit report
Preprocessor visited node count: 40838/1000000
Preprocessor generated node count: 63006/1500000
Post-expand include size: 327883/2048000 bytes
Template argument size: 190113/2048000 bytes
Highest expansion depth: 21/40
Expensive parser function count: 8/500
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:54245-0!*!0!!en!4!* and timestamp 20130213074503 -->
</div>				<!-- /bodycontent -->
								<!-- printfooter -->
				<div class="printfooter">
				Retrieved from "<a href="../../w/index-title=Technological_singularity&oldid=538009358.php.html">http://en.wikipedia.org/w/index.php?title=Technological_singularity&amp;oldid=538009358</a>"				</div>
				<!-- /printfooter -->
												<!-- catlinks -->
				<div id='catlinks' class='catlinks'><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="Help_Categories" title="Help:Categories">Categories</a>: <ul><li><a href="Category_Eschatology" title="Category:Eschatology">Eschatology</a></li><li><a href="Category_Evolution" title="Category:Evolution">Evolution</a></li><li><a href="Category_Futurology" title="Category:Futurology">Futurology</a></li><li><a href="Category_Philosophy_of_artificial_intelligence" title="Category:Philosophy of artificial intelligence">Philosophy of artificial intelligence</a></li><li><a href="Category_Singularitarianism" title="Category:Singularitarianism">Singularitarianism</a></li><li><a href="Category_Sociocultural_evolution" title="Category:Sociocultural evolution">Sociocultural evolution</a></li><li><a href="Category_Theories_of_history" title="Category:Theories of history">Theories of history</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="Category_Missing_redirects" title="Category:Missing redirects">Missing redirects</a></li><li><a href="Category_All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="Category_Articles_with_unsourced_statements_from_July_2012" title="Category:Articles with unsourced statements from July 2012">Articles with unsourced statements from July 2012</a></li><li><a href="Category_Articles_with_unsourced_statements_from_November_2010" title="Category:Articles with unsourced statements from November 2010">Articles with unsourced statements from November 2010</a></li><li><a href="Category_All_articles_with_dead_external_links" title="Category:All articles with dead external links">All articles with dead external links</a></li><li><a href="Category_Articles_with_dead_external_links_from_July_2009" title="Category:Articles with dead external links from July 2009">Articles with dead external links from July 2009</a></li><li><a href="Category_Wikipedia_external_links_cleanup_from_March_2011" title="Category:Wikipedia external links cleanup from March 2011">Wikipedia external links cleanup from March 2011</a></li><li><a href="Category_Wikipedia_spam_cleanup_from_March_2011" title="Category:Wikipedia spam cleanup from March 2011">Wikipedia spam cleanup from March 2011</a></li><li><a href="Category_Spoken_articles" title="Category:Spoken articles">Spoken articles</a></li><li><a href="Category_Articles_with_hAudio_microformats" title="Category:Articles with hAudio microformats">Articles with hAudio microformats</a></li></ul></div></div>				<!-- /catlinks -->
												<div class="visualClear"></div>
				<!-- debughtml -->
								<!-- /debughtml -->
			</div>
			<!-- /bodyContent -->
		</div>
		<!-- /content -->
		<div id="mw-navigation">
			<h2>Navigation menu</h2>
			<!-- header -->
			<div id="mw-head" class="noprint">
				
<!-- 0 -->
<div id="p-personal" role="navigation" class="">
	<h3>Personal tools</h3>
	<ul>
<li id="pt-createaccount"><a href="../../w/index-title=Special_UserLogin&returnto=Technological+singularity&type=signup.php.html">Create account</a></li><li id="pt-login"><a href="../../w/index-title=Special_UserLogin&returnto=Technological+singularity.php.html" title="You are encouraged to log in; however, it is not mandatory. [o]" accesskey="o">Log in</a></li>	</ul>
</div>

<!-- /0 -->
				<div id="left-navigation">
					
<!-- 0 -->
<div id="p-namespaces" role="navigation" class="vectorTabs">
	<h3>Namespaces</h3>
	<ul>
					<li  id="ca-nstab-main" class="selected"><span><a href="index.html"  title="View the content page [c]" accesskey="c">Article</a></span></li>
					<li  id="ca-talk"><span><a href="Talk_Technological_singularity"  title="Discussion about the content page [t]" accesskey="t">Talk</a></span></li>
			</ul>
</div>

<!-- /0 -->

<!-- 1 -->
<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet">
	<h3 id="mw-vector-current-variant">
		</h3>
	<h3><span>Variants</span><a href="#"></a></h3>
	<div class="menu">
		<ul>
					</ul>
	</div>
</div>

<!-- /1 -->
				</div>
				<div id="right-navigation">
					
<!-- 0 -->
<div id="p-views" role="navigation" class="vectorTabs">
	<h3>Views</h3>
	<ul>
					<li id="ca-view" class="selected"><span><a href="index.html" >Read</a></span></li>
					<li id="ca-edit"><span><a href="../../w/index-title=Technological_singularity&action=edit.php.html"  title="You can edit this page. &#10;Please use the preview button before saving. [e]" accesskey="e">Edit</a></span></li>
					<li id="ca-history" class="collapsible"><span><a href="../../w/index-title=Technological_singularity&action=history.php.html"  title="Past versions of this page [h]" accesskey="h">View history</a></span></li>
			</ul>
</div>

<!-- /0 -->

<!-- 1 -->
<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet">
	<h3><span>Actions</span><a href="#"></a></h3>
	<div class="menu">
		<ul>
					</ul>
	</div>
</div>

<!-- /1 -->

<!-- 2 -->
<div id="p-search" role="search">
	<h3><label for="searchInput">Search</label></h3>
	<form action="/w/index.php" id="searchform">
				<div id="simpleSearch">
						<input name="search" title="Search Wikipedia [f]" accesskey="f" id="searchInput" />						<button type="submit" name="button" title="Search Wikipedia for this text" id="searchButton"><img src="http://bits.wikimedia.org/static-1.21wmf9/skins/vector/images/search-ltr.png?303-4" alt="Search" width="12" height="13" /></button>								<input type='hidden' name="title" value="Special:Search"/>
		</div>
	</form>
</div>

<!-- /2 -->
				</div>
			</div>
			<!-- /header -->
			<!-- panel -->
			<div id="mw-panel" class="noprint">
				<!-- logo -->
					<div id="p-logo" role="banner"><a style="background-image: url(http://upload.wikimedia.org/wikipedia/en/b/bc/Wiki.png);" href="Main_Page"  title="Visit the main page"></a></div>
				<!-- /logo -->
				
<!-- navigation -->
<div class="portal" role="navigation" id='p-navigation'>
	<h3>Navigation</h3>
	<div class="body">
		<ul>
			<li id="n-mainpage-description"><a href="Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li>
			<li id="n-contents"><a href="Portal_Contents" title="Guides to browsing Wikipedia">Contents</a></li>
			<li id="n-featuredcontent"><a href="Portal_Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li>
			<li id="n-currentevents"><a href="Portal_Current_events" title="Find background information on current events">Current events</a></li>
			<li id="n-randompage"><a href="Special_Random" title="Load a random article [x]" accesskey="x">Random article</a></li>
			<li id="n-sitesupport"><a href="http://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en" title="Support us">Donate to Wikipedia</a></li>
		</ul>
	</div>
</div>

<!-- /navigation -->

<!-- SEARCH -->

<!-- /SEARCH -->

<!-- interaction -->
<div class="portal" role="navigation" id='p-interaction'>
	<h3>Interaction</h3>
	<div class="body">
		<ul>
			<li id="n-help"><a href="Help_Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li>
			<li id="n-aboutsite"><a href="Wikipedia_About" title="Find out about Wikipedia">About Wikipedia</a></li>
			<li id="n-portal"><a href="Wikipedia_Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li>
			<li id="n-recentchanges"><a href="Special_RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li>
			<li id="n-contact"><a href="Wikipedia_Contact_us" title="How to contact Wikipedia">Contact Wikipedia</a></li>
		</ul>
	</div>
</div>

<!-- /interaction -->

<!-- TOOLBOX -->
<div class="portal" role="navigation" id='p-tb'>
	<h3>Toolbox</h3>
	<div class="body">
		<ul>
			<li id="t-whatlinkshere"><a href="Special_WhatLinksHere/Technological_singularity" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li>
			<li id="t-recentchangeslinked"><a href="Special_RecentChangesLinked/Technological_singularity" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li>
			<li id="t-upload"><a href="Wikipedia_File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li>
			<li id="t-specialpages"><a href="Special_SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li>
			<li id="t-permalink"><a href="../../w/index-title=Technological_singularity&oldid=538009358.php.html" title="Permanent link to this revision of the page">Permanent link</a></li>
			<li id="t-info"><a href="../../w/index-title=Technological_singularity&action=info.php.html">Page information</a></li>
<li id="t-cite"><a href="../../w/index-title=Special_Cite&page=Technological_singularity&id=538009358.php.html" title="Information on how to cite this page">Cite this page</a></li>		</ul>
	</div>
</div>

<!-- /TOOLBOX -->

<!-- coll-print_export -->
<div class="portal" role="navigation" id='p-coll-print_export'>
	<h3>Print/export</h3>
	<div class="body">
		<ul id="collectionPortletList"><li id="coll-create_a_book"><a href="../../w/index-title=Special_Book&bookcmd=book_creator&referer=Technological+singularity.php.html" title="Create a book or page collection" rel="nofollow">Create a book</a></li><li id="coll-download-as-rl"><a href="../../w/index-title=Special_Book&bookcmd=render_article&arttitle=Technological+singularity&oldid=538009358&writer=rl.php.html" title="Download a PDF version of this wiki page" rel="nofollow">Download as PDF</a></li><li id="t-print"><a href="../../w/index-title=Technological_singularity&printable=yes.php.html" title="Printable version of this page [p]" accesskey="p">Printable version</a></li></ul>	</div>
</div>

<!-- /coll-print_export -->

<!-- LANGUAGES -->
<div class="portal" role="navigation" id='p-lang'>
	<h3>Languages</h3>
	<div class="body">
		<ul>
			<li class="interwiki-ca"><a href="http://ca.wikipedia.org/wiki/Singularitat_tecnol%C3%B2gica" title="Singularitat tecnològica" lang="ca" hreflang="ca">Català</a></li>
			<li class="interwiki-cs"><a href="http://cs.wikipedia.org/wiki/Technologick%C3%A1_singularita" title="Technologická singularita" lang="cs" hreflang="cs">Česky</a></li>
			<li class="interwiki-de"><a href="http://de.wikipedia.org/wiki/Technologische_Singularit%C3%A4t" title="Technologische Singularität" lang="de" hreflang="de">Deutsch</a></li>
			<li class="interwiki-et"><a href="http://et.wikipedia.org/wiki/Tehnoloogiline_singulaarsus" title="Tehnoloogiline singulaarsus" lang="et" hreflang="et">Eesti</a></li>
			<li class="interwiki-el"><a href="http://el.wikipedia.org/wiki/%CE%A4%CE%B5%CF%87%CE%BD%CE%BF%CE%BB%CE%BF%CE%B3%CE%B9%CE%BA%CE%AE_%CE%BC%CE%BF%CE%BD%CE%B1%CE%B4%CE%B9%CE%BA%CF%8C%CF%84%CE%B7%CF%84%CE%B1" title="Τεχνολογική μοναδικότητα" lang="el" hreflang="el">Ελληνικά</a></li>
			<li class="interwiki-es"><a href="http://es.wikipedia.org/wiki/Singularidad_tecnol%C3%B3gica" title="Singularidad tecnológica" lang="es" hreflang="es">Español</a></li>
			<li class="interwiki-fr"><a href="http://fr.wikipedia.org/wiki/Singularit%C3%A9_technologique" title="Singularité technologique" lang="fr" hreflang="fr">Français</a></li>
			<li class="interwiki-ko"><a href="http://ko.wikipedia.org/wiki/%EA%B8%B0%EC%88%A0%EC%A0%81_%ED%8A%B9%EC%9D%B4%EC%A0%90" title="기술적 특이점" lang="ko" hreflang="ko">한국어</a></li>
			<li class="interwiki-it"><a href="http://it.wikipedia.org/wiki/Singolarit%C3%A0_tecnologica" title="Singolarità tecnologica" lang="it" hreflang="it">Italiano</a></li>
			<li class="interwiki-he"><a href="http://he.wikipedia.org/wiki/%D7%A1%D7%99%D7%A0%D7%92%D7%95%D7%9C%D7%A8%D7%99%D7%95%D7%AA_%D7%98%D7%9B%D7%A0%D7%95%D7%9C%D7%95%D7%92%D7%99%D7%AA" title="סינגולריות טכנולוגית" lang="he" hreflang="he">עברית</a></li>
			<li class="interwiki-la"><a href="http://la.wikipedia.org/wiki/Singularitas_technologica" title="Singularitas technologica" lang="la" hreflang="la">Latina</a></li>
			<li class="interwiki-lv"><a href="http://lv.wikipedia.org/wiki/Tehnolo%C4%A3isk%C4%81_singularit%C4%81te" title="Tehnoloģiskā singularitāte" lang="lv" hreflang="lv">Latviešu</a></li>
			<li class="interwiki-lt"><a href="http://lt.wikipedia.org/wiki/Technologinis_singuliarumas" title="Technologinis singuliarumas" lang="lt" hreflang="lt">Lietuvių</a></li>
			<li class="interwiki-hu"><a href="http://hu.wikipedia.org/wiki/Technol%C3%B3giai_szingularit%C3%A1s" title="Technológiai szingularitás" lang="hu" hreflang="hu">Magyar</a></li>
			<li class="interwiki-nl"><a href="http://nl.wikipedia.org/wiki/Technologische_singulariteit" title="Technologische singulariteit" lang="nl" hreflang="nl">Nederlands</a></li>
			<li class="interwiki-ne"><a href="http://ne.wikipedia.org/wiki/%E0%A4%AA%E0%A5%8D%E0%A4%B0%E0%A5%8C%E0%A4%A6%E0%A5%8D%E0%A4%AF%E0%A5%8B%E0%A4%97%E0%A5%80%E0%A4%AF_%E0%A4%8F%E0%A4%95%E0%A4%B5%E0%A4%9A%E0%A4%A8%E0%A4%A4%E0%A5%8D%E0%A4%B5" title="प्रौद्योगीय एकवचनत्व" lang="ne" hreflang="ne">नेपाली</a></li>
			<li class="interwiki-ja"><a href="http://ja.wikipedia.org/wiki/%E6%8A%80%E8%A1%93%E7%9A%84%E7%89%B9%E7%95%B0%E7%82%B9" title="技術的特異点" lang="ja" hreflang="ja">日本語</a></li>
			<li class="interwiki-pl"><a href="http://pl.wikipedia.org/wiki/Technologiczna_osobliwo%C5%9B%C4%87" title="Technologiczna osobliwość" lang="pl" hreflang="pl">Polski</a></li>
			<li class="interwiki-pt"><a href="http://pt.wikipedia.org/wiki/Singularidade_tecnol%C3%B3gica" title="Singularidade tecnológica" lang="pt" hreflang="pt">Português</a></li>
			<li class="interwiki-ro"><a href="http://ro.wikipedia.org/wiki/Singularitate_tehnologic%C4%83" title="Singularitate tehnologică" lang="ro" hreflang="ro">Română</a></li>
			<li class="interwiki-ru"><a href="http://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%81%D0%B8%D0%BD%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%BD%D0%BE%D1%81%D1%82%D1%8C" title="Технологическая сингулярность" lang="ru" hreflang="ru">Русский</a></li>
			<li class="interwiki-simple"><a href="http://simple.wikipedia.org/wiki/Technological_singularity" title="Technological singularity" lang="simple" hreflang="simple">Simple English</a></li>
			<li class="interwiki-sk"><a href="http://sk.wikipedia.org/wiki/Technologick%C3%A1_singularita" title="Technologická singularita" lang="sk" hreflang="sk">Slovenčina</a></li>
			<li class="interwiki-sl"><a href="http://sl.wikipedia.org/wiki/Tehnolo%C5%A1ka_singularnost" title="Tehnološka singularnost" lang="sl" hreflang="sl">Slovenščina</a></li>
			<li class="interwiki-sr"><a href="http://sr.wikipedia.org/wiki/Tehnolo%C5%A1ka_singularnost" title="Tehnološka singularnost" lang="sr" hreflang="sr">Српски / srpski</a></li>
			<li class="interwiki-fi"><a href="http://fi.wikipedia.org/wiki/Teknologinen_singulariteetti" title="Teknologinen singulariteetti" lang="fi" hreflang="fi">Suomi</a></li>
			<li class="interwiki-sv"><a href="http://sv.wikipedia.org/wiki/Teknologisk_singularitet" title="Teknologisk singularitet" lang="sv" hreflang="sv">Svenska</a></li>
			<li class="interwiki-ta"><a href="http://ta.wikipedia.org/wiki/%E0%AE%A8%E0%AF%81%E0%AE%9F%E0%AF%8D%E0%AE%AA%E0%AE%BF%E0%AE%AF%E0%AE%B2%E0%AF%8D_%E0%AE%92%E0%AE%B1%E0%AF%8D%E0%AE%B1%E0%AF%88%E0%AE%AA%E0%AF%8D%E0%AE%AA%E0%AF%81%E0%AE%B3%E0%AF%8D%E0%AE%B3%E0%AE%BF" title="நுட்பியல் ஒற்றைப்புள்ளி" lang="ta" hreflang="ta">தமிழ்</a></li>
			<li class="interwiki-tt"><a href="http://tt.wikipedia.org/wiki/%D0%A2%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F_%D1%81%D0%B8%D0%BD%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%BB%D1%8B%D0%B3%D1%8B" title="Технология сингулярлыгы" lang="tt" hreflang="tt">Татарча/tatarça</a></li>
			<li class="interwiki-uk"><a href="http://uk.wikipedia.org/wiki/%D0%A2%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D1%96%D1%87%D0%BD%D0%B0_%D1%81%D0%B8%D0%BD%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%BD%D1%96%D1%81%D1%82%D1%8C" title="Технологічна сингулярність" lang="uk" hreflang="uk">Українська</a></li>
			<li class="interwiki-vi"><a href="http://vi.wikipedia.org/wiki/%C4%90i%E1%BB%83m_k%E1%BB%B3_d%E1%BB%8B_c%C3%B4ng_ngh%E1%BB%87" title="Điểm kỳ dị công nghệ" lang="vi" hreflang="vi">Tiếng Việt</a></li>
			<li class="interwiki-zh"><a href="http://zh.wikipedia.org/wiki/%E6%8A%80%E6%9C%AF%E5%A5%87%E5%BC%82%E7%82%B9" title="技术奇异点" lang="zh" hreflang="zh">中文</a></li>
		</ul>
	</div>
</div>

<!-- /LANGUAGES -->
			</div>
			<!-- /panel -->
		</div>
		<!-- footer -->
		<div id="footer" role="contentinfo">
							<ul id="footer-info">
											<li id="footer-info-lastmod"> This page was last modified on 13 February 2013 at 07:45.<br /></li>
											<li id="footer-info-copyright">Text is available under the <a rel="license" href="../Wikipedia_Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.
See <a href="http://wikimediafoundation.org/wiki/Terms_of_Use">Terms of Use</a> for details.<br/>
Wikipedia® is a registered trademark of the <a href="http://www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.<br /></li><li class="noprint"><a class='internal' href="Wikipedia_Contact_us">Contact us</a></li>
									</ul>
							<ul id="footer-places">
											<li id="footer-places-privacy"><a href="http://wikimediafoundation.org/wiki/Privacy_policy" title="wikimedia:Privacy policy">Privacy policy</a></li>
											<li id="footer-places-about"><a href="Wikipedia_About" title="Wikipedia:About">About Wikipedia</a></li>
											<li id="footer-places-disclaimer"><a href="Wikipedia_General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
											<li id="footer-places-mobileview"><a href="http://en.m.wikipedia.org/wiki/Technological_singularity" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
									</ul>
										<ul id="footer-icons" class="noprint">
					<li id="footer-copyrightico">
						<a href="http://wikimediafoundation.org/"><img src="http://bits.wikimedia.org/images/wikimedia-button.png" width="88" height="31" alt="Wikimedia Foundation"/></a>
					</li>
					<li id="footer-poweredbyico">
						<a href="http://www.mediawiki.org/"><img src="http://bits.wikimedia.org/static-1.21wmf9/skins/common/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" width="88" height="31" /></a>
					</li>
				</ul>
						<div style="clear:both"></div>
		</div>
		<!-- /footer -->
		<script>if(window.mw){
mw.loader.state({"site":"loading","user":"ready","user.groups":"ready"});
}</script>
<script src="http://bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&lang=en&modules=skins.vector&only=scripts&skin=vector&*"></script>
<script>if(window.mw){
mw.loader.load(["mw.PopUpMediaTransform","mobile.desktop","mediawiki.user","mediawiki.page.ready","mediawiki.searchSuggest","mediawiki.hidpi","ext.gadget.teahouse","ext.gadget.ReferenceTooltips","ext.gadget.DRN-wizard","ext.gadget.charinsert","mw.MwEmbedSupport.style","ext.vector.collapsibleNav","ext.vector.collapsibleTabs","ext.vector.editWarning","ext.UserBuckets","ext.articleFeedback.startup","ext.articleFeedbackv5.startup","ext.markAsHelpful","ext.Experiments.experiments"], null, true);
}</script>
<script src="../../w/index-title=MediaWiki_Gadget-ReferenceTooltips.js&action=raw&ctype=text_javascript&508635914.php.html"></script>
<script src="http://bits.wikimedia.org/en.wikipedia.org/load.php?debug=false&lang=en&modules=site&only=scripts&skin=vector&*"></script>
<!-- Served by mw1065 in 0.133 secs. -->
	</body>
</html>

<!-- Localized -->
